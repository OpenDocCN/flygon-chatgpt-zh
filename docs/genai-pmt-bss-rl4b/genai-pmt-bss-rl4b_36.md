参考文献和引用 Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). 生成对抗网络。在神经信息处理系统的进展中（第 2672-2680 页）。[链接：[`papers.nips.cc/paper/5423-generative-adversarial-nets.pdf`](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) ]Radford, A., Metz, L., & Chintala, S. (2016). 深度卷积生成对抗网络的无监督表示学习。arXiv 预印本 arXiv:1511.06434。[链接：[`arxiv.org/abs/1511.06434`](https://arxiv.org/abs/1511.06434) ]Brock, A., Donahue, J., & Simonyan, K. (2018). 大规模 GAN 训练用于高保真度原始图像合成。在国际学习表示会议（ICLR）中。[链接：[`openreview.net/pdf?id=B1xsqj09Fm`](https://openreview.net/pdf?id=B1xsqj09Fm) ]Karras, T., Laine, S., & Aila, T. (2018). 用于生成对抗网络的基于样式的生成器架构。在 IEEE 计算机视觉与模式识别会议论文集中（第 4401-4410 页）。[链接：[`openaccess.thecvf.com/content_cvpr_2018/papers/Karras_A_Style-Based_Generator_CVPR_2018_paper.pdf`](https://openaccess.thecvf.com/content_cvpr_2018/papers/Karras_A_Style-Based_Generator_CVPR_2018_paper.pdf) ]Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., & Belongie, S. (2018). 堆叠生成对抗网络。在 IEEE 计算机视觉与模式识别会议论文集中（第 1866-1875 页）。[链接：[`openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Stacked_Generative_Adversarial_CVPR_2017_paper.pdf`](https://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Stacked_Generative_Adversarial_CVPR_2017_paper.pdf) ]Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2017). 使用扩张卷积改进文本建模的变分自动编码器。在第 31 届国际神经信息处理系统大会上（第 2136-2146 页）。[链接：[`papers.nips.cc/paper/6706-improved-variational-autoencoders-for-text-modeling-using-dilated-convolutions.pdf`](https://papers.nips.cc/paper/6706-improved-variational-autoencoders-for-text-modeling-using-dilated-convolutions.pdf) ]Salimans, T., Karpathy, A., & Chen, X. (2017). PixelCNN++：通过离散化逻辑混合似然和其他修改改进 PixelCNN。arXiv 预印本 arXiv:1701.05517。[链接：[`arxiv.org/abs/1701.05517`](https://arxiv.org/abs/1701.05517) ]Brock, A., Lim, T., Ritchie, J. M., & Weston, N. (2019). 具有内省对抗网络的神经照片编辑。在 IEEE 计算机视觉与模式识别会议论文集中（第 6199-6208 页）。[链接：[`openaccess.thecvf.com/content_CVPR_2019/papers/Brock_Neural_Photo_Editing_With_Introspective_Adversarial_Networks_CVPR_2019_paper.pdf`](https://openaccess.thecvf.com/content_CVPR_2019/papers/Brock_Neural_Photo_Editing_With_Introspective_Adversarial_Networks_CVPR_2019_paper.pdf) ]Liu, H., & Ma, L. (2020). 生成对抗网络综述：算法、理论和应用。IEEE Access, 8, 29529-295Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... & Amodei, D. (2020). 语言模型是少样本学习者。arXiv 预印本 arXiv:2005.14165。[链接：[`arxiv.org/abs/2005.14165`](https://arxiv.org/abs/2005.14165) ]Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). 语言模型是无监督多任务学习者。OpenAI 博客, 1(8), 9。[链接：[`d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf`](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) ]Gao, J., Wenzel, S., Lin, Y., Mansimov, E., Yu, L., & Bengio, Y. (2021). 用于从自然语言中合成程序的神经引导约束逻辑编程。在北美计算语言学协会 2021 年会议论文集中（第 1531-1541 页）。[链接：[`aclanthology.org/2021.naacl-main.123.pdf`](https://aclanthology.org/2021.naacl-main.123.pdf) ]Dodge, J., & Gane, A. (2021). 微调预训练语言模型：权重初始化、数据顺序和早停止。在北美计算语言学协会 2021 年会议论文集中（第 3093-3103 页）。[链接：[`aclanthology.org/2021.naacl-main.290.pdf`](https://aclanthology.org/2021.naacl-main.290.pdf) ]Keskar, N. S., McCann, B., Varshney, L. R., Liu, C., Fischer, I., & Bengio, Y. (2021). 深度学习中初始化和动量的重要性。在第 38 届国际机器学习大会（ICML）中（第 5202-5212 页）。[链接：[`proceedings.icml.cc/static/paper_files/icml/2021/5208-Paper.pdf`](https://proceedings.icml.cc/static/paper_files/icml/2021/5208-Paper.pdf) ]Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., & Bowman, S. R. (2019). GLUE：自然语言理解的多任务基准和分析平台。在 2019 年经验方法自然语言处理会议和第 9 届国际自然语言处理联合会议（EMNLP-IJCNLP）中（第 3675-3685 页）。[链接：[`www.aclweb.org/anthology/D19-1231.pdf`](https://www.aclweb.org/anthology/D19-1231.pdf) ]Lewis, M., Liu, Y. Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., ... & Zettlemoyer, L. (2020). 预训练语言模型用于对话人工智能。arXiv 预印本 arXiv:2004.14294。[链接：[`arxiv.org/abs/2004.14294`](https://arxiv.org/abs/2004.14294)Dodge, J., Gane, A., Zhang, X., Bordes, A., Chopra, S., & Miller, A. (2020). 从人类偏好微调语言模型。arXiv 预印本 arXiv:2004.14228。[链接：[`arxiv.org/abs/2004.14228`](https://arxiv.org/abs/2004.14228) ]Holtzman, A., Buys, J., Forbes, M., & Choi, Y. (2021). 神经文本退化的奇怪案例。arXiv 预印本 arXiv:2101.05961。[链接：[`arxiv.org/abs/2101.05961`](https://arxiv.org/abs/2101.05961) ]Li, J., Li, W., Li, S., & Liu, X. (2021). 生成对抗网络研究的局限性和机会综述。arXiv 预印本 arXiv:2103.01864。[链接：[`arxiv.org/abs/2103.01864`](https://arxiv.org/abs/2103.01864) ]Keshavarzi, M., & Hashemi, S. M. (2021). 自然语言生成的挑战和局限性综述。自然语言工程, 27(2), 211-251。[链接：[`www.cambridge.org/core/journals/natural-language-engineering/article/survey-of-the-challenges-and-limitations-of-natural-language-generation/7C26143B9B04DCAE2B67051F7D42435A`](https://www.cambridge.org/core/journals/natural-language-engineering/article/survey-of-the-challenges-and-limitations-of-natural-language-generation/7C26143B9B04DCAE2B67051F7D42435A) ]Liu, C., McCann, B., Keskar, N. S., Xiong, C., & Socher, R. (2021). 无监督双语词典归纳的局限性。在北美计算语言学协会 2021 年会议论文集中（第 1929-1939 页）。[链接：[`aclanthology.org/2021.naacl-main.151.pdf`](https://aclanthology.org/2021.naacl-main.151.pdf) ]Yang, Z., Dai, Z., Yang, Y., Carbonell, J. G., Salakhutdinov, R., & Le, Q. V. (2019). XLNet：用于语言理解的广义自回归预���练。在神经信息处理系统的进展中（第 5754-5764 页）。[链接：[`proceedings.neurips.cc/paper/2019/file/2e9cf1a55c6bb74b6f8e3a9abfeaf60c-Paper.pdf`](https://proceedings.neurips.cc/paper/2019/file/2e9cf1a55c6bb74b6f8e3a9abfeaf60c-Paper.pdf) ]
