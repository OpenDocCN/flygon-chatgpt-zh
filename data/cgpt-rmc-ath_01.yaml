- en: What is ChatGPT?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是ChatGPT？
- en: Artificial intelligence is a broad field of computer science focused on creating
    systems capable of performing tasks that typically require human intelligence.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能是计算机科学的一个广泛领域，专注于创建能够执行通常需要人类智能的任务的系统。
- en: A key component of AI is Natural Language Processing. NLP allows machines to
    understand, interpret, and generate human language in a way that is both meaningful
    and contextually appropriate.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的一个关键组成部分是自然语言处理。自然语言处理使机器能够理解、解释和生成人类语言，以一种有意义且具有上下文的方式。
- en: 'How ChatGPT Works: Training, Language Model, and Abilities'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的工作原理：训练、语言模型和能力
- en: In the case of language models like ChatGPT, these algorithms are trained using
    vast amounts of data. By processing millions of sentences, phrases, and words,
    the AI model learns the structure of a language, grammar rules, common phrases,
    and facts.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像ChatGPT这样的语言模型，这些算法是使用大量数据进行训练的。通过处理数百万个句子、短语和单词，人工智能模型学习了语言的结构、语法规则、常用短语和事实。
- en: ChatGPT is based on a type of machine learning model known as a transformer
    neural network, specifically, the Generative Pre-trained Transformer model.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT基于一种称为变压器神经网络的机器学习模型，具体来说是生成式预训练变压器模型。
- en: 'Training ChatGPT involves two stages: pre-training and fine-tuning. During
    pre-training, the model is exposed to a vast dataset containing parts of the internet.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 训练ChatGPT包括两个阶段：预训练和微调。在预训练期间，模型接触到包含互联网部分的大量数据集。
- en: The model doesn't know specifics about which documents were in its training
    set or have access to any specific documents or sources.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型不知道其训练集中有哪些具体文件，也无法访问任何特定文件或来源。
- en: Instead, it learns to predict the next word in a sentence based on the words
    it has seen so far. Then, it is fine-tuned through reinforcement learning from
    human feedback, focusing it on more specific tasks, like maintaining a coherent
    conversation or writing a piece of fiction.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，它学会根据迄今为止看到的单词来预测句子中的下一个单词。然后，通过人类反馈进行强化学习，使其专注于更具体的任务，如维持连贯的对话或撰写一篇小说。
- en: The first GPT model, GPT-1, was a proof-of-concept model developed by OpenAI
    in 2018\. GPT-3, unveiled in June 2020, took things a step further, with a massive
    leap in the size of the model and its capabilities. Each iteration improved the
    language model's ability to generate coherent, contextually relevant sentences,
    and respond effectively to various prompts.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个GPT模型GPT-1是OpenAI在2018年开发的一个概念验证模型。GPT-3在2020年6月推出，进一步提升了模型的规模和能力。每个迭代都提高了语言模型生成连贯、上下文相关句子的能力，并有效地回应各种提示。
- en: It doesn't understand the text it generates but simply predicts what comes next
    based on its training.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 它不理解自己生成的文本，而只是根据其训练预测接下来会发生什么。
- en: The most recent version of this AI model is GPT-4, an even larger and more capable
    model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这个人工智能模型的最新版本是GPT-4，这是一个更大、更有能力的模型。
- en: 'ChatGPT: Purpose and Abilities'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT：目的和能力
- en: The primary purpose of ChatGPT is to generate human-like text based on the prompts
    it's given. ChatGPT can understand and continue a text based on the context provided
    by the prompt, making it useful for various purposes, from drafting emails to
    tutoring in various subjects, and writing fiction.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的主要目的是根据给定的提示生成类似人类的文本。ChatGPT可以根据提示提供的上下文理解并继续文本，使其在各种用途上都很有用，从起草电子邮件到辅导各种学科，再到写小说。
- en: 'Understanding ChatGPT: Tokens, Memory Limitations, and Evolution from 3.5 to
    4'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 理解ChatGPT：令牌、记忆限制和从3.5到4的演变
- en: Within a single conversation, ChatGPT's understanding is bound by a window of
    'memory' or context length defined by 'tokens.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个对话中，ChatGPT的理解受到由“令牌”定义的“记忆”或上下文长度窗口的限制。
- en: A token is a chunk of text that can be as short as one character or as long
    as one word in English (e.g., 'a,' 'apple'). In other languages, a token might
    not correspond to a whole word.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌是一段文本，可以是英语中的一个字符或一个单词（例如，“a”，“apple”）。在其他语言中，一个令牌可能不对应一个完整的单词。
- en: The maximum number of tokens that ChatGPT can handle at once – the 'context
    window' – limits the conversation length. If a conversation exceeds this limit,
    the AI loses sight of the earlier tokens, affecting its ability to maintain context
    and coherence.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT一次可以处理的最大令牌数量 - “上下文窗口” - 限制了对话的长度。如果对话超过此限制，人工智能将失去对先前令牌的视野，影响其维持上下文和连贯性的能力。
- en: ChatGPT-4 has a larger model size, which corresponds to improved fluency, creativity,
    and comprehension.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT-4具有更大的模型尺寸，这对应于改进的流畅性、创造力和理解能力。
- en: It means that ChatGPT-4 can generate higher-quality outputs, particularly in
    complex tasks or long conversations.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着ChatGPT-4可以生成更高质量的输出，特别是在复杂任务或长对话中。
- en: As we look to the future, continual advancements in AI tools such as ChatGPT
    will improve the ability of these tools to support creative writing projects,
    while still maintaining your unique author voice and writing style.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，像ChatGPT这样的人工智能工具的不断进步将提高这些工具支持创意写作项目的能力，同时仍然保持您独特的作者声音和写作风格。
