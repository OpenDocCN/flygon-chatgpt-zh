# [第 9 章](toc.xhtml#c09)

# [GPT 系列的历史流程和发展](toc.xhtml#c09)

# [介绍](toc.xhtml#s70a)

生成式预训练变压器（GPT）模型是当今最受欢迎的自然语言处理模型之一。本章深入探讨了 GPT-1 和 GPT-2 模型的复杂性，讨论了它们的架构、训练阶段、实施规范和评估。GPT-1 首次于 2018 年 6 月推出，旨在通过精细调整和生成式预训练开发强大的自然语言理解基础。它经过多样化级别的未标记文本语料数据训练，使其能够学习单词和短语之间的模式和关系。该模型能够生成连贯的文本和完整的句子，使其在诸如聊天机器人、语言翻译和摘要等各种应用中非常有用。

2019 年 2 月，GPT-2 发布，比其前身拥有更大的数据集和更多的参数。GPT-2 能够生成更长、更连贯的句子，同时还能同时处理多个任务。总的来说，本章详细介绍了 GPT-1 和 GPT-2 模型的技术方面。它突出了它们的优势和局限性，并讨论了它们在各个领域的潜在应用。了解这些模型的工作原理对于任何对自然语言处理和机器学习感兴趣的人都是必要的。

# [生成式预训练变压器-1](toc.xhtml#s71a)

**发布日期：**2018 年 6 月 11 日

2018 年，第一个 GPT 模型 GPT-1 发布，该模型经过多样化的未标记文本语料数据训练，以获得强大的自然语言理解（NLU）基础，并进行了精细调整和生成式预训练。

# [基本框架](toc.xhtml#s72a)

GPT-1 模型使用了变压器结构进行语言模型训练，包括大约 12 层解码器和伪装的自注意力。它使用了来自 BookCorpus 数据集的数据进行训练，该数据集包含了 7000 多本未发表的书籍，以便让模型在未被识别和未见过的数据下工作，并获得更好和更长的上下文。

# [模型训练阶段](toc.xhtml#s73a)

GPT-1 模型有 3 个阶段的训练：

1.  在高语料文本数据上对模型进行预训练，其中文本被标记并输入到可能性函数中进行优化。

1.  在这个阶段，进行了精细调整，使模型习惯于使用带标签数据的判别性任务——这些数据通过一个变压器块传递，并进入 L2 最大化，最后融入最终的线性优化目标函数。

1.  特定任务的输入转换包含组织良好的输入，如文档三元组、有序句子对、问题和回复，用于特定任务，如问答或文本蕴涵。每个输入序列的标记都被加强为一个顺序，具有开始和结束标记以及分隔符标记以保持顺序。

![](images/Figure-9.1.jpg)

**图 9.1：** *图片定义了不同任务的正常变压器架构和输入模式*

[**来源：** GPT-1 论文]*

# [模型实施规范](toc.xhtml#s74a)

模型使用了 768 维状态来将标记编码为词嵌入，用于位置智能前馈层使用了 3072 维状态和 12 个注意力头。使用了 adam 优化器，学习率为 2.5 x 10 ^(-4)，并且这个学习率在 0 到 2000 次更新中增加了余弦调度。注意力、残差、字节对编码（BPE）词汇表使用了 40000 个合并和 0.1 的嵌入辍学率用于正则化，**高斯误差线性单元**（**GELU**）被用作激活函数。模型在 64 大小的小批量和 512 序列长度上进行了 100 个时期的训练，总共有 117M 个参数。

对于微调部分，观察到了与预训练相同的超参数设置。辍学率为 0.1，学习率为 6.25e-5，批量大小为 32。微调非常迅速，共进行了 3 个时期的步骤，热身在 0.2%的训练中进行，并使用线性学习率衰减计划进行调度。

# [评估](toc.xhtml#s75a)

研究表明，预训练如何提高了模型在各种自然语言处理任务中的零-shot 性能，包括情感分析、问答和模式解析。该架构能够在相对较少的微调下执行一系列自然语言处理任务，并实现迁移学习。这个模型证明了生成式预训练的有效性，并为未来的模型提供了更好地利用更大数据集和额外参数实现这种有效性的机会。在 12 项任务中，GPT-1 在 9 项任务中的表现优于专门训练的监督式最先进模型。

他们利用了最近提供的 RACE 数据集，该数据集包含了中学和高中考试的英文文本和相应的问题。已经证明，这个语料库包含的推理类型的问题比 CNN 或 SQuaD 等其他数据集更多，使其成为该模型的理想测试场所，该模型经过训练可以处理长距离上下文。此外，他们还使用了叙述填空测试，该测试需要从两种可能性中选择正确的结论，用于具有多个句子的故事。与先前的最佳结果相比，GPT-1 模型在这些任务上的表现再次显著优于先前的最佳结果，Story Cloze 的增益高达 8.9%，RACE 整体增益为 5.7%。

要了解 GPT-1 的更多技术方面，您可以参考-通过生成式预训练改进语言理解**-** **https://tinyurl.com/3fu53mrd**

# [生成式预训练变换器-2](toc.xhtml#s76a)

**发布日期：**2019 年 2 月 14 日

GPT 模型的下一个版本是在 2019 年推出的 GPT-2，它是在更大的数据集上进行训练，并丰富了更多的参数，以使这个模型更好。在这第二个版本中，与 GPT-1 的典型即兴表演相比，它基本上是为了同时处理多个任务，如问答、机器翻译、阅读理解和摘要；并试图实现更接近人类能力的任务。它的参数数量比 GPT-1（或小型 GPT-2）增加了 10 倍以上。

# [基础框架](toc.xhtml#s77a)

基础模型类似于最初的 GPT 模型，它是一个只有解码器块的基于变换器的架构。为了执行任务，需要调整学习目标为 P（输出|输入，任务）。任务调节指的是这种修改，即模型预期对于不同任务的相同输入产生不同的输出。一些模型在架构级别上同时给出任务和输入，使用任务调节。对于语言模型，任务、输入和输出都是语言段落。因此，语言模型的任务调节是通过用自然语言给出模型示例或指令来完成的。GPT-2 中提到的零-shot 任务迁移的基础是任务调节。

GPT-2 在零样本任务转移方面的能力令人着迷。作为零样本任务转移的特例，零样本学习发生在根本没有给出任何示例的情况下，模型被指示执行任务。对于微调，GPT-2 的输入以一种预期模型能够理解任务性质并提供答案的格式呈现，而不是像 GPT-1 那样修改序列。为了模仿零样本任务转移行为，进行了这样的操作。例如，模型被给出一个英文句子，然后是单词“法国”，以及一个英文到法文翻译任务的提示。预期模型能够理解这个任务涉及翻译，并提供英文陈述的法文等价物。这些任务预计以无监督的方式执行。

为了创建一个实质性和优秀的数据集，作者们从 Reddit 网站上获取了数据（至少有 3 个 karma 的帖子），并收集了高赞帖子的外链数据。最终产品名为 WebText，包含了来自 800 多万个出版物的 40GB 文本数据。与用于训练 GPT-1 模型的 Book Corpus 数据集不同，这个庞大的数据集被用于训练 GPT-2 模型。由于测试集中维基百科材料的普遍存在，WebText 不包含维基百科内容。编码采用了 Unicode 机制，将词汇基数从 256 增加到 130,000。

# [模型规格](toc.xhtml#s78a)

GPT-2 拥有 15 亿个参数，是 GPT-1（117M 参数）的十倍。模型中有一些主要元素与 GPT-1 相似，但也包括一些与 GPT-1 有显著差异的元素：

+   对于词嵌入，GPT-2（对于 GPT 大型）使用了 1600 维向量，跨越 48 层，并使用了来自更大词汇表的总共 50,257 个标记。

+   使用了更大的批处理大小 512 和更大的上下文窗口，从 512 个标记增加到 1024 个标记。

+   层归一化被移动到每个子块的输入，并在最终的自注意块之后添加了额外的层归一化。

+   在初始化时，残差层的权重按 1/√N 进行了缩放，其中 N 是残差层的数量。

为了训练四个语言模型，分别使用了约 117M（GPT-1）、345M、762M 和 1.5B（GPT-2）个参数，层次分别为 12、24、36、48 层，维度分别为 768、1024、1280、1600。每个后续模型的困惑度都比前一个模型低。这表明随着参数数量的增加，相同数据集上的语言模型的复杂性降低。此外，具有最多参数的模型在每个下游任务中都表现更好。

# [评估](toc.xhtml#s79a)

用于评估 GPT-2 的许多下游任务的数据集，如阅读理解、摘要、翻译和问答：

+   在零样本设置中，GPT-2 在跨领域和数据集的 8 个语言建模数据集中，对 7 个数据集的当时最先进技术进行了改进。尽管在性能方面在十亿字基准测试中表现不佳，这很可能是因为它具有最多的数据样本并且具有最具破坏性的预处理。

+   儿童图书数据集评估了语言模型在应用于各种词类（包括名词、介词和命名实体）时的表现，基本上是为了估计在 10 个可能选择中正确省略的单词。随着模型参数的增长，GPT-2 在 CBT 命名实体和 CBT 常见名词方面的准确性稳步增长；对于常见名词和命名实体，新的最先进的准确性结果分别为 93.3%和 89.1%。

+   LAMBADA 数据集评估模型在找到遥远依赖和猜测句子最后一个词方面的表现。GPT-2 将语言模型的准确率从 19%提高到 52.66%，并将困惑度从 99.8 降低到 8.6。它在句子的有效延续方面表现更好，但在有效的最终词方面表现不佳。通过添加停止过滤器，它的表现得到了 4%的改善。

+   通过评估系统在文本中解决歧义的能力，Winograd Schema 挑战旨在衡量其常识思维能力。GPT-2 的准确率提高了 7%，达到了 70.70%。

+   CoQA 数据集包括来自几个领域的论文，这些领域自然地交换问题和答案。这项练习衡量了一个人的阅读理解能力，以及他们基于先前对话回答问题的能力。GPT-2 在涉及阅读理解的零-shot 任务上与训练数据中的 127,000 多个问题-答案对匹配或超过了 4 个基线中的 3 个的结果。

总的来说，根据 GPT-2 的说法，语言模型在零样本情况下理解任务并在许多任务上超越了最先进技术的能力得到了改善，这是通过在更大的数据集上进行训练并使用更多参数实现的。该论文声称，随着模型容量的增加，性能呈对数线性增长。

![](images/Figure-9.2.jpg)

**图 9.2：** *GPT-2 在 CBT 数据集中的表现

[**来源：** GPT-2 论文]*

此外，当参数数量增加时，语言模型困惑度的下降并没有接近饱和点。WebText 数据集确实使 GPT-2 欠拟合，也许更长的训练会进一步降低困惑度。根据研究，GPT-2 模型大小并不是最大的，更大的语言模型将有助于人们通过减少混淆来理解自然语言。

![](images/Figure-9.3.jpg)

**图 9.3：** *GPT-2 在 Winograd Schema Challenge 中的表现

[**来源：** GPT-2 论文]*

要了解 GPT-2 的更多技术方面，您可以参考- 语言模型是无监督多任务学习者- **https://tinyurl.com/3x7b74n9**

# [GPT-3 的介绍](toc.xhtml#s80a)

**发布日期：** 2020 年 5 月 28 日

在 GPT-2 推出一年后，openAI 推出了 GPT 系列的另一个更新和先进版本 GPT-3，“语言模型是少样本学习者”。Open AI 创建了拥有 1750 亿参数的 GPT-3 模型，旨在创建极其强大和有效的语言模型，只需要少量训练和少量演示即可理解任务并执行。这个模型的参数比 GPT-2 多 100 倍，比微软强大的 Turing NLG 语言模型多 10 倍。由于它训练的参数和庞大的数据集，GPT-3 在零样本和少样本设置下在下游 NLP 任务上表现良好。它可以写出难以区分是否由人产生的文章，这要归功于它的巨大容量。它还可以完成从未明确教授的即时任务，比如加减数字，生成 SQL 查询和代码，解码单词的句子，根据自然语言中的任务描述编写 React 和 JavaScript 代码等。

# [基础框架](toc.xhtml#s81a)

大型语言模型通过训练的文本数据获得了模式检测和其他能力。语言模型在学习预测给定上下文单词的下一个单词的核心任务时，开始识别数据中的模式，这有助于它们减少语言建模任务的损失。最终，当转移零次任务时，模型从这种技能中受益。语言模型将实例的模式与它以前学到的类似数据的模式进行比较，并利用这些知识来执行任务，当给出一些示例和/或需要完成的任务描述时。这是巨大语言模型的一个强大能力，随着模型参数数量的增加而变得更强大。

少次、一次和零次设置是零次任务转移的专门示例，正如之前所述。在少次配置中，将工作描述和尽可能多的示例提供给模型的上下文窗口。在一次设置中，向模型提供一个示例，而在零次设置中则不提供任何示例。随着容量的增加，模型的少次、一次和零次能力都得到了提高。

！[](images/Figure-9.4.jpg)

**图 9.4：** *代表训练期间上下文学习机制的图像

[**来源：**GPT-3 论文]*

使用了五个不同的语料库来训练 GPT-3，每个都有特定的权重。使用了高质量的数据集来训练模型，并且经常进行抽样。Common Crawl、WebText2、Books1、Books2 和 Wikipedia 是使用的五个数据集，其中包括大部分文本和上下文数据的用例模式。

# [模型规格](toc.xhtml#s82a)

与 GPT-2 一样，该模型首先使用了 transformer 基础的 GPT 模型，但这个版本与 GPT-2 有一些重大区别，如下所述：

+   GPT-3 已经在 3 种不同的上下文学习中进行了评估，而不是传统的零、一和少次学习技术。

+   GPT-3 有 96 层，每层有 96 个注意头。

+   GPT-3 的词嵌入大小从 GPT-2 的 1600 增加到 12888。

+   上下文窗口大小从 GPT-2 的 1024 个标记增加到 GPT-3 的 2048 个标记。

+   Adam 优化器使用β_1=0.9，β_2=0.95 和ε= 10^(-8)。

+   交替使用了密集和局部带状稀疏的注意模式。

# [评估](toc.xhtml#s83a)

使用了各种语言建模和自然语言处理数据集来测试 GPT-3。在少次或零次情况下，GPT-3 超越了像 LAMBADA 和 Penn Tree Bank 这样的语言建模数据集的尖端方法。虽然它无法超越其他数据集的最新技术，但它确实提高了零次最新技术的性能。在诸如闭卷问题回答、模式解析、翻译等 NLP 任务中，GPT-3 再次表现良好，经常超越或接近调整良好的模型。

！[](images/Figure-9.5.jpg)

**图 9.5：** *执行任务的四种语言模型方法

[**来源：**GPT-3 论文]*

对于大多数任务，该模型在少样本设置中的表现优于单样本和零样本设置。使用了各种语言建模和自然语言处理数据集来测试 GPT-3。在少样本或零样本情况下，GPT-3 的表现优于 LAMBADA 和 Penn Tree Bank 等语言建模数据集的尖端方法。虽然它无法超越其他数据集的最新技术水平，但它确实提高了零样本技术水平。在诸如闭卷问题回答、模式解析、翻译等 NLP 任务中，GPT-3 再次表现良好，经常优于或接近调整良好的模型。对于 CoQA 基准测试，在零样本设置中为 81.5 F1，在单样本设置中为 84.0 F1，在少样本设置中为 85.0 F1，而经过精调的 SOTA 达到了 90.7 F1。在 TriviaQA 基准测试中，零样本设置分别为 64.3％，68.0％，71.2％的准确率，在单样本设置和少样本设置中分别为 68.0％，优于现有技术水平（68.0％）3.2％。在 LAMBADA 数据集上，零样本设置分别为 76.2％，72.5％，86.4％的准确率，在单样本设置和少样本设置中分别为 68.0％，优于现有技术水平（68.0％）18.0％。除了在传统的 NLP 任务上进行评估外，该模型还在更多的人工任务上进行了评估，例如添加数字、解密单词、创建新闻文章、学习和利用新术语等。对于这些任务，该模型在少样本选项中的表现优于单样本和零样本设置，性能随着参数数量的增加而提高。

要了解 GPT-3 的更多技术方面，您可以参考- 语言模型是少样本学习者- **https://tinyurl.com/4ym9tehp**

# GPT-3 的 API 开发

2020 年 6 月，openAI 发布了他们的 API，提供了一个通用的“文本输入，文本输出”的接口，允许用户在基本上任何英语语言工作上尝试它，与大多数为单一用例开发的人工智能系统形成对比。现在可以请求在产品中使用 API 的许可，创建全新的应用程序，或协助研究这项技术的优势和劣势。

当给定任何文本提示时，API 将尝试匹配您提供的模式，并提供文本完成。它可以通过提供您想要完成的一些样本来“编程”它；通常成功程度取决于任务的难度。API 还可以通过从用户或标记者提供的人类输入学习，或者通过训练您提供的数据集（小或大）来提高某些任务的性能。

2020 年 9 月，GPT-3 与微软整合，独家授权 GPT-3，使我们能够利用其技术创新来开发和提供先进的人工智能解决方案，为我们的客户创造新的潜在人工智能解决方案。

![](images/Figure-9.6.jpg)

**图 9.6：** *InstructGPT 模型或 GPT 3.5 中输入馈送的过程

[**来源：** InstructGPT 论文]*

2021 年底，OpenAI 最终在指定国家的公共空间为所有用户提供了整个 GPT-3 及其 API，并提供了改进的 Playground，这使得使用我们的模型进行原型设计变得容易，一个包含数十个提示的示例库，以帮助开发人员入门，以及 Codex，一个将自然语言转换为代码的新模型。

# GPT-3.5，InstructGPT 的介绍

大型语言模型过去面临的一个主要问题是，有时会出现未经过滤的人工智能生成的内容和响应，这些内容看起来不真实、有毒且与用户无关。因此，OpenAI 集成了一个带有人类反馈的微调，这有助于满足各种任务。这种经过微调的监督模型是通过人类反馈的强化学习训练的，被称为 InstructGPT。

# [基础框架](toc.xhtml#s86a)

在 InstructGPT 中，标注者展示了预期行为的示例。这些人类提示包括生成、问答、对话、摘要、提取等自然语言任务，并且主要建立在英语（96％）上。几乎有 40 名承包商为人类反馈做出了贡献，大约 73％的训练标注者之间进行了协同合作。

# [模型规格](toc.xhtml#s87a)

在 InstructGPT 的训练部分，标注者被指示使用 3 种提示，包括 1. 参与一些任意任务 2. 多个指令和多个查询 3. 关于来自等待用户的随机观众的某些相应解决方案。训练机制被分开，以训练 3 种不同的训练模型结构，在 SFT 模型中，数据集是通过标注者演示进行训练的，同样也是通过奖励模型进行调整，并且数据集是根据先前模型输出的排名进行人类解释；而 PPO 模型则完全在没有人类干预的情况下进行微调。

**监督微调（SFT）：**在这个模型中，标签数据已经在微调机制中进行了 16 个时期的训练，使用余弦衰减率和残差丢失率 0.2。

**奖励建模（RM）：**该模型已经训练好输入提示响应并获得标量响应。奖励的差异代表了一个响应被人类标签优先于另一个的对数几率。在这个结构中，他们已经训练了大约 60 亿个 RM 中的 175B 个。

**强化学习（RL）：**在一个类似赌徒的环境中提出了一个随机的消费者请求，并期望得到一个响应。它根据提示和答案生成奖励，由奖励模型定义，并结束该情节。为了防止奖励模型过度优化，他们还在每个标记处应用了来自 SFT 模型的标记 KL 惩罚。RM 被用来初始化值函数。这些模型被称为“PPO”。

# [结果](toc.xhtml#s88a)

在探索发展现有 NLP 模型生态系统的更多领域方面，OpenAI 提出了另一个令人着迷的发展，可以解决填充问题。OpenAI 希望允许它们在不影响其从左到右正常生成代码的能力的情况下获得出色的文本填充。团队对转换训练数据的方法非常简单：他们只是将页面中心的随机文本部分转移到页面末尾。

团队表明，因果 AR LLM 可以学习填写文档的中间部分，并通过在多个目标和数据集上联合训练模型，处理相关任务，如推断导入模块、编写文档字符串和完成函数。总的来说，FIM 模型可能保留与标准 AR 模型相同的从左到右文本容量，同时学会更有效地填写中心部分-这是所提出的训练数据转换技术的优势，为 FIM 提供了免费的。

在 175B 参数（达芬奇模型，最新更新）的情况下，InstructGPT 模型比 GPT-3 更受人类指示的偏好超过 85％的时间，并且在人类指示下比 GPT-3 更受欢迎的时间达 71％。这意味着几乎有 3/4 的时间，标注者更喜欢 InstructGPT 而不是经过条件良好的 GPT-3。即使是提示工程也无法击败 InstructGPT。

![](images/Figure-9.7.jpg)

**图 9.7：** *对于预训练了 100B 标记的模型的最终快照进行评估，没有使用 FIM，然后使用 FIM 进行了 25B（a 行）和 50B（b 行）标记的微调。

[**来源：** InstructGPT 论文]*

要了解更多关于 GPT-3.5 的技术方面，您可以参考- 使用人类反馈训练语言模型遵循指示- **https://tinyurl.com/yny5uux2**

# [GPT-3 模型 API 标记的成本降低](toc.xhtml#s89a)

随着时间的推移和改进，chatGPT 的订阅模型也在 GPT-3 系列中见证了价格的降低，特别是在达芬奇模型和库里模型中，成本降低了 66% - 从每千个标记的$0.06 和$0.006 分别更新为每千个标记的$0.02 和$0.002。OpenAI 团队不断取得了使模型更加高效和可持续以导致价格降低的惊人进展。

# [Whisper 简介](toc.xhtml#s90a)

在开发更好的 NLP 领域生态系统的过程中，OpenAI 推出了另一个 Whisper，这是一个自动语音识别模型，它经过了 680,000 小时的多语言和多任务监督网络爬取的训练。该模型旨在解决背景噪音、数据干扰的问题，并使其更接近真实估计。该模型还涵盖了一系列多语言任务，并提供转录。多语言部分有 98 种不同的语言数据用于训练目的。

# [Whisper 概述](toc.xhtml#s91a)

训练数据集由多样化的音频剪辑组成，更倾向于真实生活数据，以利用更多人类方面的解释。Whisper AI 建立在以 30 秒声音波块的 mel 频谱图为基础，并将其传递到编码器-解码器 Transformer 中以预测相关的文本标题，特殊标记指示单一模型执行任务，如语言识别，短语级时间戳，多语言语音转录和英语语音翻译，这些都与特殊标记结合在一起。它有 9 种不同的模型大小，根据大小和能力而定。

![](images/Figure-9.8.jpg)

**图 9.8：** *文本处理的训练流程

[**来源：** Whisper 论文]*

其他当前的方法通常利用更大但无监督的音频预训练数据集或更小、更紧密链接的音频文本训练数据集。Whisper 并没有超越专注于 LibriSpeech 性能的模型，LibriSpeech 是语音识别中非常有竞争力的基准，因为它是在广泛而多样的数据集上训练的，而不是针对特定数据集进行了定制。

![](images/Figure-9.9.jpg)

**图 9.9：** *Whisper 的编码器-解码器模型

[**来源：** Whisper 论文]*

然而，与其他可比模型相比，它的零-shot 性能在各种不同数据集上表现出的可靠性更高，且出错率减少了 50%。

Whisper 的性能接近专业人类转录员的水平。该模型已经通过 Whisper 转录的 Kincaid46 数据集的 25 个录音的 WER 分布进行了测试，与一个计算机辅助人工转录服务的 4 个商业 ASR 系统和 4 个人工转录服务的错误范围似乎几乎相似。

要了解更多关于 Whisper 的技术方面，您可以参考- 通过大规模弱监督实现鲁棒语音识别**-** **https://tinyurl.com/359y5t5y**

![](images/Figure-9.10.jpg)

**图 9.10：** *箱线图上叠加了表示单个录音的 WER 的点，每个箱子上注释了 25 个录音的聚合 WER

[**来源：** Whisper 论文]*

# [ChatGPT 简介](toc.xhtml#s92a)

在重新定义和扩展现有模型在各种 NLP 任务周围的结构后，OpenAI 构建了他们的 GPT-3.5（被称为 GPT 3.5 的兄弟模型）系列，成为一个可以满足复杂 NLP 解决方案的对话式智能 AI NLP 系统。随着时间的推移，GPT 3.5 在功能和优化方面有所改进。OpenAI 推出了一系列 GPT 3.5 模型版本，使用户能够更清晰地根据其用例利用和实验模型。

1.  **Turbo：** ChatGPT 的基础模型系列是 Turbo。与 Davinci 模型系列相比，它在完成方面表现出色，同时针对对话式聊天输入和输出进行了优化。API 中的 Turbo 模型系列应该能够很好地适用于 ChatGPT 中可以高效处理的每种用例。像 ChatGPT 一样，第一个经常获得模型升级的模型系列是 Turbo 系列。

**特点：** 对话和文本生成

**最大请求可达到：** 4,096 个标记

**训练日期：** 截至 2021 年 9 月

1.  **DaVinci：** Davinci 模型系列是最有竞争力的，可以完成其他模型（Ada、Curie 和 Babbage）可以完成的任何工作，通常需要更少的训练。Davinci 将为需要深入理解文本的任务产生最佳结果，例如为特定受众进行摘要和创作原创内容。由于这些扩展功能需要更多的计算资源，Davinci 每个 API 请求的成本更高，速度也比其他模型慢。

理解文本目的是 Davinci 擅长的另一个领域。Davinci 擅长推断各种逻辑难题的解决方案和阐明人物动机。一些最困难的因果关系人工智能难题已经被 Davinci 解决。

**特点：** 复杂意图，因果关系，面向受众的摘要

**最大请求可达到：** 4,000 个标记

**训练日期：** 截至 2021 年 6 月

1.  **Curie：** Curie 非常强大，但速度很快。虽然 Curie 擅长许多复杂任务，如情感分类和摘要，但 Davinci 更擅长处理复杂文本。作为通用聊天机器人，Curie 在进行问答和回答查询方面也相当擅长。

**特点：** 语言翻译，复杂分类，文本情感，摘要

1.  巴贝奇：巴贝奇能够进行简单的分类和其他基本任务。在使用语义搜索评估文档与搜索查询的匹配程度时，它也非常有能力。

**特点：** 中等分类，语义搜索分类

1.  **Ada：** Ada 通常是最快的模型，能够完成不需要太多细节的工作，比如文本解析、地址校正和某些类型的分类任务。通过添加额外的上下文，Ada 的性能通常可以得到提升。

**特点：** 解析文本，简单分类，地址校正，关键词

ChatGPT 已经被制定为符合许多人类重视的原型和规则。它在 2022 年初进行了训练。ChatGPT 的基本版本使用了 GPT 3.5-turbo API 作为后端模型，比许多其他 GPT 3.5 系列模型更便宜，使其更受用户欢迎。

# [时间线摘要](toc.xhtml#s93a)

| **日期** | **里程碑** |

| 2018 年 6 月 11 日 | GPT-1 在 OpenAI 博客上宣布。|

| 2019 年 2 月 14 日 | GPT-2 在 OpenAI 博客上宣布。|

| 2020 年 5 月 28 日 | GPT-3 初稿论文发布到 arXiv。|

| 2020 年 6 月 11 日 | GPT-3 API 私人测试版。|

| 2020 年 9 月 22 日 | GPT-3 授权给微软。|

| 2021 年 11 月 18 日 | GPT-3 API 向公众开放。|

| 2022 年 1 月 27 日 | InstructGPT 作为 text-davinci-002 发布，现在被称为 GPT-3.5。InstructGPT 初稿论文于 2022 年 3 月发布。|

| 2022 年 7 月 28 日 | 在 arXiv 上发表了探索数据最优模型的论文。|

| 2022 年 9 月 1 日 | GPT-3 模型的价格为 davinci 和 curie 模型降低了 66%。|

| 2022 年 9 月 21 日 | Whisper（语音识别）在 OpenAI 博客上宣布。|

| 2022 年 11 月 28 日 | GPT-3.5 扩展到 text-davinci-003，通过电子邮件宣布：写作质量更高。处理更复杂的指令。3.更擅长生成更长的内容。 |

| 2022 年 11 月 30 日 | 在 OpenAI 博客上宣布了 ChatGPT。 |

| 2023 年 2 月 1 日 | ChatGPT 的月活跃用户达到 1 亿（通过瑞银报告）。 |

| 2023 年 3 月 1 日 | 在 OpenAI 博客上宣布了 ChatGPT API。 |

*时间表是从 Alan D. Thompson 博士的 GPT 博客中提取的

# [需要记住的要点](toc.xhtml#s94a)

+   GPT-1 于 2018 年 6 月推出，它是通过对多样化的未标记文本语料库数据进行训练，以开发强大的自然语言理解基础，并进行精细调整和生成式预训练。

+   研究表明，预训练如何提高了模型在各种自然语言处理任务上的零-shot 性能，包括情感分析、问答和模式解析。

+   GPT-1 在 12 项任务中有 9 项表现优于专门训练的监督式最先进模型。

+   GPT-1 模型再次在这些任务上表现出比以前最好的结果显着更好，Story Cloze 的增益高达 8.9％，整体上 RACE 的增益为 5.7％。

+   GPT 模型的下一个版本是在 2019 年推出的，GPT-2，它是在更大的数据集上进行训练，并丰富了更多的参数，以使这个模型更好。

+   GPT-2 中提到的零-shot 任务转移的基础是任务调节。

+   GPT 2 在转移零-shot 任务方面的能力令人着迷。

+   作为零-shot 任务转移的特例，当根本没有给出任何示例，并且指示模型执行任务时，零-shot 学习就会发生。

# 加入我们书籍的 Discord 空间

加入书籍的 Discord Workspace，获取最新更新、优惠、世界各地的技术动态、新发布和与作者的交流：

[**https://discord.bpbonline.com**](https://discord.bpbonline.com)

![](images/dis.jpg)
