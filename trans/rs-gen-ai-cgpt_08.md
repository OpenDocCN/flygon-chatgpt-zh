# [第9章](toc.xhtml#c09)

# [GPT系列的历史流程和发展](toc.xhtml#c09)

# [介绍](toc.xhtml#s70a)

生成式预训练变压器（GPT）模型是当今最受欢迎的自然语言处理模型之一。本章深入探讨了GPT-1和GPT-2模型的复杂性，讨论了它们的架构、训练阶段、实施规范和评估。GPT-1首次于2018年6月推出，旨在通过精细调整和生成式预训练开发强大的自然语言理解基础。它经过多样化级别的未标记文本语料数据训练，使其能够学习单词和短语之间的模式和关系。该模型能够生成连贯的文本和完整的句子，使其在诸如聊天机器人、语言翻译和摘要等各种应用中非常有用。

2019年2月，GPT-2发布，比其前身拥有更大的数据集和更多的参数。GPT-2能够生成更长、更连贯的句子，同时还能同时处理多个任务。总的来说，本章详细介绍了GPT-1和GPT-2模型的技术方面。它突出了它们的优势和局限性，并讨论了它们在各个领域的潜在应用。了解这些模型的工作原理对于任何对自然语言处理和机器学习感兴趣的人都是必要的。

# [生成式预训练变压器-1](toc.xhtml#s71a)

**发布日期：**2018年6月11日

2018年，第一个GPT模型GPT-1发布，该模型经过多样化的未标记文本语料数据训练，以获得强大的自然语言理解（NLU）基础，并进行了精细调整和生成式预训练。

# [基本框架](toc.xhtml#s72a)

GPT-1模型使用了变压器结构进行语言模型训练，包括大约12层解码器和伪装的自注意力。它使用了来自BookCorpus数据集的数据进行训练，该数据集包含了7000多本未发表的书籍，以便让模型在未被识别和未见过的数据下工作，并获得更好和更长的上下文。

# [模型训练阶段](toc.xhtml#s73a)

GPT-1模型有3个阶段的训练：

1.  在高语料文本数据上对模型进行预训练，其中文本被标记并输入到可能性函数中进行优化。

1.  在这个阶段，进行了精细调整，使模型习惯于使用带标签数据的判别性任务——这些数据通过一个变压器块传递，并进入L2最大化，最后融入最终的线性优化目标函数。

1.  特定任务的输入转换包含组织良好的输入，如文档三元组、有序句子对、问题和回复，用于特定任务，如问答或文本蕴涵。每个输入序列的标记都被加强为一个顺序，具有开始和结束标记以及分隔符标记以保持顺序。

![](images/Figure-9.1.jpg)

**图9.1：** *图片定义了不同任务的正常变压器架构和输入模式*

[**来源：** GPT-1论文]*

# [模型实施规范](toc.xhtml#s74a)

模型使用了768维状态来将标记编码为词嵌入，用于位置智能前馈层使用了3072维状态和12个注意力头。使用了adam优化器，学习率为2.5 x 10 ^(-4)，并且这个学习率在0到2000次更新中增加了余弦调度。注意力、残差、字节对编码（BPE）词汇表使用了40000个合并和0.1的嵌入辍学率用于正则化，**高斯误差线性单元**（**GELU**）被用作激活函数。模型在64大小的小批量和512序列长度上进行了100个时期的训练，总共有117M个参数。

对于微调部分，观察到了与预训练相同的超参数设置。辍学率为0.1，学习率为6.25e-5，批量大小为32。微调非常迅速，共进行了3个时期的步骤，热身在0.2%的训练中进行，并使用线性学习率衰减计划进行调度。

# [评估](toc.xhtml#s75a)

研究表明，预训练如何提高了模型在各种自然语言处理任务中的零-shot性能，包括情感分析、问答和模式解析。该架构能够在相对较少的微调下执行一系列自然语言处理任务，并实现迁移学习。这个模型证明了生成式预训练的有效性，并为未来的模型提供了更好地利用更大数据集和额外参数实现这种有效性的机会。在12项任务中，GPT-1在9项任务中的表现优于专门训练的监督式最先进模型。

他们利用了最近提供的RACE数据集，该数据集包含了中学和高中考试的英文文本和相应的问题。已经证明，这个语料库包含的推理类型的问题比CNN或SQuaD等其他数据集更多，使其成为该模型的理想测试场所，该模型经过训练可以处理长距离上下文。此外，他们还使用了叙述填空测试，该测试需要从两种可能性中选择正确的结论，用于具有多个句子的故事。与先前的最佳结果相比，GPT-1模型在这些任务上的表现再次显著优于先前的最佳结果，Story Cloze的增益高达8.9%，RACE整体增益为5.7%。

要了解GPT-1的更多技术方面，您可以参考-通过生成式预训练改进语言理解**-** **https://tinyurl.com/3fu53mrd**

# [生成式预训练变换器-2](toc.xhtml#s76a)

**发布日期：**2019年2月14日

GPT模型的下一个版本是在2019年推出的GPT-2，它是在更大的数据集上进行训练，并丰富了更多的参数，以使这个模型更好。在这第二个版本中，与GPT-1的典型即兴表演相比，它基本上是为了同时处理多个任务，如问答、机器翻译、阅读理解和摘要；并试图实现更接近人类能力的任务。它的参数数量比GPT-1（或小型GPT-2）增加了10倍以上。

# [基础框架](toc.xhtml#s77a)

基础模型类似于最初的GPT模型，它是一个只有解码器块的基于变换器的架构。为了执行任务，需要调整学习目标为P（输出|输入，任务）。任务调节指的是这种修改，即模型预期对于不同任务的相同输入产生不同的输出。一些模型在架构级别上同时给出任务和输入，使用任务调节。对于语言模型，任务、输入和输出都是语言段落。因此，语言模型的任务调节是通过用自然语言给出模型示例或指令来完成的。GPT-2中提到的零-shot任务迁移的基础是任务调节。

GPT-2在零样本任务转移方面的能力令人着迷。作为零样本任务转移的特例，零样本学习发生在根本没有给出任何示例的情况下，模型被指示执行任务。对于微调，GPT-2的输入以一种预期模型能够理解任务性质并提供答案的格式呈现，而不是像GPT-1那样修改序列。为了模仿零样本任务转移行为，进行了这样的操作。例如，模型被给出一个英文句子，然后是单词“法国”，以及一个英文到法文翻译任务的提示。预期模型能够理解这个任务涉及翻译，并提供英文陈述的法文等价物。这些任务预计以无监督的方式执行。

为了创建一个实质性和优秀的数据集，作者们从Reddit网站上获取了数据（至少有3个karma的帖子），并收集了高赞帖子的外链数据。最终产品名为WebText，包含了来自800多万个出版物的40GB文本数据。与用于训练GPT-1模型的Book Corpus数据集不同，这个庞大的数据集被用于训练GPT-2模型。由于测试集中维基百科材料的普遍存在，WebText不包含维基百科内容。编码采用了Unicode机制，将词汇基数从256增加到130,000。

# [模型规格](toc.xhtml#s78a)

GPT-2拥有15亿个参数，是GPT-1（117M参数）的十倍。模型中有一些主要元素与GPT-1相似，但也包括一些与GPT-1有显著差异的元素：

+   对于词嵌入，GPT-2（对于GPT大型）使用了1600维向量，跨越48层，并使用了来自更大词汇表的总共50,257个标记。

+   使用了更大的批处理大小512和更大的上下文窗口，从512个标记增加到1024个标记。

+   层归一化被移动到每个子块的输入，并在最终的自注意块之后添加了额外的层归一化。

+   在初始化时，残差层的权重按1/√N进行了缩放，其中N是残差层的数量。

为了训练四个语言模型，分别使用了约117M（GPT-1）、345M、762M和1.5B（GPT-2）个参数，层次分别为12、24、36、48层，维度分别为768、1024、1280、1600。每个后续模型的困惑度都比前一个模型低。这表明随着参数数量的增加，相同数据集上的语言模型的复杂性降低。此外，具有最多参数的模型在每个下游任务中都表现更好。

# [评估](toc.xhtml#s79a)

用于评估GPT-2的许多下游任务的数据集，如阅读理解、摘要、翻译和问答：

+   在零样本设置中，GPT-2在跨领域和数据集的8个语言建模数据集中，对7个数据集的当时最先进技术进行了改进。尽管在性能方面在十亿字基准测试中表现不佳，这很可能是因为它具有最多的数据样本并且具有最具破坏性的预处理。

+   儿童图书数据集评估了语言模型在应用于各种词类（包括名词、介词和命名实体）时的表现，基本上是为了估计在10个可能选择中正确省略的单词。随着模型参数的增长，GPT-2在CBT命名实体和CBT常见名词方面的准确性稳步增长；对于常见名词和命名实体，新的最先进的准确性结果分别为93.3%和89.1%。

+   LAMBADA数据集评估模型在找到遥远依赖和猜测句子最后一个词方面的表现。GPT-2将语言模型的准确率从19%提高到52.66%，并将困惑度从99.8降低到8.6。它在句子的有效延续方面表现更好，但在有效的最终词方面表现不佳。通过添加停止过滤器，它的表现得到了4%的改善。

+   通过评估系统在文本中解决歧义的能力，Winograd Schema挑战旨在衡量其常识思维能力。GPT-2的准确率提高了7%，达到了70.70%。

+   CoQA数据集包括来自几个领域的论文，这些领域自然地交换问题和答案。这项练习衡量了一个人的阅读理解能力，以及他们基于先前对话回答问题的能力。GPT-2在涉及阅读理解的零-shot任务上与训练数据中的127,000多个问题-答案对匹配或超过了4个基线中的3个的结果。

总的来说，根据GPT-2的说法，语言模型在零样本情况下理解任务并在许多任务上超越了最先进技术的能力得到了改善，这是通过在更大的数据集上进行训练并使用更多参数实现的。该论文声称，随着模型容量的增加，性能呈对数线性增长。

![](images/Figure-9.2.jpg)

**图9.2：** *GPT-2在CBT数据集中的表现

[**来源：** GPT-2论文]*

此外，当参数数量增加时，语言模型困惑度的下降并没有接近饱和点。WebText数据集确实使GPT-2欠拟合，也许更长的训练会进一步降低困惑度。根据研究，GPT-2模型大小并不是最大的，更大的语言模型将有助于人们通过减少混淆来理解自然语言。

![](images/Figure-9.3.jpg)

**图9.3：** *GPT-2在Winograd Schema Challenge中的表现

[**来源：** GPT-2论文]*

要了解GPT-2的更多技术方面，您可以参考- 语言模型是无监督多任务学习者- **https://tinyurl.com/3x7b74n9**

# [GPT-3的介绍](toc.xhtml#s80a)

**发布日期：** 2020年5月28日

在GPT-2推出一年后，openAI推出了GPT系列的另一个更新和先进版本GPT-3，“语言模型是少样本学习者”。Open AI创建了拥有1750亿参数的GPT-3模型，旨在创建极其强大和有效的语言模型，只需要少量训练和少量演示即可理解任务并执行。这个模型的参数比GPT-2多100倍，比微软强大的Turing NLG语言模型多10倍。由于它训练的参数和庞大的数据集，GPT-3在零样本和少样本设置下在下游NLP任务上表现良好。它可以写出难以区分是否由人产生的文章，这要归功于它的巨大容量。它还可以完成从未明确教授的即时任务，比如加减数字，生成SQL查询和代码，解码单词的句子，根据自然语言中的任务描述编写React和JavaScript代码等。

# [基础框架](toc.xhtml#s81a)

大型语言模型通过训练的文本数据获得了模式检测和其他能力。语言模型在学习预测给定上下文单词的下一个单词的核心任务时，开始识别数据中的模式，这有助于它们减少语言建模任务的损失。最终，当转移零次任务时，模型从这种技能中受益。语言模型将实例的模式与它以前学到的类似数据的模式进行比较，并利用这些知识来执行任务，当给出一些示例和/或需要完成的任务描述时。这是巨大语言模型的一个强大能力，随着模型参数数量的增加而变得更强大。

少次、一次和零次设置是零次任务转移的专门示例，正如之前所述。在少次配置中，将工作描述和尽可能多的示例提供给模型的上下文窗口。在一次设置中，向模型提供一个示例，而在零次设置中则不提供任何示例。随着容量的增加，模型的少次、一次和零次能力都得到了提高。

！[](images/Figure-9.4.jpg)

**图9.4：** *代表训练期间上下文学习机制的图像

[**来源：**GPT-3论文]*

使用了五个不同的语料库来训练GPT-3，每个都有特定的权重。使用了高质量的数据集来训练模型，并且经常进行抽样。Common Crawl、WebText2、Books1、Books2和Wikipedia是使用的五个数据集，其中包括大部分文本和上下文数据的用例模式。

# [模型规格](toc.xhtml#s82a)

与GPT-2一样，该模型首先使用了transformer基础的GPT模型，但这个版本与GPT-2有一些重大区别，如下所述：

+   GPT-3已经在3种不同的上下文学习中进行了评估，而不是传统的零、一和少次学习技术。

+   GPT-3有96层，每层有96个注意头。

+   GPT-3的词嵌入大小从GPT-2的1600增加到12888。

+   上下文窗口大小从GPT-2的1024个标记增加到GPT-3的2048个标记。

+   Adam优化器使用β_1=0.9，β_2=0.95和ε= 10^(-8)。

+   交替使用了密集和局部带状稀疏的注意模式。

# [评估](toc.xhtml#s83a)

使用了各种语言建模和自然语言处理数据集来测试GPT-3。在少次或零次情况下，GPT-3超越了像LAMBADA和Penn Tree Bank这样的语言建模数据集的尖端方法。虽然它无法超越其他数据集的最新技术，但它确实提高了零次最新技术的性能。在诸如闭卷问题回答、模式解析、翻译等NLP任务中，GPT-3再次表现良好，经常超越或接近调整良好的模型。

！[](images/Figure-9.5.jpg)

**图9.5：** *执行任务的四种语言模型方法

[**来源：**GPT-3论文]*

对于大多数任务，该模型在少样本设置中的表现优于单样本和零样本设置。使用了各种语言建模和自然语言处理数据集来测试GPT-3。在少样本或零样本情况下，GPT-3的表现优于LAMBADA和Penn Tree Bank等语言建模数据集的尖端方法。虽然它无法超越其他数据集的最新技术水平，但它确实提高了零样本技术水平。在诸如闭卷问题回答、模式解析、翻译等NLP任务中，GPT-3再次表现良好，经常优于或接近调整良好的模型。对于CoQA基准测试，在零样本设置中为81.5 F1，在单样本设置中为84.0 F1，在少样本设置中为85.0 F1，而经过精调的SOTA达到了90.7 F1。在TriviaQA基准测试中，零样本设置分别为64.3％，68.0％，71.2％的准确率，在单样本设置和少样本设置中分别为68.0％，优于现有技术水平（68.0％）3.2％。在LAMBADA数据集上，零样本设置分别为76.2％，72.5％，86.4％的准确率，在单样本设置和少样本设置中分别为68.0％，优于现有技术水平（68.0％）18.0％。除了在传统的NLP任务上进行评估外，该模型还在更多的人工任务上进行了评估，例如添加数字、解密单词、创建新闻文章、学习和利用新术语等。对于这些任务，该模型在少样本选项中的表现优于单样本和零样本设置，性能随着参数数量的增加而提高。

要了解GPT-3的更多技术方面，您可以参考- 语言模型是少样本学习者- **https://tinyurl.com/4ym9tehp**

# GPT-3的API开发

2020年6月，openAI发布了他们的API，提供了一个通用的“文本输入，文本输出”的接口，允许用户在基本上任何英语语言工作上尝试它，与大多数为单一用例开发的人工智能系统形成对比。现在可以请求在产品中使用API的许可，创建全新的应用程序，或协助研究这项技术的优势和劣势。

当给定任何文本提示时，API将尝试匹配您提供的模式，并提供文本完成。它可以通过提供您想要完成的一些样本来“编程”它；通常成功程度取决于任务的难度。API还可以通过从用户或标记者提供的人类输入学习，或者通过训练您提供的数据集（小或大）来提高某些任务的性能。

2020年9月，GPT-3与微软整合，独家授权GPT-3，使我们能够利用其技术创新来开发和提供先进的人工智能解决方案，为我们的客户创造新的潜在人工智能解决方案。

![](images/Figure-9.6.jpg)

**图9.6：** *InstructGPT模型或GPT 3.5中输入馈送的过程

[**来源：** InstructGPT论文]*

2021年底，OpenAI最终在指定国家的公共空间为所有用户提供了整个GPT-3及其API，并提供了改进的Playground，这使得使用我们的模型进行原型设计变得容易，一个包含数十个提示的示例库，以帮助开发人员入门，以及Codex，一个将自然语言转换为代码的新模型。

# GPT-3.5，InstructGPT的介绍

大型语言模型过去面临的一个主要问题是，有时会出现未经过滤的人工智能生成的内容和响应，这些内容看起来不真实、有毒且与用户无关。因此，OpenAI集成了一个带有人类反馈的微调，这有助于满足各种任务。这种经过微调的监督模型是通过人类反馈的强化学习训练的，被称为InstructGPT。

# [基础框架](toc.xhtml#s86a)

在InstructGPT中，标注者展示了预期行为的示例。这些人类提示包括生成、问答、对话、摘要、提取等自然语言任务，并且主要建立在英语（96％）上。几乎有40名承包商为人类反馈做出了贡献，大约73％的训练标注者之间进行了协同合作。

# [模型规格](toc.xhtml#s87a)

在InstructGPT的训练部分，标注者被指示使用3种提示，包括1. 参与一些任意任务 2. 多个指令和多个查询 3. 关于来自等待用户的随机观众的某些相应解决方案。训练机制被分开，以训练3种不同的训练模型结构，在SFT模型中，数据集是通过标注者演示进行训练的，同样也是通过奖励模型进行调整，并且数据集是根据先前模型输出的排名进行人类解释；而PPO模型则完全在没有人类干预的情况下进行微调。

**监督微调（SFT）：**在这个模型中，标签数据已经在微调机制中进行了16个时期的训练，使用余弦衰减率和残差丢失率0.2。

**奖励建模（RM）：**该模型已经训练好输入提示响应并获得标量响应。奖励的差异代表了一个响应被人类标签优先于另一个的对数几率。在这个结构中，他们已经训练了大约60亿个RM中的175B个。

**强化学习（RL）：**在一个类似赌徒的环境中提出了一个随机的消费者请求，并期望得到一个响应。它根据提示和答案生成奖励，由奖励模型定义，并结束该情节。为了防止奖励模型过度优化，他们还在每个标记处应用了来自SFT模型的标记KL惩罚。RM被用来初始化值函数。这些模型被称为“PPO”。

# [结果](toc.xhtml#s88a)

在探索发展现有NLP模型生态系统的更多领域方面，OpenAI提出了另一个令人着迷的发展，可以解决填充问题。OpenAI希望允许它们在不影响其从左到右正常生成代码的能力的情况下获得出色的文本填充。团队对转换训练数据的方法非常简单：他们只是将页面中心的随机文本部分转移到页面末尾。

团队表明，因果AR LLM可以学习填写文档的中间部分，并通过在多个目标和数据集上联合训练模型，处理相关任务，如推断导入模块、编写文档字符串和完成函数。总的来说，FIM模型可能保留与标准AR模型相同的从左到右文本容量，同时学会更有效地填写中心部分-这是所提出的训练数据转换技术的优势，为FIM提供了免费的。

在175B参数（达芬奇模型，最新更新）的情况下，InstructGPT模型比GPT-3更受人类指示的偏好超过85％的时间，并且在人类指示下比GPT-3更受欢迎的时间达71％。这意味着几乎有3/4的时间，标注者更喜欢InstructGPT而不是经过条件良好的GPT-3。即使是提示工程也无法击败InstructGPT。

![](images/Figure-9.7.jpg)

**图9.7：** *对于预训练了100B标记的模型的最终快照进行评估，没有使用FIM，然后使用FIM进行了25B（a行）和50B（b行）标记的微调。

[**来源：** InstructGPT论文]*

要了解更多关于GPT-3.5的技术方面，您可以参考- 使用人类反馈训练语言模型遵循指示- **https://tinyurl.com/yny5uux2**

# [GPT-3模型API标记的成本降低](toc.xhtml#s89a)

随着时间的推移和改进，chatGPT的订阅模型也在GPT-3系列中见证了价格的降低，特别是在达芬奇模型和库里模型中，成本降低了66% - 从每千个标记的$0.06和$0.006分别更新为每千个标记的$0.02和$0.002。OpenAI团队不断取得了使模型更加高效和可持续以导致价格降低的惊人进展。

# [Whisper简介](toc.xhtml#s90a)

在开发更好的NLP领域生态系统的过程中，OpenAI推出了另一个Whisper，这是一个自动语音识别模型，它经过了680,000小时的多语言和多任务监督网络爬取的训练。该模型旨在解决背景噪音、数据干扰的问题，并使其更接近真实估计。该模型还涵盖了一系列多语言任务，并提供转录。多语言部分有98种不同的语言数据用于训练目的。

# [Whisper概述](toc.xhtml#s91a)

训练数据集由多样化的音频剪辑组成，更倾向于真实生活数据，以利用更多人类方面的解释。Whisper AI建立在以30秒声音波块的mel频谱图为基础，并将其传递到编码器-解码器Transformer中以预测相关的文本标题，特殊标记指示单一模型执行任务，如语言识别，短语级时间戳，多语言语音转录和英语语音翻译，这些都与特殊标记结合在一起。它有9种不同的模型大小，根据大小和能力而定。

![](images/Figure-9.8.jpg)

**图9.8：** *文本处理的训练流程

[**来源：** Whisper论文]*

其他当前的方法通常利用更大但无监督的音频预训练数据集或更小、更紧密链接的音频文本训练数据集。Whisper并没有超越专注于LibriSpeech性能的模型，LibriSpeech是语音识别中非常有竞争力的基准，因为它是在广泛而多样的数据集上训练的，而不是针对特定数据集进行了定制。

![](images/Figure-9.9.jpg)

**图9.9：** *Whisper的编码器-解码器模型

[**来源：** Whisper论文]*

然而，与其他可比模型相比，它的零-shot性能在各种不同数据集上表现出的可靠性更高，且出错率减少了50%。

Whisper的性能接近专业人类转录员的水平。该模型已经通过Whisper转录的Kincaid46数据集的25个录音的WER分布进行了测试，与一个计算机辅助人工转录服务的4个商业ASR系统和4个人工转录服务的错误范围似乎几乎相似。

要了解更多关于Whisper的技术方面，您可以参考- 通过大规模弱监督实现鲁棒语音识别**-** **https://tinyurl.com/359y5t5y**

![](images/Figure-9.10.jpg)

**图9.10：** *箱线图上叠加了表示单个录音的WER的点，每个箱子上注释了25个录音的聚合WER

[**来源：** Whisper论文]*

# [ChatGPT简介](toc.xhtml#s92a)

在重新定义和扩展现有模型在各种NLP任务周围的结构后，OpenAI构建了他们的GPT-3.5（被称为GPT 3.5的兄弟模型）系列，成为一个可以满足复杂NLP解决方案的对话式智能AI NLP系统。随着时间的推移，GPT 3.5在功能和优化方面有所改进。OpenAI推出了一系列GPT 3.5模型版本，使用户能够更清晰地根据其用例利用和实验模型。

1.  **Turbo：** ChatGPT的基础模型系列是Turbo。与Davinci模型系列相比，它在完成方面表现出色，同时针对对话式聊天输入和输出进行了优化。API中的Turbo模型系列应该能够很好地适用于ChatGPT中可以高效处理的每种用例。像ChatGPT一样，第一个经常获得模型升级的模型系列是Turbo系列。

**特点：** 对话和文本生成

**最大请求可达到：** 4,096个标记

**训练日期：** 截至2021年9月

1.  **DaVinci：** Davinci模型系列是最有竞争力的，可以完成其他模型（Ada、Curie和Babbage）可以完成的任何工作，通常需要更少的训练。Davinci将为需要深入理解文本的任务产生最佳结果，例如为特定受众进行摘要和创作原创内容。由于这些扩展功能需要更多的计算资源，Davinci每个API请求的成本更高，速度也比其他模型慢。

理解文本目的是Davinci擅长的另一个领域。Davinci擅长推断各种逻辑难题的解决方案和阐明人物动机。一些最困难的因果关系人工智能难题已经被Davinci解决。

**特点：** 复杂意图，因果关系，面向受众的摘要

**最大请求可达到：** 4,000个标记

**训练日期：** 截至2021年6月

1.  **Curie：** Curie非常强大，但速度很快。虽然Curie擅长许多复杂任务，如情感分类和摘要，但Davinci更擅长处理复杂文本。作为通用聊天机器人，Curie在进行问答和回答查询方面也相当擅长。

**特点：** 语言翻译，复杂分类，文本情感，摘要

1.  巴贝奇：巴贝奇能够进行简单的分类和其他基本任务。在使用语义搜索评估文档与搜索查询的匹配程度时，它也非常有能力。

**特点：** 中等分类，语义搜索分类

1.  **Ada：** Ada通常是最快的模型，能够完成不需要太多细节的工作，比如文本解析、地址校正和某些类型的分类任务。通过添加额外的上下文，Ada的性能通常可以得到提升。

**特点：** 解析文本，简单分类，地址校正，关键词

ChatGPT已经被制定为符合许多人类重视的原型和规则。它在2022年初进行了训练。ChatGPT的基本版本使用了GPT 3.5-turbo API作为后端模型，比许多其他GPT 3.5系列模型更便宜，使其更受用户欢迎。

# [时间线摘要](toc.xhtml#s93a)

| **日期** | **里程碑** |

| 2018年6月11日 | GPT-1在OpenAI博客上宣布。|

| 2019年2月14日 | GPT-2在OpenAI博客上宣布。|

| 2020年5月28日 | GPT-3初稿论文发布到arXiv。|

| 2020年6月11日 | GPT-3 API私人测试版。|

| 2020年9月22日 | GPT-3授权给微软。|

| 2021年11月18日 | GPT-3 API向公众开放。|

| 2022年1月27日 | InstructGPT作为text-davinci-002发布，现在被称为GPT-3.5。InstructGPT初稿论文于2022年3月发布。|

| 2022年7月28日 | 在arXiv上发表了探索数据最优模型的论文。|

| 2022年9月1日 | GPT-3模型的价格为davinci和curie模型降低了66%。|

| 2022年9月21日 | Whisper（语音识别）在OpenAI博客上宣布。|

| 2022年11月28日 | GPT-3.5扩展到text-davinci-003，通过电子邮件宣布：写作质量更高。处理更复杂的指令。3.更擅长生成更长的内容。 |

| 2022年11月30日 | 在OpenAI博客上宣布了ChatGPT。 |

| 2023年2月1日 | ChatGPT的月活跃用户达到1亿（通过瑞银报告）。 |

| 2023年3月1日 | 在OpenAI博客上宣布了ChatGPT API。 |

*时间表是从Alan D. Thompson博士的GPT博客中提取的

# [需要记住的要点](toc.xhtml#s94a)

+   GPT-1于2018年6月推出，它是通过对多样化的未标记文本语料库数据进行训练，以开发强大的自然语言理解基础，并进行精细调整和生成式预训练。

+   研究表明，预训练如何提高了模型在各种自然语言处理任务上的零-shot性能，包括情感分析、问答和模式解析。

+   GPT-1在12项任务中有9项表现优于专门训练的监督式最先进模型。

+   GPT-1模型再次在这些任务上表现出比以前最好的结果显着更好，Story Cloze的增益高达8.9％，整体上RACE的增益为5.7％。

+   GPT模型的下一个版本是在2019年推出的，GPT-2，它是在更大的数据集上进行训练，并丰富了更多的参数，以使这个模型更好。

+   GPT-2中提到的零-shot任务转移的基础是任务调节。

+   GPT 2在转移零-shot任务方面的能力令人着迷。

+   作为零-shot任务转移的特例，当根本没有给出任何示例，并且指示模型执行任务时，零-shot学习就会发生。

# 加入我们书籍的Discord空间

加入书籍的Discord Workspace，获取最新更新、优惠、世界各地的技术动态、新发布和与作者的交流：

[**https://discord.bpbonline.com**](https://discord.bpbonline.com)

![](images/dis.jpg)
