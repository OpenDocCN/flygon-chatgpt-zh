- en: '[CHAPTER 9](toc.xhtml#c09)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[`predictive-powers:` GPT Implementation Framework for Java](toc.xhtml#c09)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Introduction](toc.xhtml#s460a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we explored `LangChain`, a GPT implementation framework
    for Python. In this chapter, we will explore `predictive-powers`, a software library
    that allows Java developers to quickly build generative AI[¹](#ftn1a)-based solutions.
    Understanding this library should be considered critical for a couple of reasons.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, as Java remains a cornerstone in enterprise-level application development,
    integrating generative AI capabilities via this library significantly broadens
    the scope of what your Java applications can achieve. Imagine automating customer
    service inquiries, generating dynamic content, or even building intelligent data
    analytics tools, all within the comfort and familiarity of the Java ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, the ease of implementation offered by this library democratizes access
    to advanced AI functionalities, making it particularly appealing for both seasoned
    Java developers and newcomers alike. If you’re interested in leveraging the power
    of GPT models but find the AI landscape daunting, this chapter serves as a navigational
    aid.
  prefs: []
  type: TYPE_NORMAL
- en: After a quick comparison between Java and Python, this chapter will describe
    the library and its features.
  prefs: []
  type: TYPE_NORMAL
- en: The first section unveils the key features of the library. You will learn about
    the underlying concepts such as API clients, endpoints, and services, with examples
    provided for enhanced comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: We then embark on a journey to showcase the practical implementation of the
    library via an autonomous agent called the ‘Essay Writer’. This use case aims
    to illustrate the versatility of the library and its application to real-world
    tasks, thereby equipping you with actionable insights that can be adapted to various
    other applications.
  prefs: []
  type: TYPE_NORMAL
- en: Following this, the chapter delves into the architectural patterns involved
    in implementing the Essay Writer, providing an exemplification of what has been
    presented in *[Chapter 4](c04.xhtml)*. Each section explores how the `predictive-powers`
    services are woven into the agent’s architecture, providing you with a roadmap
    for building similar applications.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we delve into a code walkthrough. This section will be necessarily
    concise and will only highlight some of the implementation details. Please note
    that while we provide snippets of code for context, you are encouraged to visit
    the `predictive-powers` GitHub repository [10] if you are interested in exploring
    the complete commented code. While having a foundational understanding of the
    Java language can indeed foster a deeper comprehension of the code examples presented
    in this chapter, it is not a prerequisite. Readers unfamiliar with Java can still
    grasp the ease with which the library allows for the application of the concepts
    discussed in earlier sections. However, it is advisable for readers to have a
    basic acquaintance with software development principles, as not every technical
    term will be defined in depth.
  prefs: []
  type: TYPE_NORMAL
- en: '[Structure](toc.xhtml#s461a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Quick comparison of Java and Python programming languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of the `predictive-powers` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Understanding essential concepts: API clients, endpoints, and services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predictive-powers` use case: implementation of the ‘Essay Writer’ autonomous
    agent'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ‘Essay Writer’ architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ‘Essay Writer’ code Walkthrough
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Java vs. Python](toc.xhtml#s462a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python and Java, each holding a formidable position in the technology sector,
    cater distinctively to different professional niches, setting a rich ground for
    leveraging GPT in diverse applications.
  prefs: []
  type: TYPE_NORMAL
- en: Renowned for its simplicity and readability, Python has evolved as a fundamental
    tool in the data science sector. The language’s user-friendly nature, combined
    with a rich repository of libraries, makes it a favored choice for data analysis
    and visualization, a characteristic that resonates well with professionals venturing
    into data science and artificial intelligence fields.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, Java remains a pillar in the enterprise application development
    landscape, with a reputation built on stability, built-in security features, and
    remarkable scalability to sustain large infrastructure projects. Its versatility
    extends further; Java can seamlessly operate across various environments such
    as enterprise servers, desktops, and notably, Android smartphones. This wide-ranging
    applicability makes it a preferred choice for developers aiming for adaptability
    and robust performance.
  prefs: []
  type: TYPE_NORMAL
- en: In presenting both Python and Java frameworks, this book aims at enabling a
    nuanced understanding of the available technologies for potential GPT integration
    in applications, thereby facilitating a more informed approach for developers
    from different spheres.
  prefs: []
  type: TYPE_NORMAL
- en: '[The `predictive-powers` Library](toc.xhtml#s463a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `predictive-powers` library is designed to simplify the integration of generative
    AI capabilities for Java developers. As an Apache-2.0 licensed resource, it is
    freely available on GitHub. While this section provides illustrative code snippets,
    to truly delve into its extensive functionality, we encourage a visit to the `predictive-powers`
    GitHub repository for comprehensive code and working examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the key features of the `predictive-powers` library:'
  prefs: []
  type: TYPE_NORMAL
- en: It offers low-level access to OpenAI and Hugging Face Hosted Inference APIs.
    This functionality enables developers to directly interact with these APIs, if
    they choose.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The library adds an abstraction layer for generative AI capabilities, aligning
    them with the CapabilityGPT framework exposed in *[Chapter 2](c02.xhtml)*. This
    design decision ensures compatibility with various capability providers, mitigating
    the risk of vendor lock-in. As we will illustrate, the library makes switching
    between providers trivial, allowing the developers to test different providers
    and upgrade to new language models once they are available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It hosts an in-memory vector database crucial for abilities such as semantic
    search[²](#ftn2a), information extraction, and question answering. Upcoming versions
    will allow developers to utilize any existing vector database[³](#ftn3a).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The library includes methods to conveniently read textual content from various
    sources, including web pages and files in formats such as MS Office, PDF, HTML,
    etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Components](toc.xhtml#s464a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here’s an explanation of the main components you need to familiarize yourself
    with to use the `predictive-powers` library. These are also depicted in *[Figure
    9.1](#fig9_1)*, which shows their interrelationships:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/Figure-9.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**[Figure 9.1](#fig9_1):** Essential components of the `predictive-powers`
    library and their relationships'
  prefs: []
  type: TYPE_NORMAL
- en: '**API clients**'
  prefs: []
  type: TYPE_NORMAL
- en: API clients are the lowest-level components of the `predictive-powers` library,
    facilitating direct API calls to service providers. For example, developers might
    choose to directly access the OpenAI API via an `OpenAiClient` instantiation and
    the subsequent invocation of its methods.
  prefs: []
  type: TYPE_NORMAL
- en: The API clients also offer secure access to API keys (required for service access)
    and automated management of temporary server unavailability scenarios, such as
    request flooding.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, API clients offer developers the liberty of direct API calls coupled
    with robust and efficient development via boilerplate code provision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following example of API client usage; the code instantiates an
    `OpenAiClient` and then uses it to execute a very simple prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '`import io.github.mzattera.predictivepowers.openai.client.OpenAiClient;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`import io.github.mzattera.predictivepowers.openai.client.completions.CompletionsRequest;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`import io.github.mzattera.predictivepowers.openai.client.completions.CompletionsResponse;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public class OpenAiClientExample {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public static void main(String[] args) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Retrieve API key from OS`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// environment variable OpenAiClient.OS_ENV_VAR_NAME`'
  prefs: []
  type: TYPE_NORMAL
- en: '`try (OpenAiClient client = new OpenAiClient()) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '``// Complete a sentence; refer to`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// https://platform.openai.com/docs/api-reference/completions`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// for details`'
  prefs: []
  type: TYPE_NORMAL
- en: '`CompletionsRequest req = CompletionsRequest.builder()`'
  prefs: []
  type: TYPE_NORMAL
- en: '`.model(“text-davinci-003”)`'
  prefs: []
  type: TYPE_NORMAL
- en: '`.maxTokens(50)`'
  prefs: []
  type: TYPE_NORMAL
- en: '`.prompt(“Alan Turing was”)`'
  prefs: []
  type: TYPE_NORMAL
- en: '`.build();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`CompletionsResponse resp = client.createCompletion(req);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Output result`'
  prefs: []
  type: TYPE_NORMAL
- en: '`System.out.println(resp.getChoices().get(0).getText());`'
  prefs: []
  type: TYPE_NORMAL
- en: '``} // Closes client`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: 'This will generate an output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`a British mathematician, computer scientist, logician, cryptanalyst, philosopher,
    and theoretical biologist who was highly influential in the development of theoretical
    computer science and artificial intelligence.`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Endpoints and Services**'
  prefs: []
  type: TYPE_NORMAL
- en: An endpoint is a capability provider, meaning it employs an API client to render
    different capabilities in the form of services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code illustrates the creation of an `AiEndpoint`, which provides
    access to generative AI capabilities, both for OpenAI and Hugging Face providers[⁴](#ftn4a):'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Builds a Hugging Face endpoint.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// API key is retrieved from OS environment.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`AiEndpoint endpoint = new HuggingFaceEndpoint();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Builds an OpenAI endpoint from an existing API client`'
  prefs: []
  type: TYPE_NORMAL
- en: '`OpenAiClient cli = new OpenAiClient();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`AiEndpoint endpoint = new OpenAiEndpoint(cli);`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once an endpoint is created, it enables access to services. These are high-level
    generative AI capabilities, akin to those described in the CapabilityGPT framework.
    Current services include:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**ModelService**`: Provides access to model metadata such as list of models,
    model context size, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**CompletionService**`: Performs text completion by executing provided text
    prompts. This is the most flexible service since we can instruct it to execute
    different tasks by providing the right prompts, as discussed in *[Chapter 5](c05.xhtml)*.
    With proper instructions, this service can provide capabilities such as **Assessment**,
    **Classification**, **Creation**, **Information Extraction**, **Matchmaking**,
    **Summarization**, **Transformation**, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**ChatService**`: Handles conversations between the user and an agent, managing
    the agent’s personality and the conversation history. This would correspond to
    the **Communication** capability. Also notice that `ChatService` can provide all
    the capabilities that `CompletionService` exposes, as prompt execution can be
    seen as a conversation with a single exchange, with the user starting the conversation
    by providing the prompt and the agent responding to it, thus executing it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**EmbeddingService**`: Offers text embeddings[²](#ftn2a) and similarity calculation
    features, which are essential for providing the **Semantic Search** capability
    in the CapabilityGPT framework.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**QuestionAnsweringService**`: Maps directly into the **Question Answering**
    capability of the CapabilityGPT framework by answering questions using a user-provided
    context.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**QuestionExtractionService**`: Extracts different kinds of questions from
    a text (for example, true/false questions, multiple choice quizzes, etc.). This
    is an example of the **Information Extraction** capability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**ImageGenerationService**`: Generates images using either OpenAI (DALL-E
    3[⁵](#ftn5a)) or Hugging Face (Openjourney[⁶](#ftn6a)). This is another example
    of the **Creation** capability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**SearchService**`: Searches the Internet for data. This is an example of
    an external tool that can be used as a building block for agents[⁷](#ftn7a).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following example showcases the use of `CompletionService` to complete
    a sentence. After creating an endpoint, the code obtains an instance of a `CompletionService`
    from it, which is used to complete a simple prompt. Note how the service abstraction
    allows for changing service providers (OpenAI or Hugging Face) with a single line
    of code modification:'
  prefs: []
  type: TYPE_NORMAL
- en: '`import io.github.mzattera.predictivepowers.AiEndpoint;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`import io.github.mzattera.predictivepowers.huggingface.endpoint.HuggingFaceEndpoint;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`import io.github.mzattera.predictivepowers.openai.endpoint.OpenAiEndpoint;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`import io.github.mzattera.predictivepowers.services.CompletionService;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public class CompletionExample {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public static void main(String[] args) throws Exception {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Uncomment the below to use OpenAI`'
  prefs: []
  type: TYPE_NORMAL
- en: '`AiEndpoint endpoint = new OpenAiEndpoint();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Uncomment the below to use Hugging Face`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// AiEndpoint endpoint = new HuggingFaceEndpoint();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`try (endpoint) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`CompletionService cs = endpoint.getCompletionService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`System.out.println(cs.complete(“Alan Turing was”).getText());`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge Base**'
  prefs: []
  type: TYPE_NORMAL
- en: A knowledge base in the context of the `predictive-powers` library is an in-memory
    vector database housing text embeddings[⁸](#ftn8a). Each embedding can possess
    an array of properties encapsulated as a `Map`. The knowledge base presents methods
    for semantic search based on embedding similarity and other filtering criteria.
    It can be partitioned into domains to allow separate searches and optimize performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[`predictive-powers` Use Case](toc.xhtml#s465a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will guide you through the implementation of an autonomous
    agent called the ‘Essay Writer’ (‘***Writer***’ for short), whose goal is to produce
    essays about different topics. The Writer is designed to take a short textual
    description of an essay content, search the Internet for relevant information,
    download and collate it, generating a complete essay.
  prefs: []
  type: TYPE_NORMAL
- en: We will provide code snippets to demonstrate how the capabilities of the CapabilityGPT
    framework are utilized to build the agent. For the full code of the agent, you
    can refer to the `predictive-powers` GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: '**Architecture**'
  prefs: []
  type: TYPE_NORMAL
- en: This section provides a detailed explanation of the architecture employed in
    implementing the Writer, using the three-layer approach that should be familiar
    from *[Chapter 4](c04.xhtml)*[⁹](#ftn9a). This architecture is designed to be
    extensible, allowing it to handle more complex scenarios. However, the fundamental
    layered approach will remain consistent, utilizing `predictive-powers` services
    to create a modular architecture for the application and AI layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/Figure-9.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**[Figure 9.2](#fig9_2):** Essay Writer – Architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '**User Experience Layer**'
  prefs: []
  type: TYPE_NORMAL
- en: In our example, to maintain simplicity, users will interact with the Writer
    solely via the computer console. The Writer can be launched with various command-line
    options to execute different steps in the essay writing task (please refer to
    the full application code for details). The output generated will consist of both
    JSON[^(10)](#ftn10a) and plain text files that can be inspected by using any text
    file viewer.
  prefs: []
  type: TYPE_NORMAL
- en: '**Application Layer**'
  prefs: []
  type: TYPE_NORMAL
- en: At the application layer, the orchestration agent responds to user commands
    by executing the corresponding application flow and properly coordinating different
    `predictive-powers` services. Later in this chapter, we will delve into the detailed
    description of these application flows.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, an information retrieval component is also present. It is responsible
    for searching the Internet for relevant content that will be used to create the
    essay:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**SearchService**`: The `SearchService` performs web searches based on the
    queries generated by the `ChatService` (see below). It returns a list of links
    to relevant web pages for the orchestration agent to download and utilize.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**GoogleEndpoint**`: This component facilitates the integration with Google’s
    Custom Search JSON API to bolster the functionality of the `SearchService`. It
    allows users to craft custom search engines, underpinned by Google’s robust search
    capabilities. This endpoint can then be directed towards these engines. It empowers
    users to construct potent search utilities, capable of restricting searches to
    specific websites, filtering out mature content, confining searches to particular
    regions, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AI Layer**'
  prefs: []
  type: TYPE_NORMAL
- en: The AI layer is where CapabilityGPT capabilities are implemented and exposed
    as `predictive-powers` services. Here, the endpoints connect to the relevant service
    providers to execute the tasks required by the orchestration agent.
  prefs: []
  type: TYPE_NORMAL
- en: '`**ChatService**`: This service will provide the creation capabilities needed
    to build the essay structure. It will start from its draft description, create
    search queries, search relevant materials from the web, and write each section
    of the essay by summarizing and rewriting the knowledge gathered from the Internet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**EmbeddingService**`: This service is employed to embed the content downloaded
    from the Internet, enabling it to be stored in the knowledge base to power semantic
    search.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**OpenAiEndpoint**`: This endpoint connects to the required OpenAI models[^(11)](#ftn11a).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**KnowledgeBase**`: This provides an in-memory vector database to store the
    downloaded content and retrieve it when needed to write different sections of
    the essay. Additionally, the `KnowledgeBase` can be persisted as a single file
    on the user’s PC, allowing users to regenerate the essay without re-downloading
    the relevant web pages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to remark that the services at both layers are independent of
    the endpoints and knowledge base used. This abstraction ensures that the application
    layer remains decoupled from the specific implementations provided by each service
    provider. During development, this means the software engineers can easily test
    different service providers and language models, to decide which one is more suitable
    for the solution being built.
  prefs: []
  type: TYPE_NORMAL
- en: '**Workflow**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The workflow diagram, as shown in *[Figure 9.3](#fig9_3)*, illustrates the
    steps involved in transforming a user’s essay draft into the final essay produced
    by the Writer:'
  prefs: []
  type: TYPE_NORMAL
- en: A user provides a textual description of the essay content.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Writer generates the essay structure (chapters and sections) as a JSON file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Writer generates Google queries to search for information suitable to populate
    each section of the essay.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Writer then executes each query and compiles the list of relevant web page
    links, as returned by the Google search engine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Writer downloads the content of each link and creates corresponding embeddings,
    which are stored in the `KnowledgeBase`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each section of the essay, the Writer uses semantic search to retrieve relevant
    information from the knowledge base.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the Writer uses this information to produce each section of the essay,
    resulting in a single text file output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](images/Figure-9.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**[Figure 9.3](#fig9_3):** The Essay Writer – Workflow'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s examine each step in detail and explore the CapabilityGPT framework’s
    capabilities utilized at each stage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process begins with the user providing a textual description of the essay,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Write an essay about the Italian city of Padua.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The first chapter describes the geography and demographics of the city, its
    economics, and its history from proto-history to the modern age.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Additionally, have a section for the famous people who lived in Padua.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The second chapter focuses on traditions and folklore, including traditional
    events and festivals, food and wine, and other relevant topics.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The last chapter is a collection of notable sights, with separate sections
    for each attraction, describing the places of interest and visitors’ experiences.`'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s important to note that the Writer understands the essay as consisting
    of chapters divided into sections. Although more complex structures are possible,
    for simplicity, we will focus on this format. The essay structure is initially
    generated using ChatGPT generation capabilities, creating chapters and sections
    based on the provided description. The resulting structure is saved in JSON format
    for further processing. Here’s an example structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`{`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title”: “My Essay”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“description”: “Write an essay about the Italian city of Padua.\r\nThe first
    chapter describes the geography and demographics of the city, its economics, and
    its history from proto-history to the modern age.\r\nAdditionally, have a section
    for the famous people who lived in Padua.\r\nThe second chapter focuses on traditions
    and folklore, including traditional events and festivals, food and wine, and other
    relevant topics.\r\nThe last chapter is a collection of notable sights, with separate
    sections for each attraction, describing the places of interest and visitors’
    experiences.\r\n”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“chapters”: [`'
  prefs: []
  type: TYPE_NORMAL
- en: '`{`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“id”: “1”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title”: “Geography and Demographics”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“summary”: “This chapter provides an overview of the geography and demographics
    of the city of Padua. It explores the city’s location, climate, and natural features.
    Additionally, it delves into the population demographics, including the ethnic
    makeup, age distribution, and population growth over time.”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“sections”: [`'
  prefs: []
  type: TYPE_NORMAL
- en: '`{`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“id”: “1.1”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title”: “Economics”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“summary”: “This section explores the economic aspects of Padua, including
    its main industries, trade, and economic development. It highlights the city’s
    position as an economic hub and discusses the key sectors driving its economy.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`…`'
  prefs: []
  type: TYPE_NORMAL
- en: '`},`'
  prefs: []
  type: TYPE_NORMAL
- en: '`{`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“id”: “1.2”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title”: “History”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“summary”: “This section traces the history of Padua from its proto-historic
    origins to the modern age. It covers significant historical events, rulers, and
    cultural developments that have shaped the city’s identity over time.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`…`'
  prefs: []
  type: TYPE_NORMAL
- en: '`},`'
  prefs: []
  type: TYPE_NORMAL
- en: '`…`'
  prefs: []
  type: TYPE_NORMAL
- en: '`]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`},`'
  prefs: []
  type: TYPE_NORMAL
- en: '`…`'
  prefs: []
  type: TYPE_NORMAL
- en: '`]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: Note how ChatGPT enhances the description of each section, providing a more
    detailed content summary. In the “Notable Sights” section, the places of interest
    are automatically added without the need for prior listing, thanks to ChatGPT
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '`“id” : “3”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title” : “Notable Sights”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“summary” : “This chapter serves as a guide to the notable sights in Padua,
    highlighting the city’s architectural, historical, and cultural landmarks. Each
    section focuses on a specific attraction, providing a detailed description and
    capturing the visitors’ experience.”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“sections” : [`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“id” : “3.1”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title” : “Basilica di Sant’Antonio”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`…`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}, {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“id” : “3.2”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title” : “Prato della Valle”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`…`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}, {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“id” : “3.3”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title” : “Palazzo della Ragione”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`…`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}, {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“id” : “3.4”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“title” : “Scrovegni Chapel”,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`…`'
  prefs: []
  type: TYPE_NORMAL
- en: '`} ],`'
  prefs: []
  type: TYPE_NORMAL
- en: With the essay structure in place, the Writer needs to populate it with relevant
    information. Instead of relying solely on the model’s implicit knowledge, we want
    to fetch updated and relevant information from the Internet. To accomplish this,
    we generate Google searches for each section using ChatGPT text generation capabilities.
    This generates a short list of Google queries for each section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step involves leveraging a different capability of our framework:
    **Search**. The Essay Writer uses these generated Google queries to query the
    search engine and collect a list of relevant web page links.'
  prefs: []
  type: TYPE_NORMAL
- en: Once we have identified the relevant web pages, they are downloaded and stored
    in a database for semantic search. Semantic search will allow the Writer to search
    for text in the database that is semantically similar to the summary of a given
    section, thus retrieving those documents that are relevant to compile that section
    of the essay. To enable semantic search, the downloaded pages are encoded in a
    special way known as ‘embedding’; this encoding provides a numerical representation
    of the text that is easier for AI to process.
  prefs: []
  type: TYPE_NORMAL
- en: The `predictive-powers` library provides high-level methods to download web
    content, perform embedding, and store the data in an in-memory database (the `KnowledgeBase`),
    which is available as part of the library.
  prefs: []
  type: TYPE_NORMAL
- en: After downloading, embedding, and storing the relevant web pages, the Writer
    employs semantic search to fetch contextually relevant content for each section
    of the essay. These contextual pieces, referred to as the ‘context’ for each section,
    serve as the basis for generating the actual content of the sections. ChatGPT
    utilizes its **Summarization** and **Generation** capabilities to create the section
    content based on the provided context.
  prefs: []
  type: TYPE_NORMAL
- en: By following this workflow, the Writer autonomously generates an essay that
    incorporates up-to-date information from the web, producing a comprehensive and
    well-researched final output.
  prefs: []
  type: TYPE_NORMAL
- en: '[Code Walkthrough](toc.xhtml#s466a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we elucidate the workflow of the application that was outlined
    in previous sections, offering snippets of code to demonstrate how various tasks
    are performed. Should you wish to delve deeper into the full code for the Writer,
    it is always accessible in the `predictive-powers` GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: While showcasing the application code, we take the opportunity to list some
    of the prompts used. We challenge readers to try writing their own prompts following
    the guidelines in *[Chapter 5](c05.xhtml)* and see if and how the Writer’s skills
    improve.
  prefs: []
  type: TYPE_NORMAL
- en: Take note that the Writer is a multithreaded application for the sake of efficiency.
    The method `parallelExecution()` manages the simultaneous execution of multiple
    tasks, compiling all of their results into a single `List`. Throughout this chapter,
    we will showcase snippets of code for various tasks, while not focusing much on
    the required structure for multitasking.
  prefs: []
  type: TYPE_NORMAL
- en: The `Essay` class is an inner class utilized by the Writer to maintain the structure
    of the essay. It offers several methods that facilitate obtaining its nicely formatted
    contents in an organized manner. The Writer contains one instance of `Essay` in
    its `essay` field; as the program executes, the instance is gradually populated
    with data.
  prefs: []
  type: TYPE_NORMAL
- en: The orchestration of the application workflow happens within the `main()` method
    of the class. Here, the user input is processed, and the required tasks are executed.
    In short, the `main()` method implements the ‘Orchestration Agent’ component shown
    in our architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task in the workflow is to read the user-provided draft and establish
    the structure of the essay. For processing convenience, the structure is saved
    as a JSON file. The following code snippet demonstrates how this task is accomplished.
    It assumes that the essay draft has been stored in `essay.description` (this would
    have already been carried out by the `main()` method at this point). Notice how
    the code leverages GPT’s ability to return data in various formats, JSON in this
    instance. Java libraries dedicated to handling JSON serialization allow us to
    easily transform the returned data into an `Essay` instance using a single line
    of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`public void createStructure() throws JsonProcessingException {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`String description = essay.description;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`[…]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Instantiate a service to create the essay structure`'
  prefs: []
  type: TYPE_NORMAL
- en: '`OpenAiChatService chatSvc = openAi.getChatService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`chatSvc.setModel(COMPLETION_MODEL);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`chatSvc.setTemperature(40.0);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Set agent personality, instruct it to return JSON`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// and provide one example`'
  prefs: []
  type: TYPE_NORMAL
- en: '`chatSvc.setPersonality(`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“You are an assistant helping a writer to create the structure of an essay.
    The essay structure is composed of an array of chapters, each chapter containing
    an array of sections. Always return the structure using this JSON format; here
    is an example of the format:\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “{\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ \”chapters\”: [{\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  \”title\”: \”Title for first chapter\”,\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  \”summary\”: \”Summary of first chapter.\”,\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  \”sections\”: [{\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “    \”title\”: \”Title for first section of first chapter\”,\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “    \”summary\”: \”Summary of this section\”\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  },{\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “    \”title\”: \”Title for second section of first chapter\”,\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “    \”summary\”: \”Summary of this section\”\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  }]\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ }, {\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  \”title\”: \”Title for second chapter\”,\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  \”summary\”: \”Summary of second chapter.\”,\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  \”sections\”: [{\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “    \”title\”: \”Title for first section of second chapter\”,\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “    \”summary\”: \”Summary of this section\”\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  }, {\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “      \”title\”: \”Title for second section of second chapter\”,\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “    \”summary\”: \”Summary of this section\”\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “  }]\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ }]\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “}\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “Ensure that sections are not nested within other sections. Titles should
    not include section numbering or the words ‘Chapter’ or ‘Section’.”);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Invoke the agent to create the structure,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// using the draft in description`'
  prefs: []
  type: TYPE_NORMAL
- en: '`TextCompletion resp = chatSvc.complete(`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“You are tasked with creating the structure of a book based on the provided
    description. The book should consist of several chapters, each containing a title,
    a summary, and a list of sections. Each section should have a title and a summary.
    Ensure that sections are not nested within each other.\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “If possible, try to make the summaries of the chapters and sections at
    least 100 words long to provide substantial content for the book’s outline.\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “Think it through step by step and list all chapters and the sections they
    contain. Return the result using JSON format.\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “User Description: “ + description`'
  prefs: []
  type: TYPE_NORMAL
- en: '`);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Transform returned JSON into an Essay`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// which is then copied into the local instance.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Essay created = JSON_MAPPER.readValue(resp.getText(), Essay.class);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`essay.chapters = new ArrayList<>(created.chapters);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`[…]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: Following the creation of the structure, relevant data for writing the essay
    is sourced from the Internet. The following code snippet returns a list of `SearchResult`
    instances (links to web pages), which content can be used to compose the given
    section. These links are returned in a `Pair` structure, along with their corresponding
    rank, as determined by Google.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code also illustrates another feature of the library: the capability to
    create prompt templates, which are parameterized prompts. Prompt parameters are
    indicated in the template by enclosing them in double curly braces. At runtime,
    these placeholders are replaced with values bearing the same key contained in
    a `Map` that is passed to the `CompletionService.fillSlots()` method. For instance,
    in the following code, the string “`{{chapter_summary}}`” is replaced by the value
    associated with the “`chapter_summary`” key in the `params` `Map`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`public List<Pair<SearchResult, Integer>>`'
  prefs: []
  type: TYPE_NORMAL
- en: '`google(Section chapter, Section section)`'
  prefs: []
  type: TYPE_NORMAL
- en: '`{`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// First create a list of search queries,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// based on what we want to search`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Instanciates model to create Google searches`'
  prefs: []
  type: TYPE_NORMAL
- en: '`OpenAiChatService chatSvc = openAi.getChatService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`chatSvc.setModel(COMPLETION_MODEL);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`chatSvc.setTemperature(50.0);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Dynamically build the prompt`'
  prefs: []
  type: TYPE_NORMAL
- en: '`final String prompt =`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“Given the below chapter summary, section title and section summary, provided
    in XML tags, generate a list of search engine queries that can be used to search
    the topic corresponding to the section on the Internet.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Each query is a short sentence or a short list of key terms relevant for
    the section topic.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Include terms to provide a context for the topic, as described by the
    chapter summary, so that the query is clearly related to the chapter content.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Be creative and provide exactly 5 queries.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Strictly provide results as a JSON array of strings.\n\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “<chapter_summary>{{chapter_summary}}</chapter_summary>\n\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “<section_title>{{section_title}}</section_title>\n\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “<section_summary>{{section_summary}}</section_summary>”;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Provide data to fill slots in the prompt template`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Map<String, String> params = new HashMap<>();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`params.put(“chapter_summary”, chapter.summary);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`params.put(“section_title”, section.title);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`params.put(“section_summary”, section.summary);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Prepares the conversation;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// notice the call to fill the slots in the prompt template`'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<ChatMessage> msgs = new ArrayList<>();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`msgs.add(new ChatMessage(`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Role.SYSTEM,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“You are an assistant helping a researcher in finding web pages that are relevant
    for the essay section they are writing.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`));`'
  prefs: []
  type: TYPE_NORMAL
- en: '`msgs.add(new ChatMessage(`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Role.USER, CompletionService.fillSlots(prompt, params)`'
  prefs: []
  type: TYPE_NORMAL
- en: '`));`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Build a list of Google queries for the section.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Queries are returned as a JSON list of Strings, that is deserialized.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<String> queries;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`while (true) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`try {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`queries = JSON_MAPPER.readValue(chatSvc.complete(msgs).getText(),`'
  prefs: []
  type: TYPE_NORMAL
- en: '`new TypeReference<List<String>>() {});`'
  prefs: []
  type: TYPE_NORMAL
- en: '`break;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`} catch (JsonProcessingException e) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Retry in case GPT returned badly formatted JSON`'
  prefs: []
  type: TYPE_NORMAL
- en: '`LOG.warn(“Retrying because of malformed JSON, e);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Now submit each query and collect returned links`'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<Pair<SearchResult, Integer>> result = new ArrayList<>();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`for (String query : queries) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<SearchResult> links;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`try {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`links = google.getSearchService()`'
  prefs: []
  type: TYPE_NORMAL
- en: '`.search(query, LINKS_PER_QUERY);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`} catch (Exception e) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Skip single query that fails`'
  prefs: []
  type: TYPE_NORMAL
- en: '`LOG.warn(“Ignoring error searching for: “ + query, e);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`continue;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`[…]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return result;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: Once the Writer has the list of pages to be downloaded, it goes ahead and retrieves
    them, delivering the corresponding embedding. Depending on the size of the page,
    this could potentially result in multiple items. The `ExtractionUtil.fromUrl()`
    method is a handy one-liner for fetching text content directly from a URL.
  prefs: []
  type: TYPE_NORMAL
- en: The reader should also notice how we use the `ModelService` to have some model
    metadata, like the maximum number of tokens it accepts as input.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Java, this process looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '`private List<EmbeddedText> download(SearchResult link) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Instantiate the service used to embed the downloaded pages`'
  prefs: []
  type: TYPE_NORMAL
- en: '`EmbeddingService embSvc = openAi.getEmbeddingService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Set the maximum size for each embedded text chunk;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// the following calculation ensures approximately 15 embeddings`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// will be used to compose each section.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Notice how the ModelService is fetched from the OpenAIEndpoint (openAI)`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// to retrieve the maximum prompt size for the completion model and the`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// embedding model.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`int writerSize = openAi.getModelService().getContextSize(WRITER_MODEL);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`int embSize = openAi.getModelService().getContextSize(embSvc.getModel());`'
  prefs: []
  type: TYPE_NORMAL
- en: '`embSvc.setMaxTextTokens(`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Math.min(embSize, (writerSize - SECTION_LENGTH_TOKENS) / 15)    );`'
  prefs: []
  type: TYPE_NORMAL
- en: '``// Download the page content as a String`'
  prefs: []
  type: TYPE_NORMAL
- en: '`String content = null;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`try {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`content = ExtractionUtil.fromUrl(`'
  prefs: []
  type: TYPE_NORMAL
- en: '`link.getLink(), DOWNLOAD_TIMEOUT_MILLIS));`'
  prefs: []
  type: TYPE_NORMAL
- en: '`} catch (Exception e) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// If an error occurs during page download, the page is skipped`'
  prefs: []
  type: TYPE_NORMAL
- en: '`LOG.error(“Error downloading “ + link.getLink(), e);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return new ArrayList<>();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Embed the downloaded content`'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<EmbeddedText> result = embSvc.embed(content);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`[…]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return result;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: Upon successful completion, the embeddings are stored within the knowledge base,
    paving the way for the writing process to commence. The following code snippet
    outlines how a single section is written.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examining the code, the reader can see how the `search()` method from the `KnowledgeBase`
    is used to perform semantic search, by passing an embedded version of the section
    summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '`private List<Section> write(Section section) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Instanciate services`'
  prefs: []
  type: TYPE_NORMAL
- en: '`EmbeddingService embSvc = openAi.getEmbeddingService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`OpenAiChatService chatSvc = openAi.getChatService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`chatSvc.setModel(WRITER_MODEL);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`chatSvc.setTemperature(0.0);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`String prompt =`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“<context>{{context}}</context>\n\n”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “<summary>{{summary}}</summary>”;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Map<String, String> params = new HashMap<>();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`params.put(“summary”, section.summary);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// This is the prompt used for creating the section`'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<ChatMessage> msgs = new ArrayList<>();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`msgs.add(new ChatMessage(Role.SYSTEM,`'
  prefs: []
  type: TYPE_NORMAL
- en: '`“You will be provided with a context and the summary of a section of an essay,
    both delimited by XML tags.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Your task is to use the content of the context to write the entire section
    of the essay.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Use a professional style.” + “ Avoid content repetitions but be detailed.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Output only the section content, not its title, do not create subsections.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Do not make up missing information or put placeholders for data you do
    not have.”`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ “ Only if enough information is available in the content, produce a text
    at least “`'
  prefs: []
  type: TYPE_NORMAL
- en: '`+ SECTION_LENGTH_TOKENS + “ tokens long.\n\n”));`'
  prefs: []
  type: TYPE_NORMAL
- en: '`[…]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Searches the knowledge base for relevant content// (= builds the context)`'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<Pair<EmbeddedText, Double>> knowledge = kb.search(embSvc.embed(section.summary).get(0),
    50, 0);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Here some code is needed to take only`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// the context that fits the model prompt size.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// It is omitted for simplicity.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`[…]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// Add generated content to the section`'
  prefs: []
  type: TYPE_NORMAL
- en: '`section.content = chatSvc.complete(msgs).getText();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`[…]`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return section.sections; // Not used really`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '[Conclusion](toc.xhtml#s467a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has presented a comprehensive overview of the `predictive-powers`
    library and its ability to harness the power of generative AI for Java developers.
    The focus was to present a real-life approach to utilizing generative AI capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The `predictive-powers` library offers distinct advantages for Java developers
    and AI enthusiasts alike. It not only simplifies the integration of generative
    AI capabilities but also provides low-level access to popular APIs like OpenAI
    and Hugging Face. This flexibility allows developers to engage directly with these
    APIs if desired. Moreover, the library’s design aligns with the CapabilityGPT
    framework, ensuring compatibility with different capability providers, reducing
    the risk of vendor lock-in. Additionally, its in-memory vector database supports
    essential functions like semantic search, information extraction, and question
    answering. Lastly, it facilitates the convenient retrieval of textual content
    from diverse sources, including web pages and various file formats like MS Office,
    PDF, and HTML. These features make the `predictive-powers` library a valuable
    tool for harnessing generative AI capabilities in Java applications while leveraging
    flexibility, compatibility, and ease of use typical of Java applications.
  prefs: []
  type: TYPE_NORMAL
- en: We delved into the technical aspects of the library, detailing essential concepts
    such as API clients, endpoints and services, and the knowledge base. We learned
    about their roles and functionalities within the broader framework and gained
    insights into their underlying mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the chapter’s highlights was a practical example: the creation of an
    autonomous agent named the ‘Essay Writer’. This served as a concrete illustration
    of how to leverage the `predictive-powers` library and its different features
    in a realistic project.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Key Points](toc.xhtml#s468a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By the end of this chapter, the reader should be familiar with:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The** `**predictive-powers**` **library**: An Apache-2.0 licensed library
    that offers a simplified yet powerful interface for Java developers to harness
    generative AI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API clients**: Fundamental units of the `predictive-powers` library that
    facilitate direct API calls to service providers like OpenAI and Hugging Face.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Endpoints and services**: High-level generative AI components that utilize
    API clients to render services. The reader should be aware of the services offered,
    such as the `ModelService`, `CompletionService`, `ChatService`, `EmbeddingService`,
    and others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**KnowledgeBase**`: An in-memory vector database crucial for abilities such
    as semantic search, information extraction, and question answering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implementation of an autonomous agent**: The chapter guides the reader through
    the creation of an ‘Essay Writer’, demonstrating the practical application of
    the concepts learned. It shows how the library components can be easily combined,
    leveraging the CapabilityGPT framework, prompt engineering techniques, and architecture
    patterns presented in other parts of the book to create an agent able to perform
    a complex task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Architecture pattern**: Understanding the architecture pattern and navigating
    the code is a critical part of the learning process. The reader should be familiar
    with the three-tier architecture: the User Experience layer, the Application layer,
    and the AI layer, and understand how these layers can be implemented using components
    from the `predictive-powers` library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code navigation**: Understanding the code snippets and their workings, presented
    in the Code Walkthrough section, will help the reader apply these concepts to
    their own projects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ____________________
  prefs: []
  type: TYPE_NORMAL
- en: '[¹](#ftn1) ***Generative AI*** refers to the branch of artificial intelligence
    that specializes in producing new content, which can range from text and images
    to audio and video, drawing upon patterns and information it has gleaned from
    existing data sources. The GPT series from OpenAI serves as a notable representation
    of this kind of AI. Throughout this chapter, the term ‘generative AI’ will be
    used more frequently than ‘GPT’ to maintain a focus on the broader technology
    category, emphasizing the versatility of the `predictive-powers` library, which
    is not confined to utilizing GPT exclusively.'
  prefs: []
  type: TYPE_NORMAL
- en: '[²](#ftn2) As already mentioned in *[Chapter 8: LangChain: GPT Implementation
    Framework for Python](c08.xhtml)*, Text ***embeddings*** are numerical representations
    of text, enabling machines to understand and process natural language. They transform
    words or phrases into a list of numbers, with semantically similar items possessing
    similar values. In ***semantic search***, this allows the system to match user’s
    queries with relevant documents based on semantic similarity, not just keyword
    matches. By employing text embeddings, systems can understand nuanced meanings
    and improve the relevance of search results, providing a more efficient and effective
    search experience.'
  prefs: []
  type: TYPE_NORMAL
- en: '[³](#ftn3) In-memory vector databases leverage the system memory (RAM) to store
    data, which provides the advantage of extremely quick data retrieval and processing.
    However, this comes with constraints related to RAM size, making it less suitable
    for handling extremely large datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⁴](#ftn4) As we will see later, there are also other endpoints, providing
    different capabilities, such as the `SearchEndpoint` that exposes methods to access
    web search services.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⁵](#ftn5) [https://openai.com/dall-e-3](https://openai.com/dall-e-3)'
  prefs: []
  type: TYPE_NORMAL
- en: '[⁶](#ftn6) [https://openjourney.art/](https://openjourney.art/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[⁷](#ftn7) See *[Chapter 4: Architecture Patterns enabled by GPT-Models](c04.xhtml)*,
    specifically the section “B Conversational Patterns with External Tool Integration”.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⁸](#ftn8) The knowledge base is similar to vector stores in LangChain. See
    *[Chapter 8: LangChain: GPT Implementation Framework for Python](c08.xhtml)*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⁹](#ftn9) Please refer to *[Chapter 4: Architecture Patterns enabled by GPT-Models](c04.xhtml)*,
    and compare this architecture with architecture pattern “D2 Orchestration Agent”.'
  prefs: []
  type: TYPE_NORMAL
- en: '[^(10)](#ftn10) JSON, which stands for JavaScript Object Notation, is a method
    used to store information in an organized, easy-to-access manner. In a nutshell,
    it gives us a textual human-readable collection of data that we can access in
    a logical manner. It is widely used in many digital services and products to help
    systems and servers share data efficiently and quickly. Even though its name includes
    “JavaScript,” it can be used in many programming environments outside of JavaScript.'
  prefs: []
  type: TYPE_NORMAL
- en: '[^(11)](#ftn11) [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
    (specifically, gpt-3.5-turbo for the chat service and text-embedding-ada-002 for
    embedding).```'
  prefs: []
  type: TYPE_NORMAL
