# 第 10 章

# ChatGPT 的 API 定价模型和技术限制

# 介绍

**API 定价**（截至 2023 年 3 月 2 日）：尽管 ChatGPT 仍然有免费版本可用，但 API 对于小到大型机构和个人来说是必需的，以便将他们的开发和应用程序与 GPT 集成，以在其端利用该设施。ChatGPT 和其近亲 GPT-3.5 的 API 定价现在已经变得可持续和负担得起。以下是当前每 1000 个 token 的定价列表（可以将其视为单词向量，1000 个 token 大约可以创建 750 个单词的文章）：

| **模型** | **价格 / 1000 tokens** |

| gpt-3.5-turbo | $0.002 / 1K tokens |

| Ada – 最快 | $0.0004 / 1K tokens |

| Babbage | $0.0005 / 1K tokens |

| Curie | $0.0020 / 1K tokens |

| Davinci – 最强大 | $0.0020 / 1K tokens |

# ChatGPT 的技术限制

有时 ChatGPT 提供的回答是准确的，但实际上是错误的或不合逻辑的。解决这个问题很困难，因为：（1）目前在 RL 训练期间没有真相来源；（2）使模型更谨慎会导致它拒绝它可以正确回答的问题；（3）监督训练会欺骗模型，因为最佳回应取决于模型的知识而不是示范者的知识。

输入短语可以更改，ChatGPT 对相同问题的重复尝试很敏感。例如，如果问题以一种方式表达，模型可能会声称不知道答案，但通过简单改述，他们可能能够准确回答。

模型反复声明自己是由 OpenAI 开发的语言模型，并使用其他过度使用的词语。这些问题是由训练数据中的偏见引起的（训练者偏爱看起来更彻底的更长回答）以及众所周知的过度优化问题。

当用户提供一个不确定的查询时，模型理想情况下应该提出澄清问题。相反，我们目前的模型通常会假设用户的意思是什么。

尽管我们努力使模型拒绝不合适的请求，但仍然有时会接受负面指示或表现敌意。尽管我们暂时预期会有一些误报和误判，但我们正在利用 Moderation API 来警告用户或禁止特定类别的危险材料。为了帮助我们不断努力改进这个系统，我们很乐意收集用户意见。

# 要记住的事情

+   API 定价（截至 2023 年 3 月 2 日）：尽管 ChatGPT 仍然有免费版本可用，但 API 对于小到大型机构和个人来说是必需的，以便将他们的开发和应用程序与 GPT 集成，以在其端利用该设施。

+   ChatGPT 和其近亲 GPT-3.5 的 API 定价现在已经变得可持续和负担得起。

# 加入我们书籍的 Discord 空间

加入书籍的 Discord Workspace，获取最新更新、优惠、全球技术动态、新发布和与作者的交流：

[**https://discord.bpbonline.com**](https://discord.bpbonline.com)

![](img/dis.jpg)
