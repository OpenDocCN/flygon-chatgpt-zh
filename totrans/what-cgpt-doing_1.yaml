- en: What Is ChatGPT Doing ... and Why Does It Work?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 在做什么... 为什么会有效？
- en: It’s Just Adding One Word at a Time
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它只是一次添加一个单词
- en: That [ChatGPT](https://chat.openai.com/) can automatically generate something
    that reads even superficially like human-written text is remarkable, and unexpected.
    But how does it do it? And why does it work? My purpose here is to give a rough
    outline of what’s going on inside ChatGPT—and then to explore why it is that it
    can do so well in producing what we might consider to be meaningful text. I should
    say at the outset that I’m going to focus on the big picture of what’s going on—and
    while I’ll mention some engineering details, I won’t get deeply into them. (And
    the essence of what I’ll say applies just as well to other current “large language
    models” [LLMs] as to ChatGPT.)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[ChatGPT](https://chat.openai.com/) 能够自动生成类似人类编写文本的东西，这是令人惊讶且意想不到的。但它是如何做到的？为什么有效？我在这里的目的是大致概述
    ChatGPT 内部发生的事情，然后探讨为什么它能够在产生我们可能认为有意义的文本方面做得如此出色。我应该在一开始就说，我将专注于正在发生的大局，并且虽然我会提到一些工程细节，但我不会深入探讨它们。（我将说的要点同样适用于其他当前的“大型语言模型”
    [LLMs]，就像适用于 ChatGPT 一样。）'
- en: The first thing to explain is that what ChatGPT is always fundamentally trying
    to do is to produce a “reasonable continuation” of whatever text it’s got so far,
    where by “reasonable” we mean “what one might expect someone to write after seeing
    what people have written on billions of webpages, etc.”
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要解释的是，ChatGPT 始终试图做的基本上是生成“合理的延续”，无论它目前已经有了什么文本，这里的“合理”意味着“在看到人们在数十亿网页等上写了什么之后，我们可能期望某人写下的内容”。
- en: 'So let’s say we’ve got the text “*The best thing about AI is its ability to*
    ”. Imagine scanning billions of pages of human-written text (say on the web and
    in digitized books) and finding all instances of this text—then seeing what word
    comes next what fraction of the time. ChatGPT effectively does something like
    this, except that (as I’ll explain) it doesn’t look at literal text; it looks
    for things that in a certain sense “match in meaning”. But the end result is that
    it produces a ranked list of words that might follow, together with “probabilities”:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，假设我们有文本“*AI最好的地方在于*”。想象一下扫描数十亿页人类编写的文本（比如网络上和数字化书籍中的文本），找到所有这个文本的实例，然后看看接下来的词是什么，以及在多大程度上。ChatGPT
    实际上做的就是这样一件事，只是（我将解释）它不看文字本身；它寻找的是在某种意义上“意义匹配”的东西。但最终的结果是它生成了一个排名列表，列出了可能跟随的单词，以及“概率”：
- en: '![](Image00002.gif)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00002.gif)'
- en: And the remarkable thing is that when ChatGPT does something like write an essay
    what it’s essentially doing is just asking over and over again “given the text
    so far, what should the next word be?”—and each time adding a word. (More precisely,
    as I’ll explain, it’s adding a “token”, which could be just a part of a word,
    which is why it can sometimes “make up new words”.)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，当 ChatGPT 做类似写一篇文章的事情时，它实际上只是一遍又一遍地问“在目前的文本中，下一个词应该是什么？” ——然后每次添加一个单词。（更准确地说，正如我将解释的那样，它添加的是一个“标记”，这可能只是一个单词的一部分，这就是为什么它有时“编造新词”的原因。）
- en: But, OK, at each step it gets a list of words with probabilities. But which
    one should it actually pick to add to the essay (or whatever) that it’s writing?
    One might think it should be the “highest-ranked” word (i.e. the one to which
    the highest “probability” was assigned). But this is where a bit of voodoo begins
    to creep in. Because for some reason—that maybe one day we’ll have a scientific-style
    understanding of—if we always pick the highest-ranked word, we’ll typically get
    a very “flat” essay, that never seems to “show any creativity” (and even sometimes
    repeats word for word). But if sometimes (at random) we pick lower-ranked words,
    we get a “more interesting” essay.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，在每一步，它都会得到一个带有概率的单词列表。但它应该选择哪一个添加到正在写的文章（或其他内容）中呢？人们可能认为应该选择“排名最高”的单词（即分配了最高“概率”的单词）。但这就是一些巫术开始悄悄渗入的地方。因为出于某种原因——也许有一天我们会对此有科学式的理解——如果我们总是选择排名最高的单词，我们通常会得到一篇非常“平淡”的文章，似乎从不“展现任何创造力”（甚至有时会逐字重复）。但如果有时（随机地）选择排名较低的单词，我们会得到一篇“更有趣”的文章。
- en: The fact that there’s randomness here means that if we use the same prompt multiple
    times, we’re likely to get different essays each time. And, in keeping with the
    idea of voodoo, there’s a particular so-called “temperature” parameter that determines
    how often lower-ranked words will be used, and for essay generation, it turns
    out that a “temperature” of 0.8 seems best. (It’s worth emphasizing that there’s
    no “theory” being used here; it’s just a matter of what’s been found to work in
    practice. And for example the concept of “temperature” is there because exponential
    distributions [familiar from statistical physics](https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/#textbook-thermodynamics)
    happen to be being used, but there’s no “physical” connection—at least so far
    as we know.)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这里存在随机性意味着，如果我们多次使用相同提示，每次可能会得到不同的文章。并且，与巫术的概念一致，有一个特定的所谓“温度”参数，决定了使用较低排名单词的频率，对于文章生成来说，0.8的“温度”似乎最好。（值得强调的是这里没有使用“理论”；这只是根据实践中发现的有效方法。例如，“温度”概念之所以存在是因为指数分布[熟悉于统计物理学](https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/#textbook-thermodynamics)正被使用，但没有“物理”联系——至少据我们所知。）
- en: Before we go on I should explain that for purposes of exposition I’m mostly
    not going to use the [full system that’s in ChatGPT](https://openai.com/blog/chatgpt/)
    ; instead I’ll usually work with a simpler [GPT-2 system](https://resources.wolframcloud.com/NeuralNetRepository/resources/GPT2-Transformer-Trained-on-WebText-Data/)
    , which has the nice feature that it’s small enough to be able to run on a standard
    desktop computer. And so for essentially everything I show I’ll be able to include
    explicit [Wolfram Language](https://www.wolfram.com/language/) code that you can
    immediately run on your computer. (Click any picture here to copy the code behind
    it.)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我应该解释一下，为了说明的目的，我大多不会使用[ChatGPT中的完整系统](https://openai.com/blog/chatgpt/)；相反，我通常会使用一个更简单的[GPT-2系统](https://resources.wolframcloud.com/NeuralNetRepository/resources/GPT2-Transformer-Trained-on-WebText-Data/)，它具有一个很好的特点，即它足够小，可以在标准台式计算机上运行。因此，对于我展示的几乎所有内容，我都能够包含您可以立即在计算机上运行的明确的[Wolfram语言](https://www.wolfram.com/language/)代码。（单击这里的任何图片以复制其背后的代码。）
- en: 'For example, here’s how to get the table of probabilities above. First, we
    have to [retrieve the underlying “language model” neural net](https://resources.wolframcloud.com/NeuralNetRepository)
    :'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里是如何获取上述概率表的方法。首先，我们必须[检索基础的“语言模型”神经网络](https://resources.wolframcloud.com/NeuralNetRepository)：
- en: '![](Image00003.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00003.jpg)'
- en: 'Later on, we’ll look inside this neural net, and talk about how it works. But
    for now we can just apply this “net model” as a black box to our text so far,
    and ask for the top 5 words by probability that the model says should follow:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，我们将深入研究这个神经网络，并讨论它的工作原理。但现在我们可以将这个“网络模型”作为一个黑匣子应用到我们迄今为止的文本中，并要求模型说应该跟随的前5个单词的概率最高：
- en: '![](Image00004.gif)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00004.gif)'
- en: 'This takes that result and makes it into an explicit formatted “[dataset](https://www.wolfram.com/language/elementary-introduction/2nd-ed/45-datasets.html)
    ”:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这将该结果制作成明确格式的“[数据集](https://www.wolfram.com/language/elementary-introduction/2nd-ed/45-datasets.html)”：
- en: '![](Image00005.gif)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00005.gif)'
- en: 'Here’s what happens if one repeatedly “applies the model”—at each step adding
    the word that has the top probability (specified in this code as the “decision”
    from the model):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个人反复“应用模型”，每一步都添加具有最高概率的单词（在此代码中指定为模型的“决策”），会发生什么：
- en: '![](Image00006.gif)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00006.gif)'
- en: 'What happens if one goes on longer? In this (“zero temperature”) case what
    comes out soon gets rather confused and repetitive:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果继续下去会发生什么？在这种（“零温度”）情况下，很快输出的内容会变得相当混乱和重复：
- en: '![](Image00007.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00007.jpg)'
- en: 'But what if instead of always picking the “top” word one sometimes randomly
    picks “non-top” words (with the “randomness” corresponding to “temperature” 0.8)?
    Again one can build up text:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果不总是选择“顶部”单词，而是有时随机选择“非顶部”单词（“随机性”对应于“温度”0.8）呢？同样可以构建文本：
- en: '![](Image00008.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00008.jpg)'
- en: 'And every time one does this, different random choices will be made, and the
    text will be different—as in these 5 examples:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 每次这样做时，都会做出不同的随机选择，文本也会不同，就像这5个例子中的情况：
- en: '![](Image00009.gif)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00009.gif)'
- en: 'It’s worth pointing out that even at the first step there are a lot of possible
    “next words” to choose from (at temperature 0.8), though their probabilities fall
    off quite quickly (and, yes, the straight line on this log-log plot corresponds
    to an *n* ^(–1) [“power-law” decay that’s very characteristic of the general statistics
    of language](https://www.wolframscience.com/nks/notes-8-8--zipfs-law/) ):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出，即使在第一步，也有很多可能的“下一个词”可供选择（在温度为0.8时），尽管它们的概率迅速下降（是的，在这个对数-对数图上的直线对应于* n *
    ^（-1）[“幂律”衰减，这是语言的一般统计特征](https://www.wolframscience.com/nks/notes-8-8--zipfs-law/)）：
- en: '![](Image00010.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00010.jpg)'
- en: 'So what happens if one goes on longer? Here’s a random example. It’s better
    than the top-word (zero temperature) case, but still at best a bit weird:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 那么如果继续下去会发生什么？这里是一个随机示例。它比顶部词（零温度）情况要好，但仍然至少有点奇怪：
- en: '![](Image00011.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00011.jpg)'
- en: 'This was done with the [simplest GPT-2 model](https://resources.wolframcloud.com/NeuralNetRepository/resources/GPT2-Transformer-Trained-on-WebText-Data/)
    (from 2019). With the newer and [bigger GPT-3 models](https://platform.openai.com/docs/model-index-for-researchers)
    the results are better. Here’s the top-word (zero temperature) text produced with
    the same “prompt”, but with the biggest GPT-3 model:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用[最简单的GPT-2模型](https://resources.wolframcloud.com/NeuralNetRepository/resources/GPT2-Transformer-Trained-on-WebText-Data/)（来自2019年）完成的。使用更新和[更大的GPT-3模型](https://platform.openai.com/docs/model-index-for-researchers)结果更好。这是使用相同“提示”生成的顶部词（零温度）文本，但使用最大的GPT-3模型：
- en: '![](Image00012.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00012.jpg)'
- en: 'And here’s a random example at “temperature 0.8”:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个“温度0.8”的随机示例：
- en: '![](Image00013.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00013.jpg)'
- en: Where Do the Probabilities Come From?
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概率是从哪里来的？
- en: OK, so ChatGPT always picks its next word based on probabilities. But where
    do those probabilities come from? Let’s start with a simpler problem. Let’s consider
    generating English text one letter (rather than word) at a time. How can we work
    out what the probability for each letter should be?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，ChatGPT总是根据概率选择下一个词。但这些概率是从哪里来的呢？让我们从一个更简单的问题开始。让我们考虑一次生成英文文本一个字母（而不是单词）。我们如何计算每个字母的概率呢？
- en: 'A very minimal thing we could do is just take a sample of English text, and
    calculate how often different letters occur in it. So, for example, [this counts
    letters in the Wikipedia article](https://www.wolfram.com/language/elementary-introduction/2nd-ed/34-associations.html#i-8)
    on “cats”:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做的一个非常简单的事情就是只取一段英文文本的样本，并计算其中不同字母出现的频率。例如，[这里计算了维基百科文章](https://www.wolfram.com/language/elementary-introduction/2nd-ed/34-associations.html#i-8)中“cats”中字母的频率：
- en: '![](Image00014.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00014.jpg)'
- en: 'And this does the same thing for “dogs”:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这也对“dogs”做了同样的事情：
- en: '![](Image00015.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00015.jpg)'
- en: 'The results are similar, but not the same (“o” is no doubt more common in the
    “dogs” article because, after all, it occurs in the word “dog” itself). Still,
    if we take a large enough sample of English text we can expect to eventually get
    at least fairly consistent results:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是相似的，但并不完全相同（“o”在“dogs”文章中无疑更常见，因为毕竟它出现在单词“dog”中）。不过，如果我们取足够大的英文文本样本，我们最终可以期望得到至少相当一致的结果：
- en: '![](Image00016.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00016.jpg)'
- en: 'Here’s a sample of what we get if we just generate a sequence of letters with
    these probabilities:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们只根据这些概率生成一系列字母时得到的样本：
- en: '![](Image00017.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00017.jpg)'
- en: 'We can break this into “words” by adding in spaces as if they were letters
    with a certain probability:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过按照一定概率添加空格来将其分解为“单词”：
- en: '![](Image00018.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00018.jpg)'
- en: 'We can do a slightly better job of making “words” by forcing the distribution
    of “word lengths” to agree with what it is in English:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过强制“单词长度”的分布与英语中的实际情况一致，我们可以更好地生成“单词”：
- en: '![](Image00019.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00019.jpg)'
- en: We didn’t happen to get any “actual words” here, but the results are looking
    slightly better. To go further, though, we need to do more than just pick each
    letter separately at random. And, for example, we know that if we have a “q”,
    the next letter basically has to be “u”.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们没有得到任何“实际单词”，但结果看起来稍微好一些。不过，要进一步，我们需要做的不仅仅是随机选择每个字母。例如，我们知道如果有一个“q”，下一个字母基本上必须是“u”。
- en: 'Here’s a plot of the probabilities for letters on their own:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是字母单独出现的概率的图表：
- en: '![](Image00020.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00020.jpg)'
- en: 'And here’s a plot that shows the probabilities of pairs of letters (“2-grams”)
    in typical English text. The possible first letters are shown across the page,
    the second letters down the page:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个显示典型英文文本中字母对（“2-grams”）概率的图表。可能的第一个字母横跨页面显示，第二个字母纵向显示：
- en: '![](Image00021.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00021.jpg)'
- en: 'And we see here, for example, that the “q” column is blank (zero probability)
    except on the “u” row. OK, so now instead of generating our “words” a single letter
    at a time, let’s generate them looking at two letters at a time, using these “2-gram”
    probabilities. Here’s a sample of the result—which happens to include a few “actual
    words”:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们在这里看到，“q”列是空白的（概率为零），除了“u”行。好的，现在我们不再一次生成我们的“单词”，而是一次查看两个字母，使用这些“2-gram”概率来生成它们。这里是结果的一个样本—其中包括一些“实际单词”：
- en: '![](Image00022.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00022.jpg)'
- en: 'With sufficiently much English text we can get pretty good estimates not just
    for probabilities of single letters or pairs of letters (2-grams), but also for
    longer runs of letters. And if we generate “random words” with progressively longer
    *n* -gram probabilities, we see that they get progressively “more realistic”:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过足够多的英文文本，我们不仅可以对单个字母或字母对（2-grams）的概率得到相当好的估计，还可以对更长的字母序列进行估计。如果我们使用逐渐更长的*n*-gram概率生成“随机单词”，我们会看到它们逐渐变得“更现实”：
- en: '![](Image00023.gif)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00023.gif)'
- en: 'But let’s now assume—more or less as ChatGPT does—that we’re dealing with whole
    words, not letters. There are about 40,000 [reasonably commonly used words in
    English](https://reference.wolfram.com/language/ref/WordList.html) . And by looking
    at a large corpus of English text (say a few million books, with altogether a
    few hundred billion words), we can get an [estimate of how common each word is](https://reference.wolfram.com/language/ref/WordFrequencyData.html)
    . And using this we can start generating “sentences”, in which each word is independently
    picked at random, with the same probability that it appears in the corpus. Here’s
    a sample of what we get:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在让我们假设—更多或更少地像ChatGPT一样—我们正在处理整个单词，而不是字母。英语中大约有40,000个[常用单词](https://reference.wolfram.com/language/ref/WordList.html)。通过查看大量的英文文本（比如几百万本书，总共几百亿字），我们可以得到每个单词有多常见的[估计](https://reference.wolfram.com/language/ref/WordFrequencyData.html)。利用这一点，我们可以开始生成“句子”，其中每个单词都是独立随机选择的，具有它在语料库中出现的相同概率。这里是我们得到的一个样本：
- en: '![](Image00024.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00024.jpg)'
- en: 'Not surprisingly, this is nonsense. So how can we do better? Just like with
    letters, we can start taking into account not just probabilities for single words
    but probabilities for pairs or longer *n* -grams of words. Doing this for pairs,
    here are 5 examples of what we get, in all cases starting from the word “cat”:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，这是无意义的。那么我们怎么能做得更好呢？就像处理字母一样，我们可以开始考虑不仅是单个单词的概率，而是对单词对或更长的*n*-gram单词的概率。对于成对的情况，以下是我们得到的5个示例，所有情况都从单词“cat”开始：
- en: '![](Image00025.gif)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00025.gif)'
- en: 'It’s getting slightly more “sensible looking”. And we might imagine that if
    we were able to use sufficiently long *n* -grams we’d basically “get a ChatGPT”—in
    the sense that we’d get something that would generate essay-length sequences of
    words with the “correct overall essay probabilities”. But here’s the problem:
    there just isn’t even close to enough English text that’s ever been written to
    be able to deduce those probabilities.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来稍微更“合理”了。我们可以想象，如果我们能够使用足够长的*n*-grams，我们基本上会“得到一个ChatGPT”—在这个意义上，我们会得到一些会生成具有“正确整体文章概率”的单词序列的东西。但问题在于：甚至没有足够接近的英文文本被写过，以便推断这些概率。
- en: In a [crawl of the web](https://commoncrawl.org/) there might be a few hundred
    billion words; in books that have been digitized there might be another hundred
    billion words. But with 40,000 common words, even the number of possible 2-grams
    is already 1.6 billion—and the number of possible 3-grams is 60 trillion. So there’s
    no way we can estimate the probabilities even for all of these from text that’s
    out there. And by the time we get to “essay fragments” of 20 words, the number
    of possibilities is larger than the number of particles in the universe, so in
    a sense they could never all be written down.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在[网络爬虫](https://commoncrawl.org/)中可能有数百亿字；在已数字化的书籍中可能还有另外数百亿字。但是，即使有40,000个常用词，可能的2-gram数量已经达到了16亿，而可能的3-gram数量则达到了60万亿。因此，我们无法从已有的文本中估计所有这些的概率。当我们到达“20个词的文章片段”时，可能性的数量已经超过了宇宙中的粒子数量，因此从某种意义上说，它们永远无法全部被记录下来。
- en: So what can we do? The big idea is to make a model that lets us estimate the
    probabilities with which sequences should occur—even though we’ve never explicitly
    seen those sequences in the corpus of text we’ve looked at. And at the core of
    ChatGPT is precisely a so-called “large language model” (LLM) that’s been built
    to do a good job of estimating those probabilities.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们能做什么？大的想法是制定一个模型，让我们能够估计序列应该发生的概率——即使我们从未在我们查看的文本语料库中明确看到过这些序列。而 ChatGPT
    的核心正是所谓的“大语言模型”（LLM），它被构建为很好地估计这些概率。
- en: What Is a Model?
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是模型？
- en: 'Say you want to know (as [Galileo did back in the late 1500s](https://archive.org/details/bub_gb_49d42xp-USMC/page/404/mode/2up)
    ) how long it’s going to take a cannon ball dropped from each floor of the Tower
    of Pisa to hit the ground. Well, you could just measure it in each case and make
    a table of the results. Or you could do what is the essence of theoretical science:
    make a model that gives some kind of procedure for computing the answer rather
    than just measuring and remembering each case.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想知道（就像[加利略在16世纪末所做的那样](https://archive.org/details/bub_gb_49d42xp-USMC/page/404/mode/2up)）从比萨斜塔的每层楼掉下的炮弹到达地面需要多长时间。嗯，你可以在每种情况下测量它并制作一个结果表。或者你可以做理论科学的本质：制定一个给出某种计算答案的程序的模型，而不仅仅是测量和记住每种情况。
- en: 'Let’s imagine we have (somewhat idealized) data for how long the cannon ball
    takes to fall from various floors:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象我们有（有些理想化的）数据，表明炮弹从各个楼层掉下所需的时间：
- en: '![](Image00026.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00026.jpg)'
- en: 'How do we figure out how long it’s going to take to fall from a floor we don’t
    explicitly have data about? In this particular case, we can use known laws of
    physics to work it out. But say all we’ve got is the data, and we don’t know what
    underlying laws govern it. Then we might make a mathematical guess, like that
    perhaps we should use a straight line as a model:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何确定从我们没有明确数据的楼层掉下来需要多长时间？在这种特殊情况下，我们可以利用已知的物理定律来计算。但是假设我们只有数据，而不知道支配它的基本定律。那么我们可能会做一个数学猜测，比如也许我们应该使用一条直线作为模型：
- en: '![](Image00027.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00027.jpg)'
- en: We could pick different straight lines. But this is the one that’s on average
    closest to the data we’re given. And from this straight line we can estimate the
    time to fall for any floor.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择不同的直线。但这是平均最接近我们所给出的数据的直线。从这条直线我们可以估计任何楼层掉落的时间。
- en: 'How did we know to try using a straight line here? At some level we didn’t.
    It’s just something that’s mathematically simple, and we’re used to the fact that
    lots of data we measure turns out to be well fit by mathematically simple things.
    We could try something mathematically more complicated—say *a* + *b* *x* + *c*
    *x* ² —and then in this case we do better:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们怎么知道在这里尝试使用一条直线呢？在某种程度上，我们并不知道。这只是数学上简单的东西，我们习惯于许多我们测量的数据结果很适合数学上简单的东西。我们可以尝试一些数学上更复杂的东西——比如
    *a* + *b* *x* + *c* *x* ² ——在这种情况下我们做得更好：
- en: '![](Image00028.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00028.jpg)'
- en: 'Things can go quite wrong, though. Like here’s [the best we can do](https://reference.wolfram.com/language/ref/FindFit.html)
    with *a* + *b* /*x* + *c* sin(*x* ):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 事情可能会出现问题。就像这里我们用 *a* + *b* /*x* + *c* sin(*x* )做的[最好的尝试](https://reference.wolfram.com/language/ref/FindFit.html)：
- en: '![](Image00029.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00029.jpg)'
- en: It is worth understanding that there’s never a “model-less model”. Any model
    you use has some particular underlying structure—then a certain set of “knobs
    you can turn” (i.e. parameters you can set) to fit your data. And in the case
    of ChatGPT, lots of such “knobs” are used—actually, 175 billion of them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 值得理解的是，从来没有“无模型的模型”。你使用的任何模型都有一定的基本结构——然后一组“你可以转动的旋钮”（即你可以设置的参数）来拟合你的数据。在ChatGPT的情况下，使用了许多这样的“旋钮”——实际上有1750亿个。
- en: But the remarkable thing is that the underlying structure of ChatGPT—with “just”
    that many parameters—is sufficient to make a model that computes next-word probabilities
    “well enough” to give us reasonable essay-length pieces of text.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 但值得注意的是，ChatGPT的基本结构——仅仅有那么多参数——足以构建一个计算下一个词概率“足够好”的模型，从而给我们合理长度的文章。
- en: Models for Human-Like Tasks
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人类任务的模型
- en: The example we gave above involves making a model for numerical data that essentially
    comes from simple physics—where we’ve known for several centuries that “simple
    mathematics applies”. But for ChatGPT we have to make a model of human-language
    text of the kind produced by a human brain. And for something like that we don’t
    (at least yet) have anything like “simple mathematics”. So what might a model
    of it be like?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们上面给出的例子涉及制作一个模型，用于来自简单物理的数值数据——几个世纪以来，我们已经知道“简单的数学适用”。但对于ChatGPT，我们必须制作一个模型，用于人类大脑产生的文本。对于这样的东西，我们（至少目前）没有类似于“简单的数学”。那么，这样的模型可能是什么样子呢？
- en: 'Before we talk about language, let’s talk about another human-like task: recognizing
    images. And as a simple example of this, let’s consider images of digits (and,
    yes, this is a [classic machine learning example](https://resources.wolframcloud.com/NeuralNetRepository/resources/050b1a0a-f43a-4c28-b7e0-72607a918467/)
    ):'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论语言之前，让我们先谈谈另一个类似人类任务：识别图像。作为一个简单的例子，让我们考虑数字的图像（是的，这是一个[经典的机器学习例子](https://resources.wolframcloud.com/NeuralNetRepository/resources/050b1a0a-f43a-4c28-b7e0-72607a918467/)）：
- en: '![](Image00030.gif)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00030.gif)'
- en: 'One thing we could do is get a bunch of sample images for each digit:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做的一件事是为每个数字获取一堆样本图像：
- en: '![](Image00031.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00031.jpg)'
- en: 'Then to find out if an image we’re given as input corresponds to a particular
    digit we could just do an explicit pixel-by-pixel comparison with the samples
    we have. But as humans we certainly seem to do something better—because we can
    still recognize digits, even when they’re for example handwritten, and have all
    sorts of modifications and distortions:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了找出我们输入的图像是否对应于特定的数字，我们可以将其与我们拥有的样本进行像素级比较。但作为人类，我们似乎做得更好——因为我们仍然能够识别数字，即使它们是手写的，而且经过各种修改和扭曲：
- en: '![](Image00032.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00032.jpg)'
- en: When we made a model for our numerical data above, we were able to take a numerical
    value *x* that we were given, and just compute *a + b x* for particular *a* and
    *b* . So if we treat the gray-level value of each pixel here as some variable
    *x[i]* is there some function of all those variables that—when evaluated—tells
    us what digit the image is of? It turns out that it’s possible to construct such
    a function. Not surprisingly, it’s not particularly simple, though. And a typical
    example might involve perhaps half a million mathematical operations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们为上面的数字数据建立模型时，我们能够拿到给定的数值*x*，然后只需计算特定*a*和*b*的*a + b x*。那么，如果我们将每个像素的灰度值视为某个变量*x[i]*，是否存在某个函数，当评估时告诉我们图像是哪个数字的？事实证明，构建这样的函数是可能的。毫不奇怪，这并不特别简单，一个典型的例子可能涉及大约五十万次数学运算。
- en: 'But the end result is that if we feed the collection of pixel values for an
    image into this function, out will come the number specifying which digit we have
    an image of. Later, we’ll talk about how such a function can be constructed, and
    the idea of neural nets. But for now let’s treat the function as black box, where
    we feed in images of, say, handwritten digits (as arrays of pixel values) and
    we get out the numbers these correspond to:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 但最终结果是，如果我们将图像的像素值集合输入到这个函数中，输出将是指定我们拥有的图像是哪个数字。稍后，我们将讨论如何构建这样一个函数，以及神经网络的概念。但现在让我们将这个函数视为黑匣子，我们输入手写数字的图像（作为像素值数组），然后得到对应的数字：
- en: '![](Image00033.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00033.jpg)'
- en: 'But what’s really going on here? Let’s say we progressively blur a digit. For
    a little while our function still “recognizes” it, here as a “2”. But soon it
    “loses it”, and starts giving the “wrong” result:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里真正发生了什么？假设我们逐渐模糊一个数字。有一段时间我们的函数仍然“识别”它，这里是一个“2”。但很快它“失去了”，开始给出“错误”的结果：
- en: '![](Image00034.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00034.jpg)'
- en: But why do we say it’s the “wrong” result? In this case, we know we got all
    the images by blurring a “2”. But if our goal is to produce a model of what humans
    can do in recognizing images, the real question to ask is what a human would have
    done if presented with one of those blurred images, without knowing where it came
    from.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么我们说这是“错误”的结果？在这种情况下，我们知道我们通过模糊“2”得到了所有这些图像。但如果我们的目标是产生一个模型，模拟人类在识别图像方面的能力，真正要问的问题是，如果向人类展示其中一张模糊的图像，而不知道它来自哪里，人类会做什么。
- en: And we have a “good model” if the results we get from our function typically
    agree with what a human would say. And the nontrivial scientific fact is that
    for an image-recognition task like this we now basically know how to construct
    functions that do this.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从我们的函数得到的结果通常与人类的判断一致，那么我们就有一个“好模型”。而非平凡的科学事实是，对于像这样的图像识别任务，我们现在基本上知道如何构建能够实现这一点的函数。
- en: Can we “mathematically prove” that they work? Well, no. Because to do that we’d
    have to have a mathematical theory of what we humans are doing. Take the “2” image
    and change a few pixels. We might imagine that with only a few pixels “out of
    place” we should still consider the image a “2”. But how far should that go? It’s
    a question of [human visual perception](https://www.wolframscience.com/nks/chap-10--processes-of-perception-and-analysis#sect-10-7--visual-perception)
    . And, yes, the answer would no doubt be different for bees or octopuses—and potentially
    [utterly different for putative aliens](https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/#alien-views-of-the-ruliad)
    .
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能“数学证明”它们有效吗？嗯，不行。因为要做到这一点，我们必须对我们人类正在做什么有一个数学理论。拿“2”图像并改变几个像素。我们可能会想象，即使只有几个像素“错位”，我们仍应该认为这是一个“2”。但这应该持续到什么程度？这是一个关于[人类视觉感知](https://www.wolframscience.com/nks/chap-10--processes-of-perception-and-analysis#sect-10-7--visual-perception)的问题。是的，答案无疑对蜜蜂或章鱼可能不同，对假设的外星人可能[完全不同](https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/#alien-views-of-the-ruliad)。
- en: Neural Nets
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络
- en: OK, so how do our typical models for tasks like [image recognition](https://writings.stephenwolfram.com/2015/05/wolfram-language-artificial-intelligence-the-image-identification-project/)
    actually work? The most popular—and successful—current approach uses [neural nets](https://reference.wolfram.com/language/guide/NeuralNetworks.html)
    . Invented—in a form remarkably close to their use today—[in the 1940s](https://www.wolframscience.com/nks/notes-10-12--history-of-ideas-about-thinking/)
    , neural nets can be thought of as simple idealizations of how [brains seem to
    work](https://www.wolframscience.com/nks/notes-10-12--the-brain/) .
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，那么我们用于[图像识别](https://writings.stephenwolfram.com/2015/05/wolfram-language-artificial-intelligence-the-image-identification-project/)等任务的典型模型实际上是如何工作的呢？目前最流行且最成功的方法使用[神经网络](https://reference.wolfram.com/language/guide/NeuralNetworks.html)。神经网络是在20世纪40年代发明的，其形式与今天的使用非常接近，可以被认为是对[大脑工作方式的简单理想化](https://www.wolframscience.com/nks/notes-10-12--the-brain/)。
- en: In human brains there are about 100 billion neurons (nerve cells), each capable
    of producing an electrical pulse up to perhaps a thousand times a second. The
    neurons are connected in a complicated net, with each neuron having tree-like
    branches allowing it to pass electrical signals to perhaps thousands of other
    neurons. And in a rough approximation, whether any given neuron produces an electrical
    pulse at a given moment depends on what pulses it’s received from other neurons—with
    different connections contributing with different “weights”.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 人类大脑中有大约1000亿个神经元（神经细胞），每个神经元每秒最多能产生一次电脉冲。这些神经元连接成一个复杂的网络，每个神经元都有树状的分支，使其能够向其他数千个神经元传递电信号。在一个粗略的近似中，任何给定的神经元在某一时刻是否产生电脉冲取决于它从其他神经元接收到的脉冲，不同的连接具有不同的“权重”。
- en: When we “see an image” what’s happening is that when photons of light from the
    image fall on (“photoreceptor”) cells at the back of our eyes they produce electrical
    signals in nerve cells. These nerve cells are connected to other nerve cells,
    and eventually the signals go through a whole sequence of layers of neurons. And
    it’s in this process that we “recognize” the image, eventually “forming the thought”
    that we’re “seeing a 2” (and maybe in the end doing something like saying the
    word “two” out loud).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们“看到一幅图像”时，光子从图像上落在我们眼睛后面的“光感受器”细胞上时，它们会在神经细胞中产生电信号。这些神经细胞连接到其他神经细胞，最终信号通过一系列神经元层。在这个过程中，我们“识别”图像，最终“形成思维”我们“看到一个2”（最终可能做一些像大声说“两”这样的事情）。
- en: 'The “black-box” function from the previous section is a “mathematicized” version
    of such a neural net. It happens to have 11 layers (though only 4 “core layers”):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节中的“黑匣子”函数是这样一个神经网络的“数学化”版本。它恰好有11层（尽管只有4个“核心层”）：
- en: '![](Image00035.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00035.jpg)'
- en: There’s nothing particularly “theoretically derived” about this neural net;
    it’s just something that—[back in 1998—was constructed as a piece of engineering](https://resources.wolframcloud.com/NeuralNetRepository/resources/LeNet-Trained-on-MNIST-Data/)
    , and found to work. (Of course, that’s not much different from how we might describe
    our brains as having been produced through the process of biological evolution.)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这种神经网络并没有什么特别“理论推导”的地方；它只是一种在1998年作为一种工程构建出来并被发现有效的东西。当然，这与我们描述大脑是通过生物进化过程产生的方式并没有太大不同。
- en: 'OK, but how does a neural net like this “recognize things”? The key is the
    [notion of attractors](https://www.wolframscience.com/nks/chap-6--starting-from-randomness#sect-6-7--the-notion-of-attractors)
    . Imagine we’ve got handwritten images of 1’s and 2’s:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，但是这样的神经网络如何“识别事物”呢？关键在于[吸引子的概念](https://www.wolframscience.com/nks/chap-6--starting-from-randomness#sect-6-7--the-notion-of-attractors)。想象一下我们有手写的1和2的图像：
- en: '![](Image00036.gif)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00036.gif)'
- en: We somehow want all the 1’s to “be attracted to one place”, and all the 2’s
    to “be attracted to another place”. Or, put a different way, if an image is somehow
    “[closer to being a 1](https://www.wolframscience.com/nks/notes-10-12--memory-analogs-with-numerical-data/)
    ” than to being a 2, we want it to end up in the “1 place” and vice versa.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望所有的1都“被吸引到一个地方”，所有的2都“被吸引到另一个地方”。换句话说，如果一幅图像在某种程度上“更接近于1”，而不是2，我们希望它最终出现在“1的位置”，反之亦然。
- en: 'As a straightforward analogy, let’s say we have certain positions in the plane,
    indicated by dots (in a real-life setting they might be positions of coffee shops).
    Then we might imagine that starting from any point on the plane we’d always want
    to end up at the closest dot (i.e. we’d always go to the closest coffee shop).
    We can represent this by dividing the plane into regions (“attractor basins”)
    separated by idealized “watersheds”:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个简单的类比，假设我们在平面上有某些位置，用点表示（在现实生活中，它们可能是咖啡店的位置）。然后我们可以想象，从平面上的任意点开始，我们总是希望最终到达最近的点（即我们总是去最近的咖啡店）。我们可以通过将平面分成由理想化的“分水岭”分隔的区域（“吸引子盆地”）来表示这一点：
- en: '![](Image00037.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00037.jpg)'
- en: We can think of this as implementing a kind of “recognition task” in which we’re
    not doing something like identifying what digit a given image “looks most like”—but
    rather we’re just, quite directly, seeing what dot a given point is closest to.
    (The “Voronoi diagram” setup we’re showing here separates points in 2D Euclidean
    space; the digit recognition task can be thought of as doing something very similar—but
    in a 784-dimensional space formed from the gray levels of all the pixels in each
    image.)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这看作是实现一种“识别任务”的过程，我们不是在识别给定图像“看起来最像哪个数字”之类的事情，而是直接看一个给定点最接近哪个点。（我们在这里展示的“Voronoi图”设置将二维欧几里得空间中的点分开；数字识别任务可以被认为是在一个由每个图像中所有像素的灰度级组成的784维空间中做类似的事情。）
- en: 'So how do we make a neural net “do a recognition task”? Let’s consider this
    very simple case:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何让神经网络“执行识别任务”呢？让我们考虑这个非常简单的情况：
- en: '![](Image00038.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00038.jpg)'
- en: 'Our goal is to take an “input” corresponding to a position {*x* ,*y* }—and
    then to “recognize” it as whichever of the three points it’s closest to. Or, in
    other words, we want the neural net to compute a function of {*x* ,*y* } like:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是接受一个对应于位置{*x*，*y*}的“输入”，然后将其“识别”为最接近的三个点之一。换句话说，我们希望神经网络计算出一个关于{*x*，*y*}的函数，如下所示：
- en: '![](Image00039.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00039.jpg)'
- en: 'So how do we do this with a neural net? Ultimately a neural net is a connected
    collection of idealized “neurons”—usually arranged in layers—with a simple example
    being:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何用神经网络实现这一点呢？最终，神经网络是一组理想化的“神经元”连接在一起的集合，通常排列成层，一个简单的例子如下：
- en: '![](Image00040.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00040.jpg)'
- en: 'Each “neuron” is effectively set up to evaluate a simple numerical function.
    And to “use” the network, we simply feed numbers (like our coordinates *x* and
    *y* ) in at the top, then have neurons on each layer “evaluate their functions”
    and feed the results forward through the network—eventually producing the final
    result at the bottom:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 每个“神经元”实际上被设置为评估一个简单的数值函数。为了“使用”网络，我们只需在顶部输入数字（如我们的坐标*x*和*y*），然后让每一层的神经元“评估它们的函数”并将结果向前传递通过网络——最终在底部产生最终结果：
- en: '![](Image00041.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00041.jpg)'
- en: In the traditional (biologically inspired) setup each neuron effectively has
    a certain set of “incoming connections” from the neurons on the previous layer,
    with each connection being assigned a certain “weight” (which can be a positive
    or negative number). The value of a given neuron is determined by multiplying
    the values of “previous neurons” by their corresponding weights, then adding these
    up and adding a constant—and finally applying a “thresholding” (or “activation”)
    function. In mathematical terms, if a neuron has inputs *x* = {*x* [1] , *x* [2]
    ...} then we compute *f* [*w* . *x* + *b* ], where the weights *w* and constant
    *b* are generally chosen differently for each neuron in the network; the function
    *f* is usually the same.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统（受生物启发的）设置中，每个神经元实际上具有来自前一层神经元的一定数量的“传入连接”，每个连接被分配一个特定的“权重”（可以是正数或负数）。给定神经元的值由将“前一神经元”的值乘以它们对应的权重，然后相加并加上一个常数——最后应用“阈值化”（或“激活”）函数来确定。在数学术语中，如果一个神经元有输入*x*
    = {*x*[1]，*x*[2]...}，那么我们计算*f* [*w*。*x* + *b*]，其中权重*w*和常数*b*通常对网络中的每个神经元选择不同；函数*f*通常是相同的。
- en: 'Computing *w* . *x* + *b* is just a matter of matrix multiplication and addition.
    The “activation function” *f* introduces nonlinearity (and ultimately is what
    leads to nontrivial behavior). Various activation functions commonly get used;
    here we’ll just use `[Ramp](http://reference.wolfram.com/language/ref/Ramp.html)`
    (or ReLU):'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 计算*w*。*x* + *b*只是矩阵乘法和加法的问题。 “激活函数”*f*引入了非线性（最终导致非平凡行为）。通常会使用各种激活函数；在这里我们将使用`[Ramp](http://reference.wolfram.com/language/ref/Ramp.html)`（或ReLU）：
- en: '![](Image00042.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00042.jpg)'
- en: For each task we want the neural net to perform (or, equivalently, for each
    overall function we want it to evaluate) we’ll have different choices of weights.
    (And—as we’ll discuss later—these weights are normally determined by “training”
    the neural net using machine learning from examples of the outputs we want.)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们希望神经网络执行的每个任务（或者等效地，对于我们希望它评估的每个整体函数），我们将有不同的权重选择。（并且——正如我们稍后将讨论的那样——这些权重通常是通过使用机器学习从我们想要的输出示例中“训练”神经网络来确定的。）
- en: 'Ultimately, every neural net just corresponds to some overall mathematical
    function—though it may be messy to write out. For the example above, it would
    be:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，每个神经网络只是对应于某个整体数学函数——尽管可能很难写出来。对于上面的例子，它将是：
- en: '![](Image00043.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00043.jpg)'
- en: The neural net of ChatGPT also just corresponds to a mathematical function like
    this—but effectively with billions of terms.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的神经网络也只是对应于这样一个数学函数——但实际上有数十亿个项。
- en: 'But let’s go back to individual neurons. Here are some examples of the functions
    a neuron with two inputs (representing coordinates *x* and *y* ) can compute with
    various choices of weights and constants (and `[Ramp](https://reference.wolfram.com/language/ref/Ramp.html)`
    as activation function):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们回到单个神经元。以下是具有两个输入（代表坐标*x*和*y*）的神经元可以使用各种权重和常数（以及`[Ramp](https://reference.wolfram.com/language/ref/Ramp.html)`作为激活函数）计算的一些函数示例：
- en: '![](Image00044.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00044.jpg)'
- en: 'But what about the larger network from above? Well, here’s what it computes:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 那么上面的更大网络呢？嗯，这是它计算的内容：
- en: '![](Image00045.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00045.jpg)'
- en: It’s not quite “right”, but it’s close to the “nearest point” function we showed
    above.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 它并不完全“正确”，但它接近我们上面展示的“最近点”函数。
- en: 'Let’s see what happens with some other neural nets. In each case, as we’ll
    explain later, we’re using machine learning to find the best choice of weights.
    Then we’re showing here what the neural net with those weights computes:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看其他一些神经网络会发生什么。在每种情况下，正如我们稍后将解释的那样，我们使用机器学习来找到最佳的权重选择。然后我们在这里展示这些权重的神经网络计算的内容：
- en: '![](Image00046.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00046.jpg)'
- en: Bigger networks generally do better at approximating the function we’re aiming
    for. And in the “middle of each attractor basin” we typically get exactly the
    answer we want. But [at the boundaries](https://www.wolframscience.com/nks/notes-10-12--memory-analogs-with-numerical-data/)
    —where the neural net “has a hard time making up its mind”—things can be messier.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的网络通常在逼近我们的目标函数时表现更好。在每个吸引子盆地的“中心”位置，我们通常会得到我们想要的确切答案。但是，在[边界处](https://www.wolframscience.com/nks/notes-10-12--memory-analogs-with-numerical-data/)——神经网络“难以做出决定”的地方——情况可能会更加混乱。
- en: 'With this simple mathematical-style “recognition task” it’s clear what the
    “right answer” is. But in the problem of recognizing handwritten digits, it’s
    not so clear. What if someone wrote a “2” so badly it looked like a “7”, etc.?
    Still, we can ask how a neural net distinguishes digits—and this gives an indication:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种简单的数学风格的“识别任务”，“正确答案”是明确的。但在识别手写数字的问题上，情况就不那么明确了。如果有人写的“2”看起来像“7”等等呢？尽管如此，我们可以询问神经网络如何区分数字——这给出了一个指示：
- en: '![](Image00047.gif)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00047.gif)'
- en: Can we say “mathematically” how the network makes its distinctions? Not really.
    It’s just “doing what the neural net does”. But it turns out that that normally
    seems to agree fairly well with the distinctions we humans make.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能“数学上”说出网络是如何做出区分的吗？实际上不行。它只是“做神经网络所做的事情”。但事实证明，这通常似乎与我们人类所做的区分相当一致。
- en: 'Let’s take a more elaborate example. Let’s say we have images of cats and dogs.
    And we have a [neural net that’s been trained to distinguish them](https://writings.stephenwolfram.com/2015/05/wolfram-language-artificial-intelligence-the-image-identification-project/)
    . Here’s what it might do on some examples:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举一个更详细的例子。假设我们有猫和狗的图片。我们有一个[经过训练来区分它们的神经网络](https://writings.stephenwolfram.com/2015/05/wolfram-language-artificial-intelligence-the-image-identification-project/)。以下是它在一些示例上可能会做的事情：
- en: '![](Image00048.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00048.jpg)'
- en: 'Now it’s even less clear what the “right answer” is. What about a dog dressed
    in a cat suit? Etc. Whatever input it’s given, the neural net is generating an
    answer. And, it turns out, to do it in a way that’s reasonably consistent with
    what humans might do. As I’ve said above, that’s not a fact we can “derive from
    first principles”. It’s just something that’s empirically been found to be true,
    at least in certain domains. But it’s a key reason why neural nets are useful:
    that they somehow capture a “human-like” way of doing things.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在“正确答案”甚至更不明确了。穿着猫服的狗呢？等等。无论输入什么，神经网络都会生成一个答案。而且，事实证明，它以一种与人类可能做的相当一致的方式来做。正如我上面所说的，这不是我们可以“从第一原则推导出来”的事实。这只是一种经验上被发现在某些领域至少是真实的东西。但这是神经网络有用的一个关键原因：它们以某种方式捕捉到了一种“类似人类”的做事方式。
- en: Show yourself a picture of a cat, and ask “Why is that a cat?”. Maybe you’d
    start saying “Well, I see its pointy ears, etc.” But it’s not very easy to explain
    how you recognized the image as a cat. It’s just that somehow your brain figured
    that out. But for a brain there’s no way (at least yet) to “go inside” and see
    how it figured it out. What about for an (artificial) neural net? Well, it’s straightforward
    to see what each “neuron” does when you show a picture of a cat. But even to get
    a basic visualization is usually very difficult.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 给自己展示一张猫的图片，并问“为什么那是一只猫？”。也许你会开始说“嗯，我看到了它尖尖的耳朵等等”。但解释你如何认出这张图片是一只猫并不容易。只是你的大脑以某种方式弄清楚了。但对于大脑来说，没有办法（至少目前还没有）“进入内部”并看看它是如何弄清楚的。那么对于（人造）神经网络呢？当你展示一张猫的图片时，看到每个“神经元”做什么是很���接的。但即使要获得基本的可视化通常也是非常困难的。
- en: In the final net that we used for the “nearest point” problem above there are
    17 neurons. In the net for recognizing handwritten digits there are 2190\. And
    in the net we’re using to recognize cats and dogs there are 60,650\. Normally
    it would be pretty difficult to visualize what amounts to 60,650-dimensional space.
    But because this is a network set up to deal with images, many of its layers of
    neurons are organized into arrays, like the arrays of pixels it’s looking at.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们用于上面“最近点”问题的最终网络中有17个神经元。在用于识别手写数字的网络中有2190个。而在我们用于识别猫和狗的网络中有60,650个。通常很难想象60,650维空间的情况。但因为这是一个用于处理图像的网络，它的许多神经元层都组织成数组，就像它正在查看的像素数组一样。
- en: And if we take a typical cat image
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们拿一张典型的猫的图片
- en: '![Cat](Image00049.jpg "Cat")'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![猫](Image00049.jpg "猫")'
- en: 'then we can represent the states of neurons at the first layer by a collection
    of derived images—many of which we can readily interpret as being things like
    “the cat without its background”, or “the outline of the cat”:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们可以通过一系列衍生图像来表示第一层神经元的状态——其中许多我们可以轻松解释为“没有背景的猫”，或者“猫的轮廓”：
- en: '![](Image00050.gif)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00050.gif)'
- en: 'By the 10th layer it’s harder to interpret what’s going on:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 到了第10层，很难解释发生了什么：
- en: '![](Image00051.gif)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00051.gif)'
- en: But in general we might say that the neural net is “picking out certain features”
    (maybe pointy ears are among them), and using these to determine what the image
    is of. But are those features ones for which we have names—like “pointy ears”?
    Mostly not.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 但总的来说，我们可以说神经网络“挑选出某些特征”（也许尖耳朵是其中之一），并使用这些特征来确定图像的内容。但这些特征是否是我们有名称的特征，比如“尖耳朵”？大多数情况下不是。
- en: Are our brains using similar features? Mostly we don’t know. But it’s notable
    that the first few layers of a neural net like the one we’re showing here seem
    to pick out aspects of images (like edges of objects) that seem to be similar
    to ones we know are picked out by the first level of visual processing in brains.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的大脑是否使用类似的特征？大多数情况下我们不知道。但值得注意的是，像我们在这里展示的神经网络的前几层似乎挑选出了图像的一些方面（如物体的边缘），这些方面似乎与我们知道的大脑视觉处理的第一层挑选出的方面相似。
- en: 'But let’s say we want a “theory of cat recognition” in neural nets. We can
    say: “Look, this particular net does it”—and immediately that gives us some sense
    of “how hard a problem” it is (and, for example, how many neurons or layers might
    be needed). But at least as of now we don’t have a way to “give a narrative description”
    of what the network is doing. And maybe that’s because it truly is computationally
    irreducible, and there’s no general way to find what it does except by explicitly
    tracing each step. Or maybe it’s just that we haven’t “figured out the science”,
    and identified the “natural laws” that allow us to summarize what’s going on.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 但假设我们想要一个关于神经网络中猫识别的“理论”。我们可以说：“看，这个特定的网络可以做到”——这立即让我们对“这是多么困难的问题”有了一些概念（例如，可能需要多少神经元或层）。但至少目前为止，我们没有办法“描述网络正在做什么”。也许这是因为它真的是计算上不可简化的，除非通过明确追踪每一步，否则没有一般方法可以找到它在做什么。或者可能只是因为我们还没有“弄清楚科学”，并且确定了允许我们总结正在发生的事情的“自然规律”。
- en: We’ll encounter the same kinds of issues when we talk about generating language
    with ChatGPT. And again it’s not clear whether there are ways to “summarize what
    it’s doing”. But the richness and detail of language (and our experience with
    it) may allow us to get further than with images.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论使用ChatGPT生成语言时，我们将遇到相同类型的问题。而且不清楚是否有方法“总结它在做什么”。但语言的丰富性和细节（以及我们对它的经验）可能使我们比处理图像时走得更远。
- en: Machine Learning, and the Training of Neural Nets
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习和神经网络的训练
- en: We’ve been talking so far about neural nets that “already know” how to do particular
    tasks. But what makes neural nets so useful (presumably also in brains) is that
    not only can they in principle do all sorts of tasks, but they can be incrementally
    “trained from examples” to do those tasks.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在谈论“已经知道”如何执行特定任务的神经网络。但神经网络如此有用的原因（可能也适用于大脑）不仅在于它们原则上可以执行各种任务，而且可以通过“逐步从示例中训练”来执行这些任务。
- en: When we make a neural net to distinguish cats from dogs we don’t effectively
    have to write a program that (say) explicitly finds whiskers; instead we just
    show lots of examples of what’s a cat and what’s a dog, and then have the network
    “machine learn” from these how to distinguish them.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们制作一个神经网络来区分猫和狗时，我们不需要编写一个明确查找胡须的程序；相反，我们只展示大量猫和狗的示例，然后让网络从中“机器学习”如何区分它们。
- en: And the point is that the trained network “generalizes” from the particular
    examples it’s shown. Just as we’ve seen above, it isn’t simply that the network
    recognizes the particular pixel pattern of an example cat image it was shown;
    rather it’s that the neural net somehow manages to distinguish images on the basis
    of what we consider to be some kind of “general catness”.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于训练后的网络从所展示的特定示例中“泛化”。正如我们之前所见，网络不仅仅是识别所展示的示例猫图像的特定像素模式；相反，神经网络以某种“一般猫的特性”为基础来区分图像。
- en: So how does neural net training actually work? Essentially what we’re always
    trying to do is to find weights that make the neural net successfully reproduce
    the examples we’ve given. And then we’re relying on the neural net to “interpolate”
    (or “generalize”) “between” these examples in a “reasonable” way.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 那么神经网络训练实际上是如何工作的呢？基本上，我们一直在尝试找到使神经网络成功复制我们给定示例的权重。然后我们依赖神经网络以“合理”的方式在这些示例之间“插值”（或“泛化”）。
- en: 'Let’s look at a problem even simpler than the nearest-point one above. Let’s
    just try to get a neural net to learn the function:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个比上面的最近点问题更简单的问题。让我们尝试让神经网络学习函数：
- en: '![](Image00052.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00052.jpg)'
- en: 'For this task, we’ll need a network that has just one input and one output,
    like:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个任务，我们需要一个只有一个输入和一个输出的网络，就像：
- en: '![](Image00053.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00053.jpg)'
- en: 'But what weights, etc. should we be using? With every possible set of weights
    the neural net will compute some function. And, for example, here’s what it does
    with a few randomly chosen sets of weights:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们应该使用什么权重等等？对于每组可能的权重，神经网络将计算一些函数。例如，这里是它对一些随机选择的权重集的处理结果：
- en: '![](Image00054.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00054.jpg)'
- en: And, yes, we can plainly see that in none of these cases does it get even close
    to reproducing the function we want. So how do we find weights that will reproduce
    the function?
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我们可以清楚地看到，在这些情况下，它甚至都没有接近我们想要的函数。那么我们如何找到能够复制函数的权重呢？
- en: 'The basic idea is to supply lots of “input → output” examples to “learn from”—and
    then to try to find weights that will reproduce these examples. Here’s the result
    of doing that with progressively more examples:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思想是提供大量“输入→输出”示例来“学习”—然后尝试找到能够复制这些示例的权重。这是逐渐增加示例的结果：
- en: '![](Image00055.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00055.jpg)'
- en: At each stage in this “training” the weights in the network are progressively
    adjusted—and we see that eventually we get a network that successfully reproduces
    the function we want. So how do we adjust the weights? The basic idea is at each
    stage to see “how far away we are” from getting the function we want—and then
    to update the weights in such a way as to get closer.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个“训练”的每个阶段，网络中的权重逐渐调整—我们看到最终我们得到了一个成功复制我们想要的函数的网络。那么我们如何调整权重呢？基本思想是在每个阶段看“我们离得到我们想要的函数有多远”—然后以使其更接近的方式更新权重。
- en: 'To find out “how far away we are” we compute what’s usually called a “loss
    function” (or sometimes “cost function”). Here we’re using a simple (L2) loss
    function that’s just the sum of the squares of the differences between the values
    we get, and the true values. And what we see is that as our training process progresses,
    the loss function progressively decreases (following a certain “learning curve”
    that’s different for different tasks)—until we reach a point where the network
    (at least to a good approximation) successfully reproduces the function we want:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找出“我们有多远”，我们计算通常称为“损失函数”（有时称为“成本函数”）的东西。在这里，我们使用一个简单的（L2）损失函数，它只是我们得到的值与真实值之间差值的平方和。我们看到随着训练过程的进行，损失函数逐渐减少（遵循不同任务的特定“学习曲线”）—直到我们达到一个点，网络（至少在很大程度上）成功地复制了我们想要的函数：
- en: '![](Image00056.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00056.jpg)'
- en: Alright, so the last essential piece to explain is how the weights are adjusted
    to reduce the loss function. As we’ve said, the loss function gives us a “distance”
    between the values we’ve got, and the true values. But the “values we’ve got”
    are determined at each stage by the current version of neural net—and by the weights
    in it. But now imagine that the weights are variables—say *w[i]* . We want to
    find out how to adjust the values of these variables to minimize the loss that
    depends on them.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，最后一个必要解释的要点是如何调整权重以减少损失函数。正如我们所说，损失函数给出了我们得到的值与真实值之间的“距离”。但是“我们得到的值”在每个阶段都由当前版本的神经网络确定—以及其中的权重。但现在想象一下权重是变量—比如*w[i]*。我们想找出如何调整这些变量的值以最小化依赖于它们的损失。
- en: 'For example, imagine (in an incredible simplification of typical neural nets
    used in practice) that we have just two weights *w* [1] and *w* [2] . Then we
    might have a loss that as a function of *w* [1] and *w* [2] looks like this:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象（在实践中使用的典型神经网络的极端简化中）我们只有两个权重*w* [1]和*w* [2]。那么我们可能会有一个损失函数，作为*w* [1]和*w*
    [2]的函数看起来像这样：
- en: '![](Image00057.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00057.jpg)'
- en: 'Numerical analysis provides a variety of techniques for finding the minimum
    in cases like this. But a typical approach is just to progressively follow the
    path of steepest descent from whatever previous *w* [1] , *w* [2] we had:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 数值分析提供了各种技术来找到这种情况下的最小值。但是一个典型的方法就是从我们之前的*w* [1]，*w* [2]开始逐渐沿着最陡下降的路径前进：
- en: '![](Image00058.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00058.jpg)'
- en: Like water flowing down a mountain, all that’s guaranteed is that this procedure
    will end up at some local minimum of the surface (“a mountain lake”); it might
    well not reach the ultimate global minimum.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 就像水流向下山一样，这个过程保证的只是最终会到达表面的某个局部最小值（“山湖”）；它很可能不会达到最终的全局最小值。
- en: It’s not obvious that it would be feasible to find the path of the steepest
    descent on the “weight landscape”. But calculus comes to the rescue. As we mentioned
    above, one can always think of a neural net as computing a mathematical function—that
    depends on its inputs, and its weights. But now consider differentiating with
    respect to these weights. It turns out that the chain rule of calculus in effect
    lets us “unravel” the operations done by successive layers in the neural net.
    And the result is that we can—at least in some local approximation—“invert” the
    operation of the neural net, and progressively find weights that minimize the
    loss associated with the output.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 很难说是否能够找到在“权重景观”上最陡下降的路径。但微积分来拯救。正如我们上面提到的，我们总是可以将神经网络看作计算一个依赖于其输入和权重的数学函数。但现在考虑对这些权重进行微分。事实证明，微积分的链式法则实际上让我们能够“解开”神经网络中各层所做的操作。结果是，我们至少在某种局部近似中可以“反转”神经网络的操作，并逐渐找到最小化与输出相关联的损失的权重。
- en: The picture above shows the kind of minimization we might need to do in the
    unrealistically simple case of just 2 weights. But it turns out that even with
    many more weights (ChatGPT uses 175 billion) it’s still possible to do the minimization,
    at least to some level of approximation. And in fact the big breakthrough in “deep
    learning” that occurred around 2011 was associated with the discovery that in
    some sense it can be easier to do (at least approximate) minimization when there
    are lots of weights involved than when there are fairly few.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图片展示了在只有2个权重的不切实际简单情况下可能需要做的最小化。但事实证明，即使有更多的权重（ChatGPT使用了1750亿个），仍然可以进行最小化，至少在某种程度上的近似。事实上，围绕2011年发生的“深度学习”重大突破与发现相关，发现在某种意义上，当涉及许多权重时，进行（至少近似）最小化可能比涉及相当少的权重更容易。
- en: In other words—somewhat counterintuitively—it can be easier to solve more complicated
    problems with neural nets than simpler ones. And the rough reason for this seems
    to be that when one has a lot of “weight variables” one has a high-dimensional
    space with “lots of different directions” that can lead one to the minimum—whereas
    with fewer variables it’s easier to end up getting stuck in a local minimum (“mountain
    lake”) from which there’s no “direction to get out”.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，有点反直觉的是，用神经网络解决更复杂的问题可能比解决更简单的问题更容易。这似乎是因为当有很多“权重变量”时，就有一个高维空间，有“许多不同的方向”可以引导我们到达最小值——而当变量较少时，很容易陷入局部最小值（“山湖”），从中没有“出路的方向”。
- en: 'It’s worth pointing out that in typical cases there are many different collections
    of weights that will all give neural nets that have pretty much the same performance.
    And usually in practical neural net training there are lots of random choices
    made—that lead to “different-but-equivalent solutions”, like these:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出的是，在典型情况下，有许多不同的权重集合都会给出几乎相同性能的神经网络。通常在实际的神经网络训练中会做出许多随机选择——导致“不同但等效的解决方案”，就像这些：
- en: '![](Image00059.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00059.jpg)'
- en: 'But each such “different solution” will have at least slightly different behavior.
    And if we ask, say, for an “extrapolation” outside the region where we gave training
    examples, we can get dramatically different results:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 但是每个“不同的解决方案”都会有至少稍微不同的行为。如果我们要求在我们提供训练示例的区域之外进行“外推”，我们可能会得到截然不同的结果：
- en: '![](Image00060.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00060.jpg)'
- en: But which of these is “right”? There’s really no way to say. They’re all “consistent
    with the observed data”. But they all correspond to different “innate” ways to
    “think about” what to do “outside the box”. And some may seem “more reasonable”
    to us humans than others.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 但哪一个是“正确”的？真的没有办法说。它们都“与观察到的数据一致”。但它们都对应于不同的“固有”思考方式，以“超越常规”的方式去思考该做什么。对我们人类来说，有些可能比其他的“更合理”。
- en: The Practice and Lore of Neural Net Training
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络训练的实践和传统
- en: Particularly over the past decade, there’ve been many advances in the art of
    training neural nets. And, yes, it is basically an art. Sometimes—especially in
    retrospect—one can see at least a glimmer of a “scientific explanation” for something
    that’s being done. But mostly things have been discovered by trial and error,
    adding ideas and tricks that have progressively built a significant lore about
    how to work with neural nets.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是在过去的十年里，神经网络训练的艺术取得了许多进展。是的，这基本上是一门艺术。有时候——尤其是事后看来——人们可以看到至少有一点“科学解释”来解释正在做的事情。但大多数情况下，这些都是通过试错发现的，逐渐积累了关于如何处理神经网络的重要知识。
- en: 'There are several key parts. First, there’s the matter of what architecture
    of neural net one should use for a particular task. Then there’s the critical
    issue of how one’s going to get the data on which to train the neural net. And
    increasingly one isn’t dealing with training a net from scratch: instead a new
    net can either directly incorporate another already-trained net, or at least can
    use that net to generate more training examples for itself.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个关键部分。首先，关于在特定任务中应该使用什么样的神经网络架构的问题。然后是如何获取用于训练神经网络的数据的关键问题。而且越来越多的情况下，我们不是从头开始训练一个网络：相反，一个新网络可以直接整合另一个已经训练好的网络，或者至少可以利用该网络为自己生成更多的训练样本。
- en: One might have thought that for every particular kind of task one would need
    a different architecture of neural net. But what’s been found is that the same
    architecture often seems to work even for apparently quite different tasks. At
    some level this reminds one of the [idea of universal computation](https://www.wolframscience.com/nks/chap-11--the-notion-of-computation#sect-11-3--the-phenomenon-of-universality)
    (and my [Principle of Computational Equivalence](https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence/)
    ), but, as I’ll discuss later, I think it’s more a reflection of the fact that
    the tasks we’re typically trying to get neural nets to do are “human-like” ones—and
    neural nets can capture quite general “human-like processes”.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 人们可能会认为，对于每种特定的任务，都需要不同的神经网络架构。但事实上发现，即使对于看似完全不同的任务，同样的架构通常也能起作用。在某种程度上，这让人想起了[通用计算的概念](https://www.wolframscience.com/nks/chap-11--the-notion-of-computation#sect-11-3--the-phenomenon-of-universality)（以及我的[计算等价原理](https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence/)），但正如我稍后将讨论的那样，我认为这更多地反映了我们通常试图让神经网络执行的任务是“类似人类”的任务，而神经网络可以捕捉相当一般的“类人过程”。
- en: In earlier days of neural nets, there tended to be the idea that one should
    “make the neural net do as little as possible”. For example, in [converting speech
    to text](https://reference.wolfram.com/language/ref/SpeechRecognize.html) it was
    thought that one should first analyze the audio of the speech, break it into phonemes,
    etc. But what was found is that—at least for “human-like tasks”—it’s usually better
    just to try to train the neural net on the “end-to-end problem”, letting it “discover”
    the necessary intermediate features, encodings, etc. for itself.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络的早期阶段，人们倾向于认为应该“让神经网络尽可能少地做事情”。例如，在[将语音转换为文本](https://reference.wolfram.com/language/ref/SpeechRecognize.html)时，人们认为应该先分析语音，将其分解为音素等。但发现的是，至少对于“类人任务”，通常最好只是尝试在“端到端问题”上训练神经网络，让它“发现”必要的中间特征、编码等。
- en: There was also the idea that one should introduce complicated individual components
    into the neural net, to let it in effect “explicitly implement particular algorithmic
    ideas”. But once again, this has mostly turned out not to be worthwhile; instead,
    it’s better just to deal with very simple components and let them “organize themselves”
    (albeit usually in ways we can’t understand) to achieve (presumably) the equivalent
    of those algorithmic ideas.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个想法，即应该将复杂的个别组件引入神经网络中，以使其实际上“明确实现特定的算法思想”。但再次，这在大多数情况下都被证明不值得；相反，最好只处理非常简单的组件，并让它们“自组织”（尽管通常以我们无法理解的方式）来实现（可能是）这些算法思想的等效物。
- en: That’s not to say that there are no “structuring ideas” that are relevant for
    neural nets. Thus, for example, having [2D arrays of neurons with local connections](https://reference.wolfram.com/language/ref/ConvolutionLayer.html)
    seems at least very useful in the early stages of processing images. And having
    patterns of connectivity that concentrate on “looking back in sequences” seems
    useful—as we’ll see later—in dealing with things like human language, for example
    in ChatGPT.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说对于神经网络没有相关的“结构性思想”。因此，例如，具有[具有局部连接的2D神经元数组](https://reference.wolfram.com/language/ref/ConvolutionLayer.html)在处理图像的早期阶段至少似乎非常有用。并且具有集中于“向后查看序列”的连接模式似乎很有用——正如我们稍后将看到的——在处理诸如人类语言之类的事物时，例如在ChatGPT中。
- en: 'But an important feature of neural nets is that—like computers in general—they’re
    ultimately just dealing with data. And current neural nets—with current approaches
    to neural net training—[specifically deal with arrays of numbers](https://reference.wolfram.com/language/guide/NetEncoderDecoder.html)
    . But in the course of processing, those arrays can be completely rearranged and
    reshaped. And as an example, [the network we used for identifying digits above](https://resources.wolframcloud.com/NeuralNetRepository/resources/LeNet-Trained-on-MNIST-Data/)
    starts with a 2D “image-like” array, quickly “thickening“ to many channels, but
    then [“concentrating down” into a 1D array](https://reference.wolfram.com/language/ref/AggregationLayer.html)
    that will ultimately contain elements representing the different possible output
    digits:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 但神经网络的一个重要特征是——就像一般的计算机一样——它们最终只是在处理数据。而当前的神经网络——使用当前的神经网络训练方法——[具体处理数字数组](https://reference.wolfram.com/language/guide/NetEncoderDecoder.html)。但在处理过程中，这些数组可以被完全重新排列和重塑。例如，[我们用于识别上述数字的网络](https://resources.wolframcloud.com/NeuralNetRepository/resources/LeNet-Trained-on-MNIST-Data/)从一个2D“类似图像”的数组开始，迅速“加厚”到许多通道，然后[“集中”到一个1D数组](https://reference.wolfram.com/language/ref/AggregationLayer.html)，最终包含代表不同可能输出数字的元素：
- en: '![](Image00061.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00061.jpg)'
- en: But, OK, how can one tell how big a neural net one will need for a particular
    task? It’s something of an art. At some level the key thing is to know “how hard
    the task is”. But for human-like tasks that’s typically very hard to estimate.
    Yes, there may be a systematic way to do the task very “mechanically” by computer.
    But it’s hard to know if there are what one might think of as tricks or shortcuts
    that allow one to do the task at least at a “human-like level” vastly more easily.
    It might take [enumerating a giant game tree](https://writings.stephenwolfram.com/2022/06/games-and-puzzles-as-multicomputational-systems/)
    to “mechanically” play a certain game; but there might be a much easier (“heuristic”)
    way to achieve “human-level play”.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，好吧，一个人如何能够确定为特定任务需要多大的神经网络呢？这在某种程度上是一门艺术。关键是要知道“任务有多难”。但对于类似人类的任务，通常很难估计。是的，可能有一种系统的方法可以通过计算机“机械地”完成任务。但很难知道是否有可以让人以“类似人类水平”更轻松地完成任务的技巧或捷径。可能需要[列举一个巨大的游戏树](https://writings.stephenwolfram.com/2022/06/games-and-puzzles-as-multicomputational-systems/)来“机械地”玩某个游戏；但可能有一种更简单（“启发式”）的方法来实现“人类水平的游戏”。
- en: 'When one’s dealing with tiny neural nets and simple tasks one can sometimes
    explicitly see that one “can’t get there from here”. For example, here’s the best
    one seems to be able to do on the task from the previous section with a few small
    neural nets:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理微小的神经网络和简单的任务时，有时可以明确看到自己“无法从这里到达那里”。例如，以下是在上一节中使用几个小型神经网络时似乎能够完成的任务的最佳结果：
- en: '![](Image00062.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00062.jpg)'
- en: 'And what we see is that if the net is too small, it just can’t reproduce the
    function we want. But above some size, it has no problem—at least if one trains
    it for long enough, with enough examples. And, by the way, these pictures illustrate
    a piece of neural net lore: that one can often get away with a smaller network
    if there’s a “squeeze” in the middle that forces everything to go through a smaller
    intermediate number of neurons. (It’s also worth mentioning that “no-intermediate-layer”—or
    so-called “[perceptron](https://en.wikipedia.org/wiki/Perceptron) ”—networks can
    only learn essentially linear functions—but as soon as there’s even one intermediate
    layer it’s [always in principle possible](https://en.wikipedia.org/wiki/Universal_approximation_theorem)
    to approximate any function arbitrarily well, at least if one has enough neurons,
    though to make it feasibly trainable one typically has some kind of [regularization
    or normalization](https://reference.wolfram.com/language/ref/BatchNormalizationLayer.html)
    .)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如果神经网络太小，我们发现它就无法复现我们想要的功能。但是在某个大小以上，只要训练足够长时间，提供足够的例子，它就没有问题。顺便说一句，这些图片展示了神经网络传说的一部分：如果中间有一个“挤压”，强制所有东西通过较小数量的中间神经元，通常可以用较小的网络来解决问题。（值得一提的是，“无中间层”或所谓的“[感知器](https://en.wikipedia.org/wiki/Perceptron)”网络只能学习基本线性函数，但只要有一个中间层，原则上就可以任意精确地逼近任何函数，至少如果有足够多的神经元，尽管为了使其可行地训练，通常会有某种[正则化或归一化](https://reference.wolfram.com/language/ref/BatchNormalizationLayer.html)。）
- en: OK, so let’s say one’s settled on a certain neural net architecture. Now there’s
    the issue of getting data to train the network with. And many of the practical
    challenges around neural nets—and machine learning in general—center on acquiring
    or preparing the necessary training data. In many cases (“supervised learning”)
    one wants to get explicit examples of inputs and the outputs one is expecting
    from them. Thus, for example, one might want images tagged by what’s in them,
    or some other attribute. And maybe one will have to explicitly go through—usually
    with great effort—and do the tagging. But very often it turns out to be possible
    to piggyback on something that’s already been done, or use it as some kind of
    proxy. And so, for example, one might use alt tags that have been provided for
    images on the web. Or, in a different domain, one might use closed captions that
    have been created for videos. Or—for language translation training—one might use
    parallel versions of webpages or other documents that exist in different languages.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，假设我们已经确定了某种神经网络架构。现在问题是获取用于训练网络的数据。许多关于神经网络以及机器学习的实际挑战集中在获取或准备必要的训练数据上。在许多情况下（“监督学习”），人们希望获得输入的明确示例以及预期的输出。因此，例如，人们可能希望对图像进行标记，标记它们的内容或其他属性。也许人们将不得不明确地经过一番努力进行标记。但很多时候，事实证明可以依靠已经完成的工作，或将其用作某种代理。因此，例如，人们可能会使用网络上提供的图像的alt标签。或者，在不同的领域，人们可能会使用为视频创建的闭路字幕。或者—对于语言翻译训练—人们可能会使用存在于不同语言中的网页或其他文档的平行版本。
- en: How much data do you need to show a neural net to train it for a particular
    task? Again, it’s hard to estimate from first principles. Certainly the requirements
    can be dramatically reduced by using “transfer learning” to “transfer in” things
    like lists of important features that have already been learned in another network.
    But generally neural nets need to “see a lot of examples” to train well. And at
    least for some tasks it’s an important piece of neural net lore that the examples
    can be incredibly repetitive. And indeed it’s a standard strategy to just show
    a neural net all the examples one has, over and over again. In each of these “training
    rounds” (or “epochs”) the neural net will be in at least a slightly different
    state, and somehow “reminding it” of a particular example is useful in getting
    it to “remember that example”. (And, yes, perhaps this is analogous to the usefulness
    of repetition in human memorization.)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要展示多少数据给神经网络来训练它完成特定任务？再次强调，从第一原则出发很难估计。当然，通过使用“迁移学习”将已经在另一个网络中学习过的重要特征列表等内容“迁入”，可以大大减少需求量。但通常神经网络需要“看到很多例子”才能训练良好。对于一些任务来说，神经网络传统知识中的一个重要部分是例子可能会非常重复。事实上，一个标准策略就是反复向神经网络展示所有已有的例子。在每个“训练轮次”（或“时代”）中，神经网络至少会处于稍微不同的状态，某种程度上“提醒它”某个特定例子对于让它“记住那个例子”是有用的。（是的，也许这类似于人类记忆中重复的有用性。）
- en: But often just repeating the same example over and over again isn’t enough.
    It’s also necessary to show the neural net variations of the example. And it’s
    a feature of neural net lore that those “data augmentation” variations don’t have
    to be sophisticated to be useful. Just slightly modifying images with basic image
    processing can make them essentially “as good as new” for neural net training.
    And, similarly, when one’s run out of actual video, etc. for training self-driving
    cars, one can go on and just get data from running simulations in a model videogame-like
    environment without all the detail of actual real-world scenes.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 但通常仅仅反复展示同一个例子是不够的。还需要展示例子的变化给神经网络。神经网络传统知识中的一个特点是，这些“数据增强”变化并不需要很复杂就能起到作用。只需用基本图像处理稍微修改图像，就可以使它们在神经网络训练中基本“一样好”。同样地，当用于自动驾驶汽车的实际视频等训练数据用尽时，可以继续在模拟类似视频游戏环境中运行模拟，并从中获取数据，而无需所有实际现实场景的细节。
- en: How about something like ChatGPT? Well, it has the nice feature that it can
    do “unsupervised learning”, making it much easier to get it examples to train
    from. Recall that the basic task for ChatGPT is to figure out how to continue
    a piece of text that it’s been given. So to get it “training examples” all one
    has to do is get a piece of text, and mask out the end of it, and then use this
    as the “input to train from”—with the “output” being the complete, unmasked piece
    of text. We’ll discuss this more later, but the main point is that—unlike, say,
    for learning what’s in images—there’s no “explicit tagging” needed; ChatGPT can
    in effect just learn directly from whatever examples of text it’s given.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 那么像 ChatGPT 这样的东西呢？它有一个很好的特点，即可以进行“无监督学习”，这样更容易为其提供训练例子。回想一下，ChatGPT 的基本任务是找出如何继续给定的一段文本。因此，要获得“训练例子”，我们只需获取一段文本，将其末尾遮盖，然后将其用作“训练输入”，而“输出”则是完整的、未遮盖的文本。我们稍后会更详细地讨论这一点，但主要观点是，与学习图像内容不同，ChatGPT
    不需要“显式标记”；它实际上可以直接从给定的文本例子中学习。
- en: OK, so what about the actual learning process in a neural net? In the end it’s
    all about determining what weights will best capture the training examples that
    have been given. And there are all sorts of detailed choices and “hyperparameter
    settings” (so called because the weights can be thought of as “parameters”) that
    can be used to tweak how this is done. There are different [choices of loss function](https://reference.wolfram.com/language/ref/CrossEntropyLossLayer.html)
    (sum of squares, sum of absolute values, etc.). There are different ways to do
    loss minimization (how far in weight space to move at each step, etc.). And then
    there are questions like how big a “batch” of examples to show to get each successive
    estimate of the loss one’s trying to minimize. And, yes, one can apply machine
    learning (as we do, for example, in Wolfram Language) to automate machine learning—and
    to automatically set things like hyperparameters.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，在神经网络中的实际学习过程是怎样的呢？最终，一切都是关于确定哪些权重能最好地捕捉已给出的训练示例。有各种详细的选择和“超参数设置”（所谓的因为权重可以被视为“参数”）可以用来调整如何完成这项工作。有不同的[损失函数选择](https://reference.wolfram.com/language/ref/CrossEntropyLossLayer.html)（平方和、绝对值和等）。有不同的损失最小化方法（在每一步中在权重空间中移动多远等）。然后还有诸如展示多大“批量”示例以获得每个连续估计的损失等问题。是的，人们可以应用机器学习（例如我们在Wolfram语言中所做的）来自动化机器学习，并自动设置诸如超参数之类的事物。
- en: 'But in the end the whole process of training can be characterized by seeing
    how the loss progressively decreases (as in this [Wolfram Language progress monitor
    for a small training](https://reference.wolfram.com/language/ref/NetTrain.html)
    ):'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 但最终，整个训练过程可以通过观察损失如何逐渐减少来描述（如在这个[Wolfram语言小训练进度监视器中](https://reference.wolfram.com/language/ref/NetTrain.html)）：
- en: '![](Image00063.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00063.jpg)'
- en: And what one typically sees is that the loss decreases for a while, but eventually
    flattens out at some constant value. If that value is sufficiently small, then
    the training can be considered successful; otherwise it’s probably a sign one
    should try changing the network architecture.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，人们会看到损失在一段时间内减少，但最终会在某个固定值上趋于平缓。如果该值足够小，则可以认为训练是成功的；否则，这可能是需要尝试改变网络架构的迹象。
- en: Can one tell how long it should take for the “learning curve” to flatten out?
    Like for so many other things, there seem to be approximate [power-law scaling
    relationships](https://arxiv.org/pdf/2001.08361.pdf) that depend on the size of
    neural net and amount of data one’s using. But the general conclusion is that
    training a neural net is hard—and takes a lot of computational effort. And as
    a practical matter, the vast majority of that effort is spent doing operations
    on arrays of numbers, which is what GPUs are good at—which is why neural net training
    is typically limited by the availability of GPUs.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一个人能否判断“学习曲线”何时趋于平缓？就像许多其他事情一样，似乎存在依赖于所使用的神经网络大小和数据量的近似[幂律缩放关系](https://arxiv.org/pdf/2001.08361.pdf)。但总的结论是，训练神经网络很困难，需要大量的计算工作。作为一个实际问题，其中绝大部分工作是在数字数组上进行操作，这正是GPU擅长的——这就是为什么神经网络训练通常受到GPU可用性的限制。
- en: In the future, will there be fundamentally better ways to train neural nets—or
    generally do what neural nets do? Almost certainly, I think. The fundamental idea
    of neural nets is to create a flexible “computing fabric” out of a large number
    of simple (essentially identical) components—and to have this “fabric” be one
    that can be incrementally modified to learn from examples. In current neural nets,
    one’s essentially using the ideas of calculus—applied to real numbers—to do that
    incremental modification. But it’s increasingly clear that having high-precision
    numbers doesn’t matter; 8 bits or less might be enough even with current methods.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，是否会有根本更好的方法来训练神经网络，或者一般来说做神经网络所做的事情？我几乎可以肯定，是的。神经网络的基本思想是利用大量简单（基本上相同）的组件创建一个灵活的“计算结构”，并使这个“结构”能够逐步修改以从示例中学习。在当前的神经网络中，基本上是使用微积分的思想——应用于实数——来进行这种逐步修改。但越来越清楚的是，高精度的数字并不重要；即使使用当前的方法，8位或更少可能足够。
- en: With [computational systems like cellular automata](https://www.wolframscience.com/nks/chap-2--the-crucial-experiment#sect-2-1--how-do-simple-programs-behave)
    that basically operate in parallel on many individual bits it’s never been clear
    [how to do this kind of incremental modification](https://content.wolfram.com/uploads/sites/34/2020/07/approaches-complexity-engineering.pdf)
    , but there’s no reason to think it isn’t possible. And in fact, much like with
    the “[deep-learning breakthrough of 2012](https://en.wikipedia.org/wiki/AlexNet)
    ” it may be that such incremental modification will effectively be easier in more
    complicated cases than in simple ones.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[细胞自动机等计算系统](https://www.wolframscience.com/nks/chap-2--the-crucial-experiment#sect-2-1--how-do-simple-programs-behave)基本上在许多个体位上并行运行，从来没有清楚过[如何进行这种渐进式修改](https://content.wolfram.com/uploads/sites/34/2020/07/approaches-complexity-engineering.pdf)，但没有理由认为这是不可能的。
    事实上，就像“2012年的深度学习突破”一样，也许在更复杂的情况下，这种渐进式修改实际上会比简单情况更容易。
- en: Neural nets—perhaps a bit like brains—are set up to have an essentially fixed
    network of neurons, with what’s modified being the strength (“weight”) of connections
    between them. (Perhaps in at least young brains significant numbers of wholly
    new connections can also grow.) But while this might be a convenient setup for
    biology, it’s not at all clear that it’s even close to the best way to achieve
    the functionality we need. And something that involves the equivalent of progressive
    network rewriting (perhaps reminiscent of our [Physics Project](https://www.wolframphysics.org/)
    ) might well ultimately be better.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络——或许有点像大脑——被设置为具有基本固定的神经元网络，修改的是它们之间连接的强度（“权重”）。 （也许至少在年轻的大脑中，完全新的连接也可以增长。）但是，虽然这对生物学来说可能是一个方便的设置，但目前还不清楚这是否接近我们需要实现功能的最佳方式。
    而且，涉及到类似于渐进式网络重写的东西（也许让人想起我们的[物理项目](https://www.wolframphysics.org/)）最终可能会更好。
- en: 'But even within the framework of existing neural nets there’s currently a crucial
    limitation: neural net training as it’s now done is fundamentally sequential,
    with the effects of each batch of examples being propagated back to update the
    weights. And indeed with current computer hardware—even taking into account GPUs—most
    of a neural net is “idle” most of the time during training, with just one part
    at a time being updated. And in a sense this is because our current computers
    tend to have memory that is separate from their CPUs (or GPUs). But in brains
    it’s presumably different—with every “memory element” (i.e. neuron) also being
    a potentially active computational element. And if we could set up our future
    computer hardware this way it might become possible to do training much more efficiently.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 但即使在现有神经网络框架内，目前存在一个关键限制：神经网络训练目前是基本上顺序进行的，每批示例的影响被传播回来更新权重。 而且，即使考虑到GPU，当前计算机硬件——在训练过程中，大部分神经网络大部分时间都是“空闲”的，只有一部分在更新。
    从某种意义上说，这是因为我们当前的计算机往往具有与其CPU（或GPU）分开的内存。 但在大脑中，这可能是不同的——每个“记忆元素”（即神经元）也可能是一个潜在的活跃计算元素。
    如果我们能够这样设置未来的计算机硬件，可能会更有效地进行训练。
- en: “Surely a Network That’s Big Enough Can Do Anything!”
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “当然，足够大的网络可以做任何事情！”
- en: The capabilities of something like ChatGPT seem so impressive that one might
    imagine that if one could just “keep going” and train larger and larger neural
    networks, then they’d eventually be able to “do everything”. And if one’s concerned
    with things that are readily accessible to immediate human thinking, it’s quite
    possible that this is the case. But the lesson of the past several hundred years
    of science is that there are things that can be figured out by formal processes,
    but aren’t readily accessible to immediate human thinking.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 像ChatGPT这样的东西的能力看起来非常令人印象深刻，以至于人们可能会想象，如果能够“继续下去”并训练越来越大的神经网络，那么它们最终将能够“做任何事情”。
    如果一个人关心的是那些对立即人类思维可获得的事物，那么这种情况很可能是真实的。 但是过去几百年科学的教训是，有些事情可以通过正式过程找出，但并不容易立即被人类思维所理解。
- en: 'Nontrivial mathematics is one big example. But the general case is really computation.
    And ultimately the issue is the phenomenon of [computational irreducibility](https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility)
    . There are some computations which one might think would take many steps to do,
    but which can in fact be “reduced” to something quite immediate. But the discovery
    of computational irreducibility implies that this doesn’t always work. And instead
    there are processes—probably like the one below—where to work out what happens
    inevitably requires essentially tracing each computational step:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 非平凡数学就是一个很好的例子。但一般情况下，真正的问题是计算。最终问题在于[计算不可简化性现象](https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility)。有些计算可能需要很多步骤才能完成，但实际上可以“简化”为相当直接的事情。但计算不可简化性的发现意味着这并不总是奏效。相反，有一些过程——可能类似于下面的过程——需要基本上追踪每个计算步骤才能弄清楚发生了什么：
- en: '![](Image00064.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00064.jpg)'
- en: The kinds of things that we normally do with our brains are presumably specifically
    chosen to avoid computational irreducibility. It takes special effort to do math
    in one’s brain. And it’s in practice largely impossible to “think through” the
    steps in the operation of any nontrivial program just in one’s brain.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常用大脑做的事情可能是特意选择的，以避免计算不可简化性。在大脑中进行数学运算需要特殊的努力。而在大脑中“思考”任何非平凡程序的运行步骤在实践中几乎是不可能的。
- en: But of course for that we have computers. And with computers we can readily
    do long, computationally irreducible things. And the key point is that there’s
    in general no shortcut for these.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们有计算机。有了计算机，我们可以轻松地进行长时间的、计算不可简化的事情。关键在于，通常没有这方面的捷径。
- en: Yes, we could memorize lots of specific examples of what happens in some particular
    computational system. And maybe we could even see some (“computationally reducible”)
    patterns that would allow us to do a little generalization. But the point is that
    computational irreducibility means that we can never guarantee that the unexpected
    won’t happen—and it’s only by explicitly doing the computation that you can tell
    what actually happens in any particular case.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我们可以记住许多特定计算系统中发生的事例。也许我们甚至能看到一些（“计算可简化的”）模式，使我们能够进行一些泛化。但关键在于，计算不可简化性意味着我们永远无法保证不会发生意外——只有通过明确进行计算，你才能知道在任何特定情况下实际发生了什么。
- en: And in the end there’s just a fundamental tension between learnability and computational
    irreducibility. Learning involves in effect [compressing data by leveraging regularities](https://www.wolframscience.com/nks/chap-10--processes-of-perception-and-analysis/)
    . But computational irreducibility implies that ultimately there’s a limit to
    what regularities there may be.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，学习能力和计算不可简化性之间存在根本的张力。学习实际上涉及[通过利用规律来压缩数据](https://www.wolframscience.com/nks/chap-10--processes-of-perception-and-analysis/)。但计算不可简化性意味着最终存在着规律性的限制。
- en: As a practical matter, one can imagine building little computational devices—like
    cellular automata or Turing machines—into trainable systems like neural nets.
    And indeed such devices can serve as good “tools” for the neural net—like [Wolfram|Alpha
    can be a good tool for ChatGPT](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)
    . But computational irreducibility implies that one can’t expect to “get inside”
    those devices and have them learn.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个实际问题，人们可以想象将小型计算设备——比如细胞自动机或图灵机——构建到像神经网络这样的可训练系统中。实际上，这样的设备可以作为神经网络的良好“工具”——就像[Wolfram|Alpha可以成为ChatGPT的好工具](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)。但是计算不可简化性意味着我们不能指望“进入”这些设备并让它们学习。
- en: 'Or put another way, there’s an ultimate tradeoff between capability and trainability:
    the more you want a system to make “true use” of its computational capabilities,
    the more it’s going to show computational irreducibility, and the less it’s going
    to be trainable. And the more it’s fundamentally trainable, the less it’s going
    to be able to do sophisticated computation.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 或者换个说法，能力和可训练性之间存在着最终的权衡：你希望系统充分利用其计算能力，它就会展现出计算不可简化性，而可训练性就会降低。而基本上可训练性越强，它就越无法进行复杂的计算。
- en: (For ChatGPT as it currently is, the situation is actually much more extreme,
    because the neural net used to generate each token of output is a pure “feed-forward”
    network, without loops, and therefore has no ability to do any kind of computation
    with nontrivial “control flow”.)
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: （对于当前的ChatGPT系统来说，情况实际上更加极端，因为用于生成每个输出标记的神经网络是一个纯“前馈”网络，没有循环，因此无法进行任何具有非平凡“控制流”计算。）
- en: Of course, one might wonder whether it’s actually important to be able to do
    irreducible computations. And indeed for much of human history it wasn’t particularly
    important. But our modern technological world has been built on engineering that
    makes use of at least mathematical computations—and increasingly also more general
    computations. And if we look at the natural world, it’s [full of irreducible computation](https://www.wolframscience.com/nks/chap-8--implications-for-everyday-systems/)
    —that we’re slowly understanding how to emulate and use for our technological
    purposes.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，人们可能会想知道是否能够进行不可约计算实际上很重要。事实上，在人类历史的大部分时间里，这并不特别重要。但我们现代的技术世界是建立在至少利用数学计算的工程基础上的，而且越来越多地也利用更一般的计算。如果我们看看自然界，它充满了不可约计算——我们正在逐渐理解如何模拟并利用它们来实现我们的技术目的。
- en: Yes, a neural net can certainly notice the kinds of regularities in the natural
    world that we might also readily notice with “unaided human thinking”. But if
    we want to work out things that are in the purview of mathematical or computational
    science the neural net isn’t going to be able to do it—unless it effectively “uses
    as a tool” an “ordinary” computational system.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，神经网络当然可以注意到自然界中我们可能也可以轻松注意到的“无辅助人类思维”中的规律。但是，如果我们想解决数学或计算科学范围内的问题，神经网络是做不到的——除非它有效地“作为工具”使用一个“普通”的计算系统。
- en: But there’s something potentially confusing about all of this. In the past there
    were plenty of tasks—including writing essays—that we’ve assumed were somehow
    “fundamentally too hard” for computers. And now that we see them done by the likes
    of ChatGPT we tend to suddenly think that computers must have become vastly more
    powerful—in particular surpassing things they were already basically able to do
    (like progressively computing the behavior of computational systems like cellular
    automata).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 但所有这些可能会让人感到困惑。过去有很多任务，包括写文章，我们认为计算机在某种程度上“基本上太难了”。现在我们看到像ChatGPT这样的系统完成这些任务，我们突然认为计算机必须变得更加强大——特别是超越了它们已经基本能够做到的事情（比如逐步计算细胞自动机等计算系统的行为）。
- en: But this isn’t the right conclusion to draw. Computationally irreducible processes
    are still computationally irreducible, and are still fundamentally hard for computers—even
    if computers can readily compute their individual steps. And instead what we should
    conclude is that tasks—like writing essays—that we humans could do, but we didn’t
    think computers could do, are actually in some sense computationally easier than
    we thought.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不是正确的结论。计算上不可约的过程仍然是计算上不可约的，对于计算机来说仍然是基本困难的，即使计算机可以轻松计算它们的各个步骤。我们应该得出的结论是，我们人类可以做到的任务，比如写文章，我们以前认为计算机无法做到，实际上在某种意义上比我们想象的要容易一些。
- en: In other words, the reason a neural net can be successful in writing an essay
    is because writing an essay turns out to be a “computationally shallower” problem
    than we thought. And in a sense this takes us closer to “having a theory” of how
    we humans manage to do things like writing essays, or in general deal with language.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，神经网络能够成功地写一篇文章的原因是因为写一篇文章事实上是一个比我们想象的“计算上更浅”的问题。在某种意义上，这使我们更接近于“拥有一个理论”，解释我们人类如何做到像写文章这样的事情，或者一般地处理语言。
- en: If you had a big enough neural net then, yes, you might be able to do whatever
    humans can readily do. But you wouldn’t capture what the natural world in general
    can do—or that the tools that we’ve fashioned from the natural world can do. And
    it’s the use of those tools—both practical and conceptual—that have allowed us
    in recent centuries to transcend the boundaries of what’s accessible to “pure
    unaided human thought”, and capture for human purposes more of what’s out there
    in the physical and computational universe.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个足够大的神经网络，那么，是的，你可能能够做任何人类可以轻松做到的事情。但你不会捕捉到自然界一般可以做到的事情——或者我们从自然界中制造的工具可以做到的事情。正是这些工具的使用——无论是实际的还是概念上的——在近几个世纪里使我们超越了“纯粹无助的人类思维”所能接触到的边界，并为人类目的捕捉到更多物理和计算宇宙中的东西。
- en: The Concept of Embeddings
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入的概念
- en: Neural nets—at least as they’re currently set up—are fundamentally based on
    numbers. So if we’re going to to use them to work on something like text we’ll
    need a way to [represent our text with numbers](https://reference.wolfram.com/language/guide/NetEncoderDecoder.html)
    . And certainly we could start (essentially as ChatGPT does) by just assigning
    a number to every word in the dictionary. But there’s an important idea—that’s
    for example central to ChatGPT—that goes beyond that. And it’s the idea of “embeddings”.
    One can think of an embedding as a way to try to represent the “essence” of something
    by an array of numbers—with the property that “nearby things” are represented
    by nearby numbers.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络——至少在它们当前的设置中——基本上是基于数字的。因此，如果我们要用它们来处理类似文本这样的东西，我们需要一种方法来用数字来[表示我们的文本](https://reference.wolfram.com/language/guide/NetEncoderDecoder.html)。当然，我们可以开始（基本上就像ChatGPT一样）只是给字典中的每个单词分配一个数字。但有一个重要的想法——比如ChatGPT中的核心想法——超越了这一点。这就是“嵌入”的概念。人们可以将嵌入看作是一种尝试用一系列数字来表示某物的“本质”的方式，具有“附近的事物”由附近的数字表示的属性。
- en: 'And so, for example, we can think of a word embedding as trying to [lay out
    words in a kind of “meaning space”](https://reference.wolfram.com/language/ref/FeatureSpacePlot.html)
    in which words that are somehow “nearby in meaning” appear nearby in the embedding.
    The actual embeddings that are used—say in ChatGPT—tend to involve large lists
    of numbers. But if we project down to 2D, we can show examples of how words are
    laid out by the embedding:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，例如，我们可以将单词嵌入视为试图在一种“意义空间”中[展示单词](https://reference.wolfram.com/language/ref/FeatureSpacePlot.html)，在这个空间中，某种程度上“意义相近”的单词会在嵌入中附近出现。实际使用的嵌入——比如在ChatGPT中——往往涉及大量的数字列表。但如果我们投影到2D，我们可以展示单词如何被嵌入布局：
- en: '![](Image00065.gif)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00065.gif)'
- en: And, yes, what we see does remarkably well in capturing typical everyday impressions.
    But how can we construct such an embedding? Roughly the idea is to look at large
    amounts of text (here 5 billion words from the web) and then see “how similar”
    the “environments” are in which different words appear. So, for example, “alligator”
    and “crocodile” will often appear almost interchangeably in otherwise similar
    sentences, and that means they’ll be placed nearby in the embedding. But “turnip”
    and “eagle” won’t tend to appear in otherwise similar sentences, so they’ll be
    placed far apart in the embedding.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我们看到的确实很好地捕捉了典型的日常印象。但是我们如何构建这样的嵌入呢？大致的想法是查看大量文本（这里是来自网络的50亿个单词），然后看看不同单词出现在其中的“环境”有多相似。因此，例如，“鳄鱼”和“鳄鱼”通常会几乎可以互换地出现在其他类似的句子中，这意味着它们会在嵌入中附近放置。但“萝卜”和“老鹰”不太可能出现在其他类似的句子中，因此它们会在嵌入中远离放置。
- en: But how does one actually implement something like this using neural nets? Let’s
    start by talking about embeddings not for words, but for images. We want to find
    some way to characterize images by lists of numbers in such a way that “images
    we consider similar” are assigned similar lists of numbers.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如何使用神经网络实际实现这样的东西呢？让我们首先讨论不是针对单词而是针对图像的嵌入。我们希望找到一种方法，以列表的数字来表征图像，这样“我们认为相似的图像”被分配相似的数字列表。
- en: How do we tell if we should “consider images similar”? Well, if our images are,
    say, of handwritten digits we might “consider two images similar” if they are
    of the same digit. Earlier we discussed a neural net that was trained to recognize
    handwritten digits. And we can think of this neural net as being set up so that
    in its final output it puts images into 10 different bins, one for each digit.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何判断是否应该“认为图像相似”呢？嗯，如果我们的图像是手写数字，我们可能会“认为两个图像相似”如果它们是相同的数字。早些时候，我们讨论过一个训练用于识别手写数字的神经网络。我们可以将这个神经网络看作是设置成在最终输出中将图像放入10个不同的箱子中，每个箱子代表一个数字。
- en: But what if we “intercept” what’s going on inside the neural net before the
    final “it’s a ‘4’” decision is made? We might expect that inside the neural net
    there are numbers that characterize images as being “mostly 4-like but a bit 2-like”
    or some such. And the idea is to pick up such numbers to use as elements in an
    embedding.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果我们在最终“这是一个‘4’”决定被做出之前“拦截”神经网络内部发生的事情呢？我们可能期望在神经网络内部有一些数字，用来表征图像“大部分像4但有点像2”之类的特征。这个想法是挑选这样的数字用作嵌入的元素。
- en: So here’s the concept. Rather than directly trying to characterize “what image
    is near what other image”, we instead consider a well-defined task (in this case
    digit recognition) for which we can get explicit training data—then use the fact
    that in doing this task the neural net implicitly has to make what amount to “nearness
    decisions”. So instead of us ever explicitly having to talk about “nearness of
    images” we’re just talking about the concrete question of what digit an image
    represents, and then we’re “leaving it to the neural net” to implicitly determine
    what that implies about “nearness of images”.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这里是概念。我们不是直接试图表征“哪个图像靠近哪个图像”，而是考虑一个明确定义的任务（在这种情况下是数字识别），我们可以获得明确的训练数据，然后利用这个事实，神经网络在执行这个任务时隐含地必须做出“接近决策”。因此，我们不需要明确讨论“图像的接近程度”，我们只是在讨论图像代表什么数字这个具体问题，然后“交给神经网络”隐含地确定这对“图像的接近程度”意味着什么。
- en: 'So how in more detail does this work for the digit recognition network? We
    can think of the network as consisting of 11 successive layers, that we might
    summarize iconically like this (with activation functions shown as separate layers):'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这种方法在数字识别网络中是如何更详细地工作的呢？我们可以将网络看作由11个连续层组成，我们可以用这种方式图标化地总结（激活函数显示为单独的层）：
- en: '![](Image00066.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00066.jpg)'
- en: At the beginning we’re feeding into the first layer actual images, represented
    by 2D arrays of pixel values. And at the end—from the last layer—we’re getting
    out an array of 10 values, which we can think of saying “how certain” the network
    is that the image corresponds to each of the digits 0 through 9.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始时，我们将实际图像（由像素值的2D数组表示）输入到第一层中。而在最后一层，我们得到一个包含10个值的数组，我们可以认为这个数组表示网络对图像与数字0到9的对应关系的“确定程度”。
- en: 'Feed in the image ![](Image00067.jpg) and the values of the neurons in that
    last layer are:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像 ![](Image00067.jpg) ，那最后一层神经元的值是：
- en: '![](Image00068.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00068.jpg)'
- en: In other words, the neural net is by this point “incredibly certain” that this
    image is a 4—and to actually get the output “4” we just have to pick out the position
    of the neuron with the largest value.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，到这一点，神经网络“非常确定”这个图像是一个4—为了实际得到输出“4”，我们只需挑选出具有最大值的神经元的位置。
- en: 'But what if we look one step earlier? The very last operation in the network
    is a so-called [softmax](https://reference.wolfram.com/language/ref/SoftmaxLayer.html)
    which tries to “force certainty”. But before that’s been applied the values of
    the neurons are:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们再往前看一步呢？网络中的最后一个操作是所谓的[softmax](https://reference.wolfram.com/language/ref/SoftmaxLayer.html)，它试图“强制确定性”。但在应用之前，神经元的值是：
- en: '![](Image00069.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00069.jpg)'
- en: 'The neuron representing “4” still has the highest numerical value. But there’s
    also information in the values of the other neurons. And we can expect that this
    list of numbers can in a sense be used to characterize the “essence” of the image—and
    thus to provide something we can use as an embedding. And so, for example, each
    of the 4’s here has a slightly different “signature” (or “feature embedding”)—all
    very different from the 8’s:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 代表“4”的神经元仍然具有最高的数值。但其他神经元的值也包含信息。我们可以期望这些数字列表在某种意义上可以用来表征图像的“本质”，从而提供我们可以用作嵌入的东西。因此，例如，这里的每个4都有略微不同的“签名”（或“特征嵌入”）—都与8完全不同：
- en: '![](Image00070.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00070.jpg)'
- en: Here we’re essentially using 10 numbers to characterize our images. But it’s
    often better to use much more than that. And for example in our digit recognition
    network we can get an array of 500 numbers by tapping into the preceding layer.
    And this is probably a reasonable array to use as an “image embedding”.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们基本上使用 10 个数字来描述我们的图像。但通常最好使用更多的数字。例如，在我们的数字识别网络中，我们可以通过访问前一层获得一个包含 500 个数字的数组。这可能是一个合理的“图像嵌入”数组。
- en: 'If we want to make an explicit visualization of “image space” for handwritten
    digits we need to “reduce the dimension”, effectively by projecting the 500-dimensional
    vector we’ve got into, say, 3D space:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要对手写数字的“图像空间”进行明确的可视化，我们需要“降低维度”，有效地将我们得到的 500 维向量投影到，比如，3D 空间中：
- en: '![](Image00071.gif)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00071.gif)'
- en: We’ve just talked about creating a characterization (and thus embedding) for
    images based effectively on identifying the similarity of images by determining
    whether (according to our training set) they correspond to the same handwritten
    digit. And we can do the same thing much more generally for images if we have
    a training set that identifies, say, which of 5000 common types of object (cat,
    dog, chair, ...) each image is of. And in this way we can make an image embedding
    that’s “anchored” by our identification of common objects, but then “generalizes
    around that” according to the behavior of the neural net. And the point is that
    insofar as that behavior aligns with how we humans perceive and interpret images,
    this will end up being an embedding that “seems right to us”, and is useful in
    practice in doing “human-judgement-like” tasks.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚讨论了基于识别图像相似性有效地创建图像的表征（从而嵌入）的内容，通过确定（根据我们的训练集）它们是否对应于相同的手写数字。如果我们有一个训练集，可以更一般地对图像执行相同的操作，识别出每个图像属于哪种
    5000 种常见对象（猫、狗、椅子，...）。通过这种方式，我们可以创建一个由我们对常见对象的识别“锚定”的图像嵌入，但然后根据神经网络的行为“泛化”。关键在于，只要这种行为与我们人类感知和解释图像的方式一致，这将最终成为一个对我们“看起来正确”的嵌入，并且在实践中对执行“类似人类判断”的任务非常有用。
- en: OK, so how do we follow the same kind of approach to find embeddings for words?
    The key is to start from a task about words for which we can readily do training.
    And the standard such task is “word prediction”. Imagine we’re given “the ___
    cat”. Based on a large corpus of text (say, the text content of the web), what
    are the probabilities for different words that might “fill in the blank”? Or,
    alternatively, given “___ black ___” what are the probabilities for different
    “flanking words”?
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么我们如何遵循相同的方法来为单词找到嵌入？关键是从一个关于单词的任务开始，我们可以很容易进行训练。标准的这种任务是“单词预测”。想象一下，我们得到了“the
    ___ cat”。根据大量文本语料库（比如，网络的文本内容），不同可能“填空”的单词的概率是多少？或者，另一种情况是，给定“___ black ___”，不同“两侧单词”的概率是多少？
- en: How do we set this problem up for a neural net? Ultimately we have to formulate
    everything in terms of numbers. And one way to do this is just to assign a unique
    number to each of the 50,000 or so common words in English. So, for example, “the”
    might be 914, and “cat” (with a space before it) might be 3542\. (And these are
    the actual numbers used by GPT-2.) So for the “the ___ cat” problem, our input
    might be {914, 3542}. What should the output be like? Well, it should be a list
    of 50,000 or so numbers that effectively give the probabilities for each of the
    possible “fill-in” words. And once again, to find an embedding, we want to “intercept”
    the “insides” of the neural net just before it “reaches its conclusion”—and then
    pick up the list of numbers that occur there, and that we can think of as “characterizing
    each word”.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何为神经网络设置这个问题？最终，我们必须用数字来表达一切。一种方法就是为英语中的大约 50,000 个常见单词中的每一个分配一个唯一的数字。因此，例如，“the”
    可能是 914，而“cat”（前面带有空格）可能是 3542。 （这些是 GPT-2 实际使用的数字。）因此，对于“the ___ cat”问题，我们的输入可能是
    {914, 3542}。输出应该是什么样的呢？嗯，它应该是一个包含大约 50,000 个数字的列表，有效地给出每个可能的“填充”单词的概率。再一次，为了找到一个嵌入，我们希望在神经网络“达成结论”之前“拦截”其“内部”，然后获取出现在那里的数字列表，并且我们可以将其视为“表征每个单词”。
- en: OK, so what do those characterizations look like? Over the past 10 years there’ve
    been a sequence of different systems developed ([word2vec](https://resources.wolframcloud.com/NeuralNetRepository/resources/ConceptNet-Numberbatch-Word-Vectors-V17.06/)
    , [GloVe](https://resources.wolframcloud.com/NeuralNetRepository/search/?i=GloVe)
    , [BERT](https://resources.wolframcloud.com/NeuralNetRepository/search/?i=BERT)
    , [GPT](https://resources.wolframcloud.com/NeuralNetRepository/resources/GPT2-Transformer-Trained-on-WebText-Data/)
    , ...), each based on a different neural net approach. But ultimately all of them
    take words and characterize them by lists of hundreds to thousands of numbers.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么这些特征看起来是什么样子的呢？在过去的10年里，已经开发了一系列不同的系统（[word2vec](https://resources.wolframcloud.com/NeuralNetRepository/resources/ConceptNet-Numberbatch-Word-Vectors-V17.06/)，[GloVe](https://resources.wolframcloud.com/NeuralNetRepository/search/?i=GloVe)，[BERT](https://resources.wolframcloud.com/NeuralNetRepository/search/?i=BERT)，[GPT](https://resources.wolframcloud.com/NeuralNetRepository/resources/GPT2-Transformer-Trained-on-WebText-Data/)，...），每个系统都基于不同的神经网络方法。但最终，它们都将单词通过数百到数千个数字的列表来表征。
- en: 'In their raw form, these “embedding vectors” are quite uninformative. For example,
    here’s what GPT-2 produces as the raw embedding vectors for three specific words:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在它们的原始形式中，这些“嵌入向量”并不具有信息量。例如，这里是GPT-2为三个特定单词生成的原始嵌入向量：
- en: '![](Image00072.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00072.jpg)'
- en: If we do things like measure distances between these vectors, then we can find
    things like “nearnesses” of words. Later we’ll discuss in more detail what we
    might consider the “cognitive” significance of such embeddings. But for now the
    main point is that we have a way to usefully turn words into “neural-net-friendly”
    collections of numbers.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们像测量这些向量之间的距离这样的事情，那么我们可以找到词语之间的“接近度”。稍后我们将更详细地讨论这些嵌入的“认知”意义。但现在的主要观点是，我们有一种有用的方法，可以将单词转化为“神经网络友好”的数字集合。
- en: But actually we can go further than just characterizing words by collections
    of numbers; we can also do this for sequences of words, or indeed whole blocks
    of text. And inside ChatGPT that’s how it’s dealing with things. It takes the
    text it’s got so far, and generates an embedding vector to represent it. Then
    its goal is to find the probabilities for different words that might occur next.
    And it represents its answer for this as a list of numbers that essentially give
    the probabilities for each of the 50,000 or so possible words.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 但实际上，我们可以进一步，不仅仅通过数字集合来表征单词；我们也可以对单词序列，甚至整个文本块进行这样的操作。在ChatGPT内部，它就是这样处理事情的。它获取到目前为止的文本，并生成一个嵌入向量来代表它。然后，它的目标是找到可能出现的下一个单词的概率。它将其答案表示为一系列数字，这些数字基本上给出了大约50,000个可能单词的概率。
- en: (Strictly, ChatGPT does not deal with words, but [rather with “tokens”](https://platform.openai.com/tokenizer)
    —convenient linguistic units that might be whole words, or might just be pieces
    like “pre” or “ing” or “ized”. Working with tokens makes it easier for ChatGPT
    to handle rare, compound and non-English words, and, sometimes, for better or
    worse, to invent new words.)
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: （严格来说，ChatGPT不处理单词，而是[处理“标记”](https://platform.openai.com/tokenizer)—方便的语言单位，可能是整个单词，也可能只是像“pre”或“ing”或“ized”这样的部分。使用标记使ChatGPT更容易处理罕见、复合和非英语单词，有时，好或坏，也更容易创造新单词。）
- en: Inside ChatGPT
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在ChatGPT内部
- en: OK, so we’re finally ready to discuss what’s inside ChatGPT. And, yes, ultimately,
    it’s a giant neural net—currently a version of the so-called GPT-3 network with
    175 billion weights. In many ways this is a neural net very much like the other
    ones we’ve discussed. But it’s a neural net that’s particularly set up for dealing
    with language. And its most notable feature is a piece of neural net architecture
    called a “transformer”.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们终于准备好讨论ChatGPT内部的内容了。是的，最终，它是一个巨大的神经网络—目前是一个拥有1750亿个权重的所谓GPT-3网络的版本。在许多方面，这是一个与我们讨论过的其他神经网络非常相似的神经网络。但它是一个特别用于处理语言的神经网络。它最显著的特点是一种名为“transformer”的神经网络架构。
- en: In the first neural nets we discussed above, every neuron at any given layer
    was basically connected (at least with some weight) to every neuron on the layer
    before. But this kind of fully connected network is (presumably) overkill if one’s
    working with data that has particular, known structure. And thus, for example,
    in the early stages of dealing with images, it’s typical to use so-called [convolutional
    neural nets](https://reference.wolfram.com/language/ref/ConvolutionLayer.html)
    (“convnets”) in which neurons are effectively laid out on a grid analogous to
    the pixels in the image—and connected only to neurons nearby on the grid.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面讨论的第一个神经网络中，每个神经元在任何给定层上基本上都与前一层的每个神经元连接（至少具有一定的权重）。但是，如果处理具有特定已知结构的数据，这种全连接网络（据推测）可能是过度的。因此，例如，在处理图像的早期阶段，通常使用所谓的[卷积神经网络](https://reference.wolfram.com/language/ref/ConvolutionLayer.html)（“卷积网络”），其中神经元实际上布置在类似于图像中的像素的网格上，并且仅与网格上附近的神经元连接。
- en: The idea of transformers is to do something at least somewhat similar for sequences
    of tokens that make up a piece of text. But instead of just defining a fixed region
    in the sequence over which there can be connections, transformers instead introduce
    the notion of “[attention](https://reference.wolfram.com/language/ref/AttentionLayer.html)
    ”—and the idea of “paying attention” more to some parts of the sequence than others.
    Maybe one day it’ll make sense to just start a generic neural net and do all customization
    through training. But at least as of now it seems to be critical in practice to
    “modularize” things—as transformers do, and probably as our brains also do.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器的理念是对构成一段文本的标记序列做出至少在某种程度上类似的事情。但是，变压器不是仅仅定义一个固定区域，使得在该区域内可以建立连接，而是引入了“[注意力](https://reference.wolfram.com/language/ref/AttentionLayer.html)”的概念——以及“更多地关注”序列的某些部分的想法。也许有一天，直接启动一个通用神经网络并通过训练进行所有定制会有意义。但至少目前来看，在实践中“模块化”事物似乎至关重要——就像变压器所做的，也可能是我们的大脑所做的。
- en: OK, so what does ChatGPT (or, rather, the GPT-3 network on which it’s based)
    actually do? Recall that its overall goal is to continue text in a “reasonable”
    way, based on what it’s seen from the training it’s had (which consists in looking
    at billions of pages of text from the web, etc.) So at any given point, it’s got
    a certain amount of text—and its goal is to come up with an appropriate choice
    for the next token to add.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么 ChatGPT（或者说，它基于的 GPT-3 网络）实际上是做什么的呢？回想一下，它的总体目标是以“合理”的方式继续文本，基于它从训练中看到的内容（这包括查看来自网络等的数十亿页文本）。因此，在任何给定时刻，它都有一定量的文本—它的目标是提出适当的选择，以添加下一个标记。
- en: It operates in three basic stages. First, it takes the sequence of tokens that
    corresponds to the text so far, and finds an embedding (i.e. an array of numbers)
    that represents these. Then it operates on this embedding—in a “standard neural
    net way”, with values “rippling through” successive layers in a network—to produce
    a new embedding (i.e. a new array of numbers). It then takes the last part of
    this array and generates from it an array of about 50,000 values that turn into
    probabilities for different possible next tokens. (And, yes, it so happens that
    there are about the same number of tokens used as there are common words in English,
    though only about 3000 of the tokens are whole words, and the rest are fragments.)
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 它分为三个基本阶段。首先，它获取与迄今为止的文本相对应的标记序列，并找到代表这些标记的嵌入（即一组数字数组）。然后，它以“标准神经网络方式”在这个嵌入上操作，数值“通过”网络中的连续层产生一个新的嵌入（即一个新的数字数组）。然后，它取这个数组的最后部分，并从中生成大约
    50,000 个值的数组，这些值转化为不同可能的下一个标记的概率。（是的，碰巧使用的标记数量与英语中常用单词的数量大致相同，尽管只有大约 3000 个标记是完整的单词，其余是片段。）
- en: A critical point is that every part of this pipeline is implemented by a neural
    network, whose weights are determined by end-to-end training of the network. In
    other words, in effect nothing except the overall architecture is “explicitly
    engineered”; everything is just “learned” from training data.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键点是，这个流水线的每个部分都由一个神经网络实现，其权重由网络的端到端训练确定。换句话说，实际上除了整体架构之外，没有任何部分是“明确设计”的；一切都只是从训练数据中“学习”而来。
- en: There are, however, plenty of details in the way the architecture is set up—reflecting
    all sorts of experience and neural net lore. And—even though this is definitely
    going into the weeds—I think it’s useful to talk about some of those details,
    not least to get a sense of just what goes into building something like ChatGPT.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，架构设置中有很多细节—反映了各种经验和神经网络传说。即使这显然是深入细节了—我认为谈论一些这些细节是有用的，至少可以让人了解构建像ChatGPT这样的东西需要付出多少努力。
- en: 'First comes the embedding module. Here’s a schematic Wolfram Language representation
    for it for GPT-2:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是嵌入模块。这里是GPT-2的Wolfram语言示意图表示：
- en: '![](Image00073.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00073.jpg)'
- en: The input is a [vector of *n* tokens](https://reference.wolfram.com/language/ref/netencoder/SubwordTokens.html)
    (represented as in the previous section by integers from 1 to about 50,000). Each
    of these tokens is converted (by a [single-layer neural net](https://reference.wolfram.com/language/ref/EmbeddingLayer.html)
    ) into an embedding vector (of length 768 for GPT-2 and 12,288 for ChatGPT’s GPT-3).
    Meanwhile, there’s a “secondary pathway” that takes the [sequence of (integer)
    positions](https://reference.wolfram.com/language/ref/SequenceIndicesLayer.html)
    for the tokens, and from these integers creates another embedding vector. And
    finally the embedding vectors from the token value and the token position are
    [added together](https://reference.wolfram.com/language/ref/ThreadingLayer.html)
    —to produce the final sequence of embedding vectors from the embedding module.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 输入是一个[由*n*个标记组成的向量](https://reference.wolfram.com/language/ref/netencoder/SubwordTokens.html)（如前一节中所示，由1到约50,000的整数表示）。这些标记中的每一个都被（通过[单层神经网络](https://reference.wolfram.com/language/ref/EmbeddingLayer.html)）转换为一个嵌入向量（对于GPT-2为长度768，对于ChatGPT的GPT-3为长度12,288）。同时，还有一个“次要路径”，它获取标记的（整数）位置序列，并从这些整数创建另一个嵌入向量。最后，来自标记值和标记位置的嵌入向量被[相加在一起](https://reference.wolfram.com/language/ref/ThreadingLayer.html)
    —生成来自嵌入模块的最终嵌入向量序列。
- en: Why does one just add the token-value and token-position embedding vectors together?
    I don’t think there’s any particular science to this. It’s just that various different
    things have been tried, and this is one that seems to work. And it’s part of the
    lore of neural nets that—in some sense—so long as the setup one has is “roughly
    right” it’s usually possible to home in on details just by doing sufficient training,
    without ever really needing to “understand at an engineering level” quite how
    the neural net has ended up configuring itself.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要将标记值和标记位置嵌入向量简单相加？我认为这并没有什么特别的科学依据。只是尝试了各种不同的方法，这种方法似乎有效。而神经网络的传说部分是—在某种意义上—只要所拥有的设置“大致正确”，通常可以通过足够的训练来逐步细化细节，而无需真正需要“在工程层面上理解”神经网络是如何配置自己的。
- en: 'Here’s what the embedding module does, operating on the string *hello hello
    hello hello hello hello hello hello hello hello bye bye bye bye bye bye bye bye
    bye bye* :'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这是嵌入模块的操作，作用于字符串*hello hello hello hello hello hello hello hello hello hello
    bye bye bye bye bye bye bye bye bye bye*：
- en: '![](Image00074.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00074.jpg)'
- en: The elements of the embedding vector for each token are shown down the page,
    and across the page we see first a run of “*hello* ” embeddings, followed by a
    run of “*bye* ” ones. The second array above is the positional embedding—with
    its somewhat-random-looking structure being just what “happened to be learned”
    (in this case in GPT-2).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 每个标记的嵌入向量的元素显示在页面下方，横跨页面我们首先看到一系列“*hello*”嵌入，然后是一系列“*bye*”嵌入。上面的第二个数组是位置嵌入—其看起来有些随机的结构只是“学到的”（在这种情况下是GPT-2）。
- en: 'OK, so after the embedding module comes the “main event” of the transformer:
    a sequence of so-called “attention blocks” (12 for GPT-2, 96 for ChatGPT’s GPT-3).
    It’s all pretty complicated—and reminiscent of typical large hard-to-understand
    engineering systems, or, for that matter, biological systems. But anyway, here’s
    a schematic representation of a single “attention block” (for GPT-2):'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，所以在嵌入模块之后是变压器的“主要事件”：一系列所谓的“注意力块”（GPT-2有12个，ChatGPT的GPT-3有96个）。这一切都相当复杂，让人想起典型的难以理解的大型工程系统，或者说生物系统。但无论如何，这里是GPT-2的单个“注意力块”的示意图表示：
- en: '![](Image00075.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00075.jpg)'
- en: Within each such attention block there are a collection of “attention heads”
    (12 for GPT-2, 96 for ChatGPT’s GPT-3)—each of which operates independently on
    different chunks of values in the embedding vector. (And, yes, we don’t know any
    particular reason why it’s a good idea to split up the embedding vector, or what
    the different parts of it “mean”; this is just one of those things that’s been
    “found to work”.)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个这样的注意力块中，有一组“注意力头”（对于GPT-2有12个，对于ChatGPT的GPT-3有96个）——每个头在嵌入向量中的不同值块上独立操作。
    （是的，我们不知道为什么将嵌入向量分割开是个好主意，或者它的不同部分“意味着”什么；这只是那些“发现有效”的事情之一。）
- en: OK, so what do the attention heads do? Basically they’re a way of “looking back”
    in the sequence of tokens (i.e. in the text produced so far), and “packaging up
    the past” in a form that’s useful for finding the next token. [In the first section
    above](text00005.html#What_Is_ChatGPT_Doing_..._and_Why_Does_It_Work_-1) we talked
    about using 2-gram probabilities to pick words based on their immediate predecessors.
    What the “attention” mechanism in transformers does is to allow “attention to”
    even much earlier words—thus potentially capturing the way, say, verbs can refer
    to nouns that appear many words before them in a sentence.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，注意头是做什么的？基本上，它们是一种“回顾”标记序列（即迄今为止生成的文本），并以对于找到下一个标记有用的形式“打包过去”。[在上面的第一节](text00005.html#What_Is_ChatGPT_Doing_..._and_Why_Does_It_Work_-1)中，我们讨论了使用2-gram概率根据它们的直接前导词选择单词。变压器中的“注意力”机制所做的是允许“注意力”甚至更早的单词——因此潜在地捕捉到动词可以指代在句子中出现在它们之前许多单词的名词的方式。
- en: 'At a more detailed level, what an attention head does is to recombine chunks
    in the embedding vectors associated with different tokens, with certain weights.
    And so, for example, the 12 attention heads in the first attention block (in GPT-2)
    have the following (“look-back-all-the-way-to-the-beginning-of-the-sequence-of-tokens”)
    patterns of “recombination weights” for the “*hello* , *bye* ” string above:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在更详细的层面上，注意头所做的是重新组合与不同标记相关的嵌入向量中的块，具有一定的权重。因此，例如，在第一个注意力块中的12个注意力头（在GPT-2中）对于上述“*hello*，*bye*”字符串的“回溯到标记序列开始”的“重新组合权重”模式如下：
- en: '![](Image00076.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00076.jpg)'
- en: 'After being processed by the attention heads, the resulting “re-weighted embedding
    vector” (of length 768 for GPT-2 and length 12,288 for ChatGPT’s GPT-3) is passed
    through a standard [“fully connected” neural net layer](https://reference.wolfram.com/language/ref/LinearLayer.html)
    . It’s hard to get a handle on what this layer is doing. But here’s a plot of
    the 768×768 matrix of weights it’s using (here for GPT-2):'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在被注意力头处理后，生成的“重新加权嵌入向量”（对于GPT-2长度为768，对于ChatGPT的GPT-3长度为12,288）通过一个标准的[“全连接”神经网络层](https://reference.wolfram.com/language/ref/LinearLayer.html)。很难理解这一层在做什么。但这里是它使用的768×768权重矩阵的绘图（这里是GPT-2的）：
- en: '![](Image00077.gif)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00077.gif)'
- en: 'Taking 64×64 moving averages, some (random-walk-ish) structure begins to emerge:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 通过64×64的移动平均值，一些（类似随机漫步的）结构开始显现：
- en: '![](Image00078.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00078.jpg)'
- en: What determines this structure? Ultimately it’s presumably some “neural net
    encoding” of features of human language. But as of now, what those features might
    be is quite unknown. In effect, we’re “opening up the brain of ChatGPT” (or at
    least GPT-2) and discovering, yes, it’s complicated in there, and we don’t understand
    it—even though in the end it’s producing recognizable human language.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 是什么决定了这种结构？最终，这可能是人类语言特征的某种“神经网络编码”。但目前，这些特征可能是相当未知的。实际上，我们正在“打开ChatGPT的大脑”（或至少是GPT-2），发现，是的，里面很复杂，我们并不理解它——尽管最终它产生了可识别的人类语言。
- en: 'OK, so after going through one attention block, we’ve got a new embedding vector—which
    is then successively passed through additional attention blocks (a total of 12
    for GPT-2; 96 for GPT-3). Each attention block has its own particular pattern
    of “attention” and “fully connected” weights. Here for GPT-2 are the sequence
    of attention weights for the “hello, bye” input, for the first attention head:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，所以经过一个注意力块后，我们得到了一个新的嵌入向量——然后依次通过额外的注意力块传递（对于GPT-2共有12个；对于GPT-3共有96个）。每个注意力块都有自己特定的“注意力”和“全连接”权重模式。这里是GPT-2中“hello,
    bye”输入的第一个注意力头的注意力权重序列：
- en: '![](Image00079.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00079.jpg)'
- en: 'And here are the (moving-averaged) “matrices” for the fully connected layers:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是完全连接层的（移动平均）“矩阵”：
- en: '![](Image00080.gif)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00080.gif)'
- en: 'Curiously, even though these “matrices of weights” in different attention blocks
    look quite similar, the distributions of the sizes of weights can be somewhat
    different (and are not always Gaussian):'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，即使在不同的注意力块中，这些“权重矩阵”看起来相似，权重大小的分布可能有所不同（并且并非总是高斯分布）：
- en: '![](Image00081.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00081.jpg)'
- en: So after going through all these attention blocks what is the net effect of
    the transformer? Essentially it’s to transform the original collection of embeddings
    for the sequence of tokens to a final collection. And the particular way ChatGPT
    works is then to pick up the last embedding in this collection, and “decode” it
    to produce a list of probabilities for what token should come next.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 经过所有这些注意力块后，变压器的净效果是什么？基本上是将一系列令牌的原始嵌入转换为最终集合。而 ChatGPT 的特定工作方式是选择这个集合中的最后一个嵌入，并对其进行“解码”，以生成下一个应该出现的令牌的概率列表。
- en: So that’s in outline what’s inside ChatGPT. It may seem complicated (not least
    because of its many inevitably somewhat arbitrary “engineering choices”), but
    actually the ultimate elements involved are remarkably simple. Because in the
    end what we’re dealing with is just a neural net made of “artificial neurons”,
    each doing the simple operation of taking a collection of numerical inputs, and
    then combining them with certain weights.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是 ChatGPT 内部的大致概况。这可能看起来很复杂（主要是因为其中许多不可避免的“工程选择”有些随意），但实际上所涉及的最终元素非常简单。因为最终我们所处理的只是一个由“人工神经元”组成的神经网络，每个神经元都执行着将一组数字输入进行简单操作，然后与特定权重结合的操作。
- en: The original input to ChatGPT is an array of numbers (the embedding vectors
    for the tokens so far), and what happens when ChatGPT “runs” to produce a new
    token is just that these numbers “ripple through” the layers of the neural net,
    with each neuron “doing its thing” and passing the result to neurons on the next
    layer. There’s no looping or “going back”. Everything just “feeds forward” through
    the network.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 的原始输入是一组数字数组（迄今为止令牌的嵌入向量），当 ChatGPT“运行”以生成一个新令牌时，这些数字只是“涟漪”通过神经网络的各层，每个神经元“做自己的事情”并将结果传递给下一层的神经元。没有循环或“回溯”。一切都只是通过网络“前馈”。
- en: It’s a very different setup from a typical computational system—like a [Turing
    machine](https://www.wolframscience.com/nks/chap-3--the-world-of-simple-/%20programs/#sect-3-4--turing-machines)
    —in which results are repeatedly “reprocessed” by the same computational elements.
    Here—at least in generating a given token of output—each computational element
    (i.e. neuron) is used only once.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这与典型的计算系统（如[图灵机](https://www.wolframscience.com/nks/chap-3--the-world-of-simple-/%20programs/#sect-3-4--turing-machines)）的设置非常不同，其中结果会被相同的计算元素重复“重新处理”。在这里——至少在生成给定输出令牌时——每个计算元素（即神经元）只使用一次。
- en: But there is in a sense still an “outer loop” that reuses computational elements
    even in ChatGPT. Because when ChatGPT is going to generate a new token, it always
    “reads” (i.e. takes as input) the whole sequence of tokens that come before it,
    including tokens that ChatGPT itself has “written” previously. And we can think
    of this setup as meaning that ChatGPT does—at least at its outermost level—involve
    a “feedback loop”, albeit one in which every iteration is explicitly visible as
    a token that appears in the text that it generates.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 但在某种意义上，即使在 ChatGPT 中，仍然存在一个“外部循环”重复使用计算元素。因为当 ChatGPT 要生成一个新令牌时，它总是“读取”（即将其作为输入）之前出现的所有令牌序列，包括
    ChatGPT 自己之前“写入”的令牌。我们可以将这种设置看作是意味着 ChatGPT 至少在其最外层涉及一个“反馈循环”，尽管每次迭代都明确可见为出现在其生成文本中的令牌。
- en: 'But let’s come back to the core of ChatGPT: the neural net that’s being repeatedly
    used to generate each token. At some level it’s very simple: a whole collection
    of identical artificial neurons. And some parts of the network just consist of
    (“[fully connected](https://reference.wolfram.com/language/ref/LinearLayer.html)
    ”) layers of neurons in which every neuron on a given layer is connected (with
    some weight) to every neuron on the layer before. But particularly with its transformer
    architecture, ChatGPT has parts with more structure, in which only specific neurons
    on different layers are connected. (Of course, one could still say that “all neurons
    are connected”—but some just have zero weight.)'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们回到ChatGPT的核心：被反复用来生成每个标记的神经网络。在某种程度上，它非常简单：一整套相同的人工神经元。网络的一些部分只是由（“[全连接](https://reference.wolfram.com/language/ref/LinearLayer.html)”）层组成的神经元，在这些层中，给定层上的每个神经元都与前一层上的每个神经元连接（带有一些权重）。但特别是在其变压器架构中，ChatGPT具有更多结构的部分，其中只有不同层上的特定神经元相连。
    （当然，人们仍然可以说“所有神经元都相连”——但有些只是权重为零。）
- en: In addition, there are aspects of the neural net in ChatGPT that aren’t most
    naturally thought of as just consisting of “homogeneous” layers. And for example—as
    the iconic summary above indicates—inside an attention block there are places
    where “multiple copies are made” of incoming data, each then going through a different
    “processing path”, potentially involving a different number of layers, and only
    later recombining. But while this may be a convenient representation of what’s
    going on, it’s always at least in principle possible to think of “densely filling
    in” layers, but just having some weights be zero.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在ChatGPT中的神经网络中有一些方面，并不是最自然地被认为只是由“同质”层组成。例如——正如上面的标志性摘要所示——在一个注意力块内，有一些地方会“制作”传入数据的“多个副本”，然后每个副本都会通过不同的“处理路径”进行，可能涉及不同数量的层，只有在稍后才重新组合。但是虽然这可能是对正在发生的事情的一个方便的表示，但至少原则上总是可能想象“密集填充”层，只是有一些权重为零。
- en: If one looks at the longest path through ChatGPT, there are about 400 (core)
    layers involved—in some ways not a huge number. But there are millions of neurons—with
    a total of 175 billion connections and therefore 175 billion weights. And one
    thing to realize is that every time ChatGPT generates a new token, it has to do
    a calculation involving every single one of these weights. Implementationally
    these calculations can be somewhat organized “by layer” into highly parallel array
    operations that can conveniently be done on GPUs. But for each token that’s produced,
    there still have to be 175 billion calculations done (and in the end a bit more)—so
    that, yes, it’s not surprising that it can take a while to generate a long piece
    of text with ChatGPT.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看一下通过ChatGPT的最长路径，涉及到大约400个（核心）层——在某种程度上并不是一个巨大的数字。但是有数百万个神经元——总共有1750亿个连接，因此有1750亿个权重。有一件事要意识到的是，每当ChatGPT生成一个新的标记时，它都必须进行一次涉及所有这些权重的计算。在实现上，这些计算可以在高度并行的数组操作中有些组织“按层”进行，这些操作可以方便地在GPU上完成。但是对于每个生成的标记，仍然必须进行1750亿次计算（最后还要多一点）——所以，是的，生成一段长文本可能需要一段时间。
- en: 'But in the end, the remarkable thing is that all these operations—individually
    as simple as they are—can somehow together manage to do such a good “human-like”
    job of generating text. It has to be emphasized again that (at least so far as
    we know) there’s no “ultimate theoretical reason” why anything like this should
    work. And in fact, as we’ll discuss, I think we have to view this as a—potentially
    surprising—scientific discovery: that somehow in a neural net like ChatGPT’s it’s
    possible to capture the essence of what human brains manage to do in generating
    language.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 但最终，值得注意的是，所有这些操作——尽管它们各自都很简单——却可以一起完成如此出色的“类人”生成文本的工作。必须再次强调（至少就我们所知），没有“终极理论原因”说明为什么类似这样的东西会起作用。事实上，正如我们将讨论的那样，我认为我们必须将这视为一项——可能令人惊讶的——科学发现：在像ChatGPT这样的神经网络中，以某种方式能够捕捉到人类大脑在生成语言方面所能做到的本质。
- en: The Training of ChatGPT
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT的训练
- en: OK, so we’ve now given an outline of how ChatGPT works once it’s set up. But
    how did it get set up? How were all those 175 billion weights in its neural net
    determined? Basically they’re the result of very large-scale training, based on
    a huge corpus of text—on the web, in books, etc.—written by humans. As we’ve said,
    even given all that training data, it’s certainly not obvious that a neural net
    would be able to successfully produce “human-like” text. And, once again, there
    seem to be detailed pieces of engineering needed to make that happen. But the
    big surprise—and discovery—of ChatGPT is that it’s possible at all. And that—in
    effect—a neural net with “just” 175 billion weights can make a “reasonable model”
    of text humans write.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，现在我们已经概述了ChatGPT在设置后的工作原理。但是它是如何设置的呢？它的神经网络中的所有那1750亿个权重是如何确定的呢？基本上，它们是基于由人类撰写的大量文本的巨大语料库进行的大规模训练的结果——在网络上，书籍中等等。正如我们所说，即使考虑到所有这些训练数据，神经网络能够成功产生“类似人类”的文本显然并不明显。而且，再次，似乎需要详细的工程细节才能实现这一点。但是ChatGPT的大惊喜和发现是，这是可能的。实际上，一个“仅有”1750亿个权重的神经网络可以制作出人类撰写的“合理模型”文本。
- en: In modern times, there’s lots of text written by humans that’s out there in
    digital form. The public web has at least several billion human-written pages,
    with altogether perhaps a trillion words of text. And if one includes non-public
    webpages, the numbers might be at least 100 times larger. So far, more than 5
    million digitized books have been made available (out of 100 million or so that
    have ever been published), giving another 100 billion or so words of text. And
    that’s not even mentioning text derived from speech in videos, etc. (As a personal
    comparison, [my total lifetime output of published material](https://www.stephenwolfram.com/publications/)
    has been a bit under 3 million words, and over the [past 30 years I’ve written](https://writings.stephenwolfram.com/2012/03/the-personal-analytics-of-my-life/)
    about 15 million words of email, and altogether typed perhaps 50 million words—and
    in just the past couple of years I’ve spoken more than 10 million words on [livestreams](https://www.stephenwolfram.com/livestreams)
    . And, yes, I’ll train a bot from all of that.)
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代，有大量由人类撰写的文本以数字形式存在。公共网络上至少有数十亿人类撰写的页面，总共可能有万亿字的文本。如果包括非公开网页，数字可能至少大100倍。到目前为止，已经提供了超过500万本数字化书籍（大约有1亿本曾经出版的书籍），提供了另外约1000亿字的文本。甚至没有提到从视频中的语音中衍生的文本。（作为个人比较，[我一生中发表的总产出](https://www.stephenwolfram.com/publications/)大约不到300万字，过去[30年来我写了](https://writings.stephenwolfram.com/2012/03/the-personal-analytics-of-my-life/)约1500万字的电子邮件，总共可能打了大约5000万字，仅在过去几年里我在[直播中说了](https://www.stephenwolfram.com/livestreams)超过1000万字。是的，我将从所有这些内容中训练一个机器人。）
- en: But, OK, given all this data, how does one train a neural net from it? The basic
    process is very much as we discussed it in the simple examples above. You present
    a batch of examples, and then you adjust the weights in the network to minimize
    the error (“loss”) that the network makes on those examples. The main thing that’s
    expensive about “back propagating” from the error is that each time you do this,
    every weight in the network will typically change at least a tiny bit, and there
    are just a lot of weights to deal with. (The actual “back computation” is typically
    only a small constant factor harder than the forward one.)
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，好吧，考虑到所有这些数据，如何从中训练神经网络呢？基本过程与我们在上面的简单示例中讨论的非常相似。您提供一批示例，然后调整网络中的权重，以最小化网络在这些示例上产生的错误（“损失”）。关于从错误“反向传播”的主要昂贵之处在于，每次执行此操作时，网络中的每个权重通常至少会发生微小变化，并且有很多权重需要处理。（实际的“反向计算”通常只比前向计算难一点点。）
- en: With modern GPU hardware, it’s straightforward to compute the results from batches
    of thousands of examples in parallel. But when it comes to actually updating the
    weights in the neural net, current methods require one to do this basically batch
    by batch. (And, yes, this is probably where actual brains—with their combined
    computation and memory elements—have, for now, at least an architectural advantage.)
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 使用现代GPU硬件，可以轻松并行计算成千上万个示例的批次的结果。但是，当涉及实际更新神经网络中的权重时，当前的方法要求基本上是逐批次进行的。（是的，这可能是实际大脑目前至少在架构上具有优势的地方，因为它们具有结合计算和存储元素。）
- en: Even in the seemingly simple cases of learning numerical functions that we discussed
    earlier, we found we often had to use millions of examples to successfully train
    a network, at least from scratch. So how many examples does this mean we’ll need
    in order to train a “human-like language” model? There doesn’t seem to be any
    fundamental “theoretical” way to know. But in practice ChatGPT was successfully
    trained on a few hundred billion words of text.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在我们之前讨论的学习数值函数的看似简单的情况下，我们发现我们经常需要使用数百万个示例才能成功地训练一个网络，至少是从头开始。那么这意味着我们需要多少示例才能训练一个“类似人类语言”的模型呢？似乎没有任何基本的“理论”方法可以知道。但实际上，ChatGPT成功地在数千亿字的文本上进行了训练。
- en: Some of the text it was fed several times, some of it only once. But somehow
    it “got what it needed” from the text it saw. But given this volume of text to
    learn from, how large a network should it require to “learn it well”? Again, we
    don’t yet have a fundamental theoretical way to say. Ultimately—as we’ll discuss
    further below—there’s presumably a certain “total algorithmic content” to human
    language and what humans typically say with it. But the next question is how efficient
    a neural net will be at implementing a model based on that algorithmic content.
    And again we don’t know—although the success of ChatGPT suggests it’s reasonably
    efficient.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 它被喂入的文本有些是多次，有些是只有一次。但不知何故，它从看到的文本中“得到了所需的内容”。但考虑到这么多文本要学习，它需要多大的网络才能“学得好”呢？同样，我们还没有一个基本的理论方法来说。最终——正如我们将在下面进一步讨论的那样——人类语言和人类通常用它说的内容可能存在一定的“总算法内容”。但接下来的问题是神经网络在基于该算法内容的模型上实现时会有多有效率。同样，我们不知道——尽管ChatGPT的成功表明它是相当有效率的。
- en: And in the end we can just note that ChatGPT does what it does using a couple
    hundred billion weights—comparable in number to the total number of words (or
    tokens) of training data it’s been given. In some ways it’s perhaps surprising
    (though empirically observed also in smaller analogs of ChatGPT) that the “size
    of the network” that seems to work well is so comparable to the “size of the training
    data”. After all, it’s certainly not that somehow “inside ChatGPT” all that text
    from the web and books and so on is “directly stored”. Because what’s actually
    inside ChatGPT are a bunch of numbers—with a bit less than 10 digits of precision—that
    are some kind of distributed encoding of the aggregate structure of all that text.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 最后我们可以注意到，ChatGPT使用了数千亿个权重来完成它的任务——与它所接收的训练数据的总词数（或标记）相当。在某种程度上，也许令人惊讶的是（尽管在ChatGPT的较小模拟中也经验观察到），似乎“工作良好的网络大小”与“训练数据大小”是如此相近。毕竟，ChatGPT内部肯定不是以某种方式“直接存储”所有来自网络、书籍等的文本。因为实际上ChatGPT内部是一堆数字——精度略低于10位数——这些数字是对所有文本的总体结构的某种分布式编码。
- en: Put another way, we might ask what the “effective information content” is of
    human language and what’s typically said with it. There’s the raw corpus of examples
    of language. And then there’s the representation in the neural net of ChatGPT.
    That representation is very likely far from the “algorithmically minimal” representation
    (as we’ll discuss below). But it’s a representation that’s readily usable by the
    neural net. And in this representation it seems there’s in the end rather little
    “compression” of the training data; it seems on average to basically take only
    a bit less than one neural net weight to carry the “information content” of a
    word of training data.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们可以问一下人类语言的“有效信息内容”是什么，以及通常用它说了些什么。有语言示例的原始语料库。然后是ChatGPT神经网络中的表示。这种表示很可能远离“算法上最小”表示（如下面我们将讨论的）。但这是一个神经网络可以轻松使用的表示。在这种表示中，训练数据似乎最终没有太多的“压缩”；平均来看，基本上只需要不到一个神经网络权重来携带一个训练数据中的单词的“信息内容”。
- en: When we run ChatGPT to generate text, we’re basically having to use each weight
    once. So if there are *n* weights, we’ve got of order *n* computational steps
    to do—though in practice many of them can typically be done in parallel in GPUs.
    But if we need about *n* words of training data to set up those weights, then
    from what we’ve said above we can conclude that we’ll need about *n* ² computational
    steps to do the training of the network—which is why, with current methods, one
    ends up needing to talk about billion-dollar training efforts.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行ChatGPT生成文本时，基本上是必须使用每个权重一次。因此，如果有*n*个权重，我们需要大约*n*个计算步骤来完成——尽管在实践中，许多计算步骤通常可以在GPU中并行执行。但是，如果我们需要大约*n*个单词的训练数据来设置这些权重，那么根据我们上面所说的，我们可以得出结论，我们将需要大约*n*²个计算步骤来进行网络的训练——这就是为什么，使用当前的方法，人们最终需要谈论数十亿美元的培训工作。
- en: Beyond Basic Training
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超越基础训练
- en: The majority of the effort in training ChatGPT is spent “showing it” large amounts
    of existing text from the web, books, etc. But it turns out there’s another—apparently
    rather important—part too.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 训练ChatGPT的大部分工作都花在“展示”大量来自网络、书籍等现有文本的过程中。但事实证明，还有另一个——显然相当重要的——部分。
- en: As soon as it’s finished its “raw training” from the original corpus of text
    it’s been shown, the neural net inside ChatGPT is ready to start generating its
    own text, continuing from prompts, etc. But while the results from this may often
    seem reasonable, they tend—particularly for longer pieces of text—to “wander off”
    in often rather non-human-like ways. It’s not something one can readily detect,
    say, by doing traditional statistics on the text. But it’s something that actual
    humans reading the text easily notice.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦ChatGPT从它展示的原始文本语料库中完成了“原始训练”，内部的神经网络就准备好开始生成自己的文本，继续从提示中生成等等。但是，尽管这些结果通常看起来合理，但它们往往——特别是对于较长的文本——会以一种相当不像人类的方式“偏离”。这不是通过对文本进行传统统计分析就能轻易检测到的事情。但实际阅读文本的人很容易注意到这一点。
- en: 'And a [key idea in the construction of ChatGPT](https://openai.com/blog/instruction-following/)
    was to have another step after “passively reading” things like the web: to have
    actual humans actively interact with ChatGPT, see what it produces, and in effect
    give it feedback on “how to be a good chatbot”. But how can the neural net use
    that feedback? The first step is just to have humans rate results from the neural
    net. But then another neural net model is built that attempts to predict those
    ratings. But now this prediction model can be run—essentially like a loss function—on
    the original network, in effect allowing that network to be “tuned up” by the
    human feedback that’s been given. And the results in practice seem to have a big
    effect on the success of the system in producing “human-like” output.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '[ChatGPT构建中的一个关键思想](https://openai.com/blog/instruction-following/)是在“被动阅读”诸如网络之类的内容之后再进行另一步：让实际人类积极与ChatGPT互动，看看它产生了什么，实际上给予它“如何成为一个好的聊天机器人”的反馈。但神经网络如何利用这些反馈呢？第一步只是让人类评价神经网络的结果。然后建立另一个神经网络模型，试图预测这些评分。但现在这个预测模型可以运行——本质上像一个损失函数——在原始网络上，实际上允许该网络通过给出的人类反馈进行“调整”。实践中的结果似乎对系统成功产生“类似人类”的输出有很大影响。'
- en: In general, it’s interesting how little “poking” the “originally trained” network
    seems to need to get it to usefully go in particular directions. One might have
    thought that to have the network behave as if it’s “learned something new” one
    would have to go in and run a training algorithm, adjusting weights, and so on.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，有趣的是，“最初训练”的网络似乎需要很少的“刺激”就能让它有目的地前进。人们可能会认为，为了让网络表现得好像“学到了新东西”，就必须进入并运行训练算法，调整权重等等。
- en: But that’s not the case. Instead, it seems to be sufficient to basically tell
    ChatGPT something one time—as part of the prompt you give—and then it can successfully
    make use of what you told it when it generates text. And once again, the fact
    that this works is, I think, an important clue in understanding what ChatGPT is
    “really doing” and how it relates to the structure of human language and thinking.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 但事实并非如此。相反，似乎只需基本告诉ChatGPT一次——作为您给出的提示的一部分——然后它在生成文本时就能成功利用您告诉它的内容。而且再次，这种方法奏效的事实，我认为，是理解ChatGPT“真正做了什么”以及它与人类语言和思维结构之间关系的重要线索。
- en: 'There’s certainly something rather human-like about it: that at least once
    it’s had all that pre-training you can tell it something just once and it can
    “remember it”—at least “long enough” to generate a piece of text using it. So
    what’s going on in a case like this? It could be that “everything you might tell
    it is already in there somewhere”—and you’re just leading it to the right spot.
    But that doesn’t seem plausible. Instead, what seems more likely is that, yes,
    the elements are already in there, but the specifics are defined by something
    like a “trajectory between those elements” and that’s what you’re introducing
    when you tell it something.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这个确实有点像人类：至少在经过所有的预训练之后，你只需告诉它一次，它就能“记住”——至少“足够长时间”以生成一段文本。那么在这种情况下到底发生了什么呢？可能是“你可能告诉它的一切都已经在那里某个地方了”——你只是引导它到正确的位置。但这似乎不太可能。相反，更有可能的是，是的，元素已经在那里了，但具体内容由类似于“这些元素之间的轨迹”之类的东西定义，当你告诉它时，你引入的就是这个。
- en: And indeed, much like for humans, if you tell it something bizarre and unexpected
    that completely doesn’t fit into the framework it knows, it doesn’t seem like
    it’ll successfully be able to “integrate” this. It can “integrate” it only if
    it’s basically riding in a fairly simple way on top of the framework it already
    has.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 而且，就像对于人类一样，如果你告诉它一些奇怪和意想不到的完全不符合它已知框架的东西，它似乎无法成功地“整合”这些信息。只有当它基本上是在已有框架的基础上以一种相当简单的方式运行时，它才能“整合”它。
- en: It’s also worth pointing out again that there are inevitably “algorithmic limits”
    to what the neural net can “pick up”. Tell it “shallow” rules of the form “this
    goes to that”, etc., and the neural net will most likely be able to represent
    and reproduce these just fine—and indeed what it “already knows” from language
    will give it an immediate pattern to follow. But try to give it rules for an actual
    “deep” computation that involves many potentially computationally irreducible
    steps and it just won’t work. (Remember that at each step it’s always just “feeding
    data forward” in its network, never looping except by virtue of generating new
    tokens.)
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得再次指出，神经网络能够“捕捉”的内容不可避免地存在“算法限制”。告诉它“这个转换为那个”等形式的“浅层”规则，神经网络很可能能够很好地表示和复制这些规则——实际上，它从语言中“已知的”将给它一个立即要遵循的模式。但是，尝试为涉及许多潜在计算不可简化步骤的实际“深层”计算提供规则，它就无法工作了。（请记住，在每一步中，它总是在其网络中“向前传递数据”，除了生成新的标记外，永远不会循环。）
- en: Of course, the network can learn the answer to specific “irreducible” computations.
    But as soon as there are combinatorial numbers of possibilities, no such “table-lookup-style”
    approach will work. And so, yes, just like humans, it’s time then for neural nets
    to “reach out” and use actual computational tools. (And, yes, [Wolfram|Alpha](https://www.wolframalpha.com/)
    and [Wolfram Language](https://www.wolfram.com/language/) are [uniquely suitable](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)
    , because they’ve been built to “talk about things in the world”, just like the
    language-model neural nets.)
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，网络可以学习特定“不可简化”计算的答案。但是一旦存在组合数量的可能性，这种“查表式”方法就行不通了。因此，是的，就像人类一样，现在是神经网络“伸手”并使用实际计算工具的时候了。（而且，是的，[Wolfram|Alpha](https://www.wolframalpha.com/)
    和 [Wolfram Language](https://www.wolfram.com/language/) 是[独特合适的](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)，因为它们被构建为“谈论世界中的事物”，就像语言模型神经网络一样。）
- en: What Really Lets ChatGPT Work?
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 到底是什么让 ChatGPT 起作用？
- en: 'Human language—and the processes of thinking involved in generating it—have
    always seemed to represent a kind of pinnacle of complexity. And indeed it’s seemed
    somewhat remarkable that human brains—with their network of a “mere” 100 billion
    or so neurons (and maybe 100 trillion connections) could be responsible for it.
    Perhaps, one might have imagined, there’s something more to brains than their
    networks of neurons—like some new layer of undiscovered physics. But now with
    ChatGPT we’ve got an important new piece of information: we know that a pure,
    artificial neural network with about as many connections as brains have neurons
    is capable of doing a surprisingly good job of generating human language.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 人类语言——以及生成它所涉及的思维过程——一直似乎代表着一种复杂性的巅峰。事实上，人类大脑——其“仅仅”拥有大约1000亿个神经元（也许有100万亿个连接）的网络——能够负责这一切似乎有些令人惊讶。也许，人们可能会想象，大脑除了神经元网络之外还有一些未被发现的物理新层面。但现在有了ChatGPT，我们获得了一项重要的新信息：我们知道，一个纯粹的人工神经网络，具有与大脑神经元数量相当的连接数，能够出奇地成功地生成人类语言。
- en: And, yes, that’s still a big and complicated system—with about as many neural
    net weights as there are words of text currently available out there in the world.
    But at some level it still seems difficult to believe that all the richness of
    language and the things it can talk about can be encapsulated in such a finite
    system. Part of what’s going on is no doubt a reflection of the ubiquitous phenomenon
    (that first became evident in the [example of rule 30](https://www.wolframscience.com/nks/chap-2--the-crucial-experiment#sect-2-1--how-do-simple-programs-behave)
    ) that computational processes can in effect greatly amplify the apparent complexity
    of systems even when their underlying rules are simple. But, actually, as we discussed
    above, neural nets of the kind used in ChatGPT tend to be specifically constructed
    to restrict the effect of this phenomenon—and the computational irreducibility
    associated with it—in the interest of making their training more accessible.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这仍然是一个庞大且复杂的系统——大约有与当前世界上可用的文字数量相当的神经网络权重。但在某种程度上，仍然很难相信语言的丰富性以及它所能谈论的事物可以被封装在这样一个有限的系统中。部分原因无疑是由于无处不在的现象（最初在[规则30的例子](https://www.wolframscience.com/nks/chap-2--the-crucial-experiment#sect-2-1--how-do-simple-programs-behave)中首次显现），即计算过程实际上可以大大放大系统的表面复杂性，即使它们的基本规则很简单。但实际上，正如我们上面讨论的那样，ChatGPT中使用的神经网络往往是专门构建的，以限制这种现象及与之相关的计算不可简化性，以便使它们的训练更易于理解。
- en: So how is it, then, that something like ChatGPT can get as far as it does with
    language? The basic answer, I think, is that language is at a fundamental level
    somehow simpler than it seems. And this means that ChatGPT—even with its ultimately
    straightforward neural net structure—is successfully able to “capture the essence”
    of human language and the thinking behind it. And moreover, in its training, ChatGPT
    has somehow “implicitly discovered” whatever regularities in language (and thinking)
    make this possible.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，像ChatGPT这样的系统是如何在语言方面取得如此大的进展的呢？我认为，基本答案是，语言在某种基本层面上似乎比它看起来要简单。这意味着，即使ChatGPT最终的神经网络结构相对直接，它仍能成功地“捕捉到”人类语言及其背后的思维的本质。而且，在训练过程中，ChatGPT不知何故“隐含地发现”了使这一切成为可能的语言（和思维）中的规律性。
- en: 'The success of ChatGPT is, I think, giving us evidence of a fundamental and
    important piece of science: it’s suggesting that we can expect there to be major
    new “laws of language”—and effectively “laws of thought”—out there to discover.
    In ChatGPT—built as it is as a neural net—those laws are at best implicit. But
    if we could somehow make the laws explicit, there’s the potential to do the kinds
    of things ChatGPT does in vastly more direct, efficient—and transparent—ways.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的成功，我认为，为我们提供了一项基础且重要的科学证据：它表明我们可以期待发现一些全新的“语言法则”——以及有效的“思维法则”。在ChatGPT中——作为一个神经网络构建的系统——这些法则最多只是隐含的。但如果我们能够以某种方式使这些法则明确化，就有潜力以更加直接、高效和透明的方式做到ChatGPT所做的那些事情。
- en: But, OK, so what might these laws be like? Ultimately they must give us some
    kind of prescription for how language—and the things we say with it—are put together.
    Later we’ll discuss how “looking inside ChatGPT” may be able to give us some hints
    about this, and how what we know from building computational language suggests
    a path forward. But first let’s discuss two long-known examples of what amount
    to “laws of language”—and how they relate to the operation of ChatGPT.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，好吧，这些规则可能是什么样的呢？最终它们必须给我们一些关于语言——以及我们用语言表达的东西——如何组合的指导。稍后我们将讨论“查看ChatGPT内部”可能能够给我们一些关于这一点的提示，以及我们从构建计算语言中所知的内容暗示了一条前进的道路。但首先让我们讨论两个长期已知的类似于“语言规律”的例子——以及它们如何与ChatGPT的运作相关。
- en: 'The first is the syntax of language. Language is not just a random jumble of
    words. Instead, there are (fairly) definite [grammatical rules](https://www.wolframscience.com/nks/notes-10-12--computer-and-human-languages/)
    for how words of different kinds can be put together: in English, for example,
    nouns can be preceded by adjectives and followed by verbs, but typically two nouns
    can’t be right next to each other. Such grammatical structure can (at least approximately)
    be captured by a set of rules that define how what amount to [“parse trees” can
    be put together](https://reference.wolfram.com/language/ref/TextStructure.html)
    :'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是语言的语法。语言不只是一堆随机的词汇。相反，有（相当）明确的[语法规则](https://www.wolframscience.com/nks/notes-10-12--computer-and-human-languages/)规定了不同类型的词汇如何组合在一起：例如，在英语中，名词可以由形容词前置和动词后置，但通常两个名词不能直接相邻。这种语法结构可以（至少近似地）通过一组规则来捕捉，这些规则定义了如何组合[“解析树”](https://reference.wolfram.com/language/ref/TextStructure.html)：
- en: '![](Image00082.jpg)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00082.jpg)'
- en: ChatGPT doesn’t have any explicit “knowledge” of such rules. But somehow in
    its training it implicitly “discovers” them—and then seems to be good at following
    them. So how does this work? At a “big picture” level it’s not clear. But to get
    some insight it’s perhaps instructive to look at a much simpler example.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT并没有对这些规则有明确的“知识”。但在其训练中，它以某种方式隐式“发现”了它们，然后似乎擅长遵循这些规则。那么这是如何运作的呢？从“宏观”层面来看并不清楚。但为了获得一些见解，也许看一个更简单的例子会有帮助。
- en: 'Consider a “language” formed from sequences of (’s and )’s, with a [grammar
    that specifies](https://www.wolframscience.com/nks/notes-7-9--nested-lists/) that
    parentheses should always be balanced, as represented by a parse tree like:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个由（’s和)’s序列组成的“语言”，其[语法规定](https://www.wolframscience.com/nks/notes-7-9--nested-lists/)括号应始终保持平衡，如下所示的解析树：
- en: '![](Image00083.gif)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00083.gif)'
- en: Can we train a neural net to produce “grammatically correct” parenthesis sequences?
    There are various ways to handle sequences in neural nets, but let’s use transformer
    nets, as ChatGPT does. And given a simple transformer net, we can start feeding
    it grammatically correct parenthesis sequences as training examples. A subtlety
    (which actually also appears in ChatGPT’s generation of human language) is that
    in addition to our “content tokens” (here “(” and “)”) we have to include an “End”
    token, that’s generated to indicate that the output shouldn’t continue any further
    (i.e. for ChatGPT, that one’s reached the “end of the story”).
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能训练一个神经网络生成“语法正确”的括号序列吗？神经网络中有各种处理序列的方法，但让我们使用变压器网络，就像ChatGPT一样。给定一个简单的变压器网络，我们可以开始将语法正确的括号序列作为训练样本输入。一个微妙之处（实际上也出现在ChatGPT生成人类语言的过程中）是，除了我们的“内容标记”（这里是“(”和“)”）之外，我们还必须包括一个“结束”标记，用于指示输出不应继续（即对于ChatGPT，表示已经到达“故事的结尾”）。
- en: If we set up a transformer net with just one attention block with 8 heads and
    feature vectors of length 128 (ChatGPT also uses feature vectors of length 128,
    but has 96 attention blocks, each with 96 heads) then it doesn’t seem possible
    to get it to learn much about parenthesis language. But with 2 attention blocks,
    the learning process seems to converge—at least after 10 million or so examples
    have been given (and, as is common with transformer nets, showing yet more examples
    just seems to degrade its performance).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们设置一个只有一个注意力块、8个头和长度为128的特征向量的变压器网络（ChatGPT也使用长度为128的特征向量，但有96个注意力块，每个块有96个头），那么似乎不可能让它学习太多关于括号语言的知识。但是通过2个注意力块，学习过程似乎会收敛——至少在提供了大约1000万个例子之后（并且，与变压器网络一般情况一样，提���更多的例子似乎只会降低其性能）。
- en: 'So with this network, we can do the analog of what ChatGPT does, and ask for
    probabilities for what the next token should be—in a parenthesis sequence:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过这个网络，我们可以做类似于ChatGPT的事情，并询问下一个标记应该是什么的概率——在一个括号序列中：
- en: '![](Image00084.gif)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00084.gif)'
- en: And in the first case, the network is “pretty sure” that the sequence can’t
    end here—which is good, because if it did, the parentheses would be left unbalanced.
    In the second case, however, it “correctly recognizes” that the sequence can end
    here, though it also “points out” that it’s possible to “start again”, putting
    down a “(”, presumably with a “)” to follow. But, oops, even with its 400,000
    or so laboriously trained weights, it says there’s a 15% probability to have “)”
    as the next token—which isn’t right, because that would necessarily lead to an
    unbalanced parenthesis.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，网络“非常确定”序列不能在这里结束——这是好事，因为如果结束了，括号就会不平衡。然而，在第二种情况下，它“正确地认识到”序列可以在这里结束，尽管它也“指出”可以“重新开始”，放下一个“（”，可能会跟着一个“）”。但是，哎呀，即使经过了大约40万个辛苦训练的权重，它说下一个标记是“)”的概率为15%——这是不正确的，因为这必然会导致括号不平衡。
- en: 'Here’s what we get if we ask the network for the highest-probability completions
    for progressively longer sequences of (’s:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要求网络为逐渐变长的（'s）序列提供最高概率的完成情况，我们会得到以下结果：
- en: '![](Image00085.jpg)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00085.jpg)'
- en: And, yes, up to a certain length the network does just fine. But then it starts
    failing. It’s a pretty typical kind of thing to see in a “precise” situation like
    this with a neural net (or with machine learning in general). Cases that a human
    “can solve in a glance” the neural net can solve too. But cases that require doing
    something “more algorithmic” (e.g. explicitly counting parentheses to see if they’re
    closed) the neural net tends to somehow be “too computationally shallow” to reliably
    do. (By the way, even the full current ChatGPT has a hard time correctly matching
    parentheses in long sequences.)
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，直到一定长度，网络表现得很好。但然后它开始失败。这在像这样的“精确”情况下与神经网络（或者一般的机器学习）是一种相当典型的情况。人类“一眼就能解决的情况”神经网络也能解决。但是需要做一些“更算法化”的情况（例如明确计算括号以查看它们是否关闭），神经网络往往在某种程度上“计算上不够深入”以可靠地执行。
    （顺便说一句，即使是完整的当前ChatGPT在长序列中也很难正确匹配括号。）
- en: So what does this mean for things like ChatGPT and the syntax of a language
    like English? The parenthesis language is “austere”—and much more of an “algorithmic
    story”. But in English it’s much more realistic to be able to “guess” what’s grammatically
    going to fit on the basis of local choices of words and other hints. And, yes,
    the neural net is much better at this—even though perhaps it might miss some “formally
    correct” case that, well, humans might miss as well. But the main point is that
    the fact that there’s an overall syntactic structure to the language—with all
    the regularity that implies—in a sense limits “how much” the neural net has to
    learn. And a key “natural-science-like” observation is that the transformer architecture
    of neural nets like the one in ChatGPT seems to successfully be able to learn
    the kind of nested-tree-like syntactic structure that seems to exist (at least
    in some approximation) in all human languages.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这对像ChatGPT和英语这样的语言的语法意味着什么呢？括号语言是“严肃的”—更像是一个“算法故事”。但在英语中，根据单词的局部选择和其他提示，能够“猜测”在语法上什么样的内容更合适，这更现实。而且，是的，神经网络在这方面要好得多——尽管也许它可能会错过一些“形式上正确”的情况，嗯，人类也可能会错过。但主要观点是，语言存在整体的句法结构——带有所有这意味着的规律性——在某种意义上限制了神经网络需要学习的“程度”。一个关键的“类似自然科学”的观察是，像ChatGPT中的变压器架构这样的神经网络似乎成功地学会了类似嵌套树状句法结构的语法结构，这种结构似乎存在于所有人类语言中（至少在某种程度上）。
- en: Syntax provides one kind of constraint on language. But there are clearly more.
    A sentence like “Inquisitive electrons eat blue theories for fish” is grammatically
    correct but isn’t something one would normally expect to say, and wouldn’t be
    considered a success if ChatGPT generated it—because, well, with the normal meanings
    for the words in it, it’s basically meaningless.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 语法对语言提供了一种约束。但显然还有更多。像“好奇的电子吃蓝色的理论来换取鱼”这样的句子在语法上是正确的，但不是人们通常会说的东西，如果ChatGPT生成了这样的句子，也不会被认为是成功的——因为，嗯，根据其中的单词的正常含义，它基本上是毫无意义的。
- en: But is there a general way to tell if a sentence is meaningful? There’s no traditional
    overall theory for that. But it’s something that one can think of ChatGPT as having
    implicitly “developed a theory for” after being trained with billions of (presumably
    meaningful) sentences from the web, etc.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 但是有没有一种通用的方法来判断一个句子是否有意义？对此并没有传统的整体理论。但可以将 ChatGPT 视为在通过来自网络等地方的数十亿（据推测有意义的）句子进行训练后，隐含地“发展出了一个理论”。
- en: What might this theory be like? Well, there’s one tiny corner that’s basically
    been known for two millennia, and that’s [logic](https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/)
    . And certainly in the syllogistic form in which Aristotle discovered it, logic
    is basically a way of saying that sentences that follow certain patterns are reasonable,
    while others are not. Thus, for example, it’s reasonable to say “All X are Y.
    This is not Y, so it’s not an X” (as in “All fishes are blue. This is not blue,
    so it’s not a fish.”). And just as one can somewhat whimsically imagine that Aristotle
    discovered syllogistic logic by going (“machine-learning-style”) through lots
    of examples of rhetoric, so too one can imagine that in the training of ChatGPT
    it will have been able to “discover syllogistic logic” by looking at lots of text
    on the web, etc. (And, yes, while one can therefore expect ChatGPT to produce
    text that contains “correct inferences” based on things like syllogistic logic,
    it’s a quite different story when it comes to more sophisticated formal logic—and
    I think one can expect it to fail here for the same kind of reasons it fails in
    parenthesis matching.)
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 这个理论可能是什么样的？嗯，有一个微小的角落基本上已知了两千年，那就是[逻辑](https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/)。当然，在亚里士多德发现它的三段论形式中，逻辑基本上是一种说法，即遵循某些模式的句子是合理的，而其他句子则不是。因此，例如，说“所有
    X 都是 Y。这不是 Y，所以它不是 X”是合理的（如“所有鱼都是蓝色。这不是蓝色，所以它不是鱼。”）。就像人们可以略带幽默地想象亚里士多德通过大量修辞例子（“机器学习风格”）发现了三段论逻辑一样，人们也可以想象在
    ChatGPT 的训练中，它将能够通过查看网络上的大量文本等内容“发现三段论逻辑”（是的，虽然因此可以期望 ChatGPT 生成包含基于三段论逻辑等内容的“正确推理”的文本，但当涉及更复杂的形式逻辑时情况就大不相同了——我认为可以期望它在括号匹配方面失败的原因也会导致它在这里失败）。
- en: But beyond the narrow example of logic, what can be said about how to systematically
    construct (or recognize) even plausibly meaningful text? Yes, there are things
    like [Mad Libs^(&reg)](https://en.wikipedia.org/wiki/Mad_Libs) that use very specific
    “phrasal templates”. But somehow ChatGPT implicitly has a much more general way
    to do it. And perhaps there’s nothing to be said about how it can be done beyond
    “somehow it happens when you have 175 billion neural net weights”. But I strongly
    suspect that there’s a much simpler and stronger story.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 但除了逻辑这个狭窄的例子之外，如何系统地构建（或识别）甚至可能有意义的文本？是的，有像[Mad Libs^(&reg)](https://en.wikipedia.org/wiki/Mad_Libs)这样使用非常具体的“短语模板”的东西。但不知何故，ChatGPT
    隐含地有一种更通用的方法来做到这一点。也许除了“当你有 1750 亿个神经网络权重时，某种方式会发生”之外，我们无法说出如何做到这一点。但我强烈怀疑有一个更简单更强大的故事。
- en: Meaning Space and Semantic Laws of Motion
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 意义空间和语义运动规律
- en: We discussed above that inside ChatGPT any piece of text is effectively represented
    by an array of numbers that we can think of as coordinates of a point in some
    kind of “linguistic feature space”. So when ChatGPT continues a piece of text
    this corresponds to tracing out a trajectory in linguistic feature space. But
    now we can ask what makes this trajectory correspond to text we consider meaningful.
    And might there perhaps be some kind of “semantic laws of motion” that define—or
    at least constrain—how points in linguistic feature space can move around while
    preserving “meaningfulness”?
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论过，在 ChatGPT 中，任何文本片段实际上都被一组数字表示，我们可以将其视为某种“语言特征空间”中某点的坐标。因此，当 ChatGPT
    继续一个文本片段时，这相当于在语言特征空间中描绘出一条轨迹。但现在我们可以问，是什么使得这条轨迹对应于我们认为有意义的文本。也许在语言特征空间中有一些“语义运动规律”，定义了——或者至少约束了——点在其中如何移动以保持“有意义性”？
- en: 'So what is this linguistic feature space like? Here’s an example of how single
    words (here, common nouns) might get laid out if we project such a feature space
    down to 2D:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这个语言特征空间是什么样的？这里是一个示例，展示了如果我们将这样一个特征空间投影到 2D 中，单词（这里是常见名词）可能会被布置的样子：
- en: '![](Image00086.jpg)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00086.jpg)'
- en: We saw another example above based on words representing plants and animals.
    But the point in both cases is that “semantically similar words” are placed nearby.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上面看到了另一个例子，基于代表植物和动物的单词。但两种情况的共同点是“语义相似的单词”被放置在附近。
- en: 'As another example, here’s how words corresponding to different parts of speech
    get laid out:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，这里展示了不同词性对应的单词是如何排列的：
- en: '![](Image00087.jpg)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00087.jpg)'
- en: 'Of course, a given word doesn’t in general just have “one meaning” (or necessarily
    correspond to just one part of speech). And by looking at how sentences containing
    a word lay out in feature space, one can often “tease apart” different meanings—as
    in the example here for the word “crane” (bird or machine?):'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一个给定的单词通常不只有“一个含义”（或者不一定对应于一个词性）。通过查看包含一个单词的句子在特征空间中的排列方式，人们通常可以“区分出”不同的含义——就像这里对于“起重机”这个词的例子一样（鸟还是机器？）：
- en: '![](Image00088.jpg)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00088.jpg)'
- en: 'OK, so it’s at least plausible that we can think of this feature space as placing
    “words nearby in meaning” close in this space. But what kind of additional structure
    can we identify in this space? Is there for example some kind of notion of “parallel
    transport” that would reflect “flatness” in the space? One way to get a handle
    on that is to look at analogies:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，至少可以认为我们可以将这个特征空间看作是将“意义相近的单词”放在这个空间中靠近的地方。但在这个空间中我们能够识别出什么样的额外结构呢？例如，是否存在某种“平行传输”的概念，反映了空间中的“平坦性”？了解这一点的一种方法是看类比：
- en: '![](Image00089.jpg)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00089.jpg)'
- en: And, yes, even when we project down to 2D, there’s often at least a “hint of
    flatness”, though it’s certainly not universally seen.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，即使我们投影到2D，通常至少会有一些“平坦的迹象”，尽管这当然并非普遍可见。
- en: 'So what about trajectories? We can look at the trajectory that a prompt for
    ChatGPT follows in feature space—and then we can see how ChatGPT continues that:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 那么轨迹呢？我们可以看看ChatGPT的提示在特征空间中遵循的轨迹，然后我们可以看看ChatGPT是如何继续的：
- en: '![](Image00090.jpg)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00090.jpg)'
- en: There’s certainly no “geometrically obvious” law of motion here. And that’s
    not at all surprising; we fully expect this to be a [considerably more complicated
    story](https://writings.stephenwolfram.com/2021/09/multicomputation-a-fourth-paradigm-for-theoretical-science/#linguistics)
    . And, for example, it’s far from obvious that even if there is a “semantic law
    of motion” to be found, what kind of embedding (or, in effect, what “variables”)
    it’ll most naturally be stated in.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显然没有“几何上明显的运动规律”。这一点一点也不令人惊讶；我们完全预期这将是一个[相当复杂的故事](https://writings.stephenwolfram.com/2021/09/multicomputation-a-fourth-paradigm-for-theoretical-science/#linguistics)。例如，即使存在“语义运动规律”，也不明显会以何种嵌入（或者实际上以何种“变量”）最自然地陈述。
- en: 'In the picture above, we’re showing several steps in the “trajectory”—where
    at each step we’re picking the word that ChatGPT considers the most probable (the
    “zero temperature” case). But we can also ask what words can “come next” with
    what probabilities at a given point:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图片中，我们展示了“轨迹”中的几个步骤——在每一步中，我们选择ChatGPT认为最有可能的单词（“零温度”情况）。但我们也可以询问在给定点上下一个可能出现的单词及其概率是什么：
- en: '![](Image00091.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00091.jpg)'
- en: 'And what we see in this case is that there’s a “fan” of high-probability words
    that seems to go in a more or less definite direction in feature space. What happens
    if we go further? Here are the successive “fans” that appear as we “move along”
    the trajectory:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们看到有一个“高概率词”的“扇形”，在特征空间中似乎沿着一个更或多或少明确的方向前进。如果我们继续前进会发生什么？以下是我们“沿着”轨迹“移动”时出现的连续“扇形”：
- en: '![](Image00092.jpg)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00092.jpg)'
- en: 'Here’s a 3D representation, going for a total of 40 steps:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个3D表示，共进行了40步：
- en: '![](Image00093.jpg)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![](Image00093.jpg)'
- en: And, yes, this seems like a mess—and doesn’t do anything to particularly encourage
    the idea that one can expect to identify “mathematical-physics-like” “semantic
    laws of motion” by empirically studying “what ChatGPT is doing inside”. But perhaps
    we’re just looking at the “wrong variables” (or wrong coordinate system) and if
    only we looked at the right one, we’d immediately see that ChatGPT is doing something
    “mathematical-physics-simple” like following geodesics. But as of now, we’re not
    ready to “empirically decode” from its “internal behavior” what ChatGPT has “discovered”
    about how human language is “put together”.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这看起来像一团乱麻，并且并没有特别鼓励人们期望通过经验研究“ChatGPT内部正在做什么”来确定“类似数学物理的”“语义运动定律”。但也许我们只是在看“错误的变量”（或错误的坐标系），如果我们只看正确的变量，我们会立刻看到ChatGPT正在做一些“数学物理简单”的事情，比如遵循测地线。但目前，我们还没有准备好从其“内部行为”中“经验性地解码”ChatGPT已经“发现”有关人类语言“如何组合”的内容。
- en: Semantic Grammar and the Power of Computational Language
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语义语法和计算语言的力量
- en: 'What does it take to produce “meaningful human language”? In the past, we might
    have assumed it could be nothing short of a human brain. But now we know it can
    be done quite respectably by the neural net of ChatGPT. Still, maybe that’s as
    far as we can go, and there’ll be nothing simpler—or more human understandable—that
    will work. But my strong suspicion is that the success of ChatGPT implicitly reveals
    an important “scientific” fact: that there’s actually a lot more structure and
    simplicity to meaningful human language than we ever knew—and that in the end
    there may be even fairly simple rules that describe how such language can be put
    together.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 产生“有意义的人类语言”需要什么？过去，我们可能认为这只能由人类大脑完成。但现在我们知道，ChatGPT的神经网络也可以相当体面地完成这项任务。或许这已经是我们能达到的极限了，没有更简单、更易理解的方法可以实现。但我强烈怀疑ChatGPT的成功隐含地揭示了一个重要的“科学”事实：有关有意义的人类语言的结构和简单性远比我们所知道的要多，最终可能存在着描述如何组合这种语言的相当简单的规则。
- en: As we mentioned above, syntactic grammar gives rules for how words corresponding
    to things like different parts of speech can be put together in human language.
    But to deal with meaning, we need to go further. And one version of how to do
    this is to think about not just a syntactic grammar for language, but also a semantic
    one.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们上面提到的，句法语法规定了词语如何在人类语言中组合在一起，对应不同的词类。但要处理意义，我们需要更进一步。如何做到这一点的一个版本是不仅考虑语言的句法语法，还要考虑语义语法。
- en: For purposes of syntax, we identify things like nouns and verbs. But for purposes
    of semantics, we need “finer gradations”. So, for example, we might identify the
    concept of “moving”, and the concept of an “object” that “maintains its identity
    independent of location”. There are endless specific examples of each of these
    “semantic concepts”. But for the purposes of our semantic grammar, we’ll just
    have some general kind of rule that basically says that “objects” can “move”.
    There’s a lot to say about how all this might work ([some of which I’ve said before](https://writings.stephenwolfram.com/2016/10/computational-law-symbolic-discourse-and-the-ai-constitution/)
    ). But I’ll content myself here with just a few remarks that indicate some of
    the potential path forward.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 就句法而言，我们识别诸如名词和动词之类的事物。但就语义而言，我们需要“更细微的分级”。因此，例如，我们可能识别“移动”的概念，以及“保持其独立于位置的身份的对象”的概念。每个“语义概念”都有无数具体的例子。但就我们的语义语法而言，我们只需有一些基本规则，基本上说“对象”可以“移动”。关于这一切可能如何运作，有很多可以说的（[其中一些我之前已经说过](https://writings.stephenwolfram.com/2016/10/computational-law-symbolic-discourse-and-the-ai-constitution/)）。但在这里我只会满足于简单地提出一些迈向前进的潜在途径。
- en: It’s worth mentioning that even if a sentence is perfectly OK according to the
    semantic grammar, that doesn’t mean it’s been realized (or even could be realized)
    in practice. “The elephant traveled to the Moon” would doubtless “pass” our semantic
    grammar, but it certainly hasn’t been realized (at least yet) in our actual world—though
    it’s absolutely fair game for a fictional world.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，即使一句话在语义语法上完全没问题，也不意味着它已经在实践中实现（甚至可能无法实现）。“大象去月球旅行”无疑会“通过”我们的语义语法，但它在我们实际的世界中肯定还没有实现（至少目前还没有）—尽管这绝对适用于虚构世界。
- en: When we start talking about “semantic grammar” we’re soon led to ask “What’s
    underneath it?” What “model of the world” is it assuming? A syntactic grammar
    is really just about the construction of language from words. But a semantic grammar
    necessarily engages with some kind of “model of the world”—something that serves
    as a “skeleton” on top of which language made from actual words can be layered.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始谈论“语义语法”时，我们很快就会问：“它的底层是什么？”它假设了什么“世界模型”？句法语法实际上只是关于从单词构建语言。但语义语法必然涉及某种“世界模型”——一种作为“骨架”的东西，语言可以在其上层叠而成。
- en: 'Until recent times, we might have imagined that (human) language would be the
    only general way to describe our “model of the world”. Already a few centuries
    ago there started to be formalizations of specific kinds of things, based particularly
    on mathematics. But now there’s a much more general approach to formalization:
    [computational language](https://writings.stephenwolfram.com/2019/05/what-weve-built-is-a-computational-language-and-thats-very-important/)
    .'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，我们可能会想象（人类）语言将是描述我们“世界模型”的唯一通用方式。几个世纪前，开始对特定类型的事物进行形式化，特别是基于数学。但现在有了一种更通用的形式化方法：[计算语言](https://writings.stephenwolfram.com/2019/05/what-weve-built-is-a-computational-language-and-thats-very-important/)。
- en: 'And, yes, that’s been my big project over the course of more than four decades
    (as now embodied in the [Wolfram Language](https://www.wolfram.com/language/)
    ): to develop a precise symbolic representation that can talk as broadly as possible
    about things in the world, as well as abstract things that we care about. And
    so, for example, we have symbolic representations for [cities](https://reference.wolfram.com/language/ref/entity/City.html)
    and [molecules](https://reference.wolfram.com/language/guide/MolecularStructureAndComputation.html)
    and [images](https://reference.wolfram.com/language/guide/ImageRepresentation.html)
    and [neural networks](https://reference.wolfram.com/language/guide/NeuralNetworkConstruction.html)
    , and we have built-in knowledge about how to compute about those things.'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这是我在四十多年的时间里的大项目（现在体现在[Wolfram语言](https://www.wolfram.com/language/)中）：开发一个精确的符号表示，可以尽可能广泛地谈论世界上的事物，以及我们关心的抽象事物。因此，例如，我们有关于[城市](https://reference.wolfram.com/language/ref/entity/City.html)、[分子](https://reference.wolfram.com/language/guide/MolecularStructureAndComputation.html)、[图像](https://reference.wolfram.com/language/guide/ImageRepresentation.html)和[神经网络](https://reference.wolfram.com/language/guide/NeuralNetworkConstruction.html)的符号表示，并且我们内置了关于如何计算这些事物的知识。
- en: And, after decades of work, we’ve covered a lot of areas in this way. But in
    the past, we haven’t particularly dealt with “[everyday discourse](https://writings.stephenwolfram.com/2016/10/computational-law-symbolic-discourse-and-the-ai-constitution/)
    ”. In “I bought two pounds of apples” we can [readily represent](https://reference.wolfram.com/language/ref/entity/Food.html)
    (and do nutrition and other computations on) the “two pounds of apples”. But we
    don’t (quite yet) have a symbolic representation for “I bought”.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 经过几十年的工作，我们以这种方式涵盖了许多领域。但在过去，我们并没有特别处理“[日常话语](https://writings.stephenwolfram.com/2016/10/computational-law-symbolic-discourse-and-the-ai-constitution/)”。在“我买了两磅苹果”中，我们可以[很容易地表示](https://reference.wolfram.com/language/ref/entity/Food.html)（并对其进行营养和其他计算）“两磅苹果”。但我们（还）没有“我买了”这样的符号表示。
- en: It’s all connected to the idea of semantic grammar—and the goal of having a
    generic symbolic “construction kit” for concepts, that would give us rules for
    what could fit together with what, and thus for the “flow” of what we might turn
    into human language.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都与语义语法的概念有关，以及拥有一个通用的符号“构建工具包”来构建概念的目标，这将为我们提供关于什么可以与什么结合以及我们可能转化为人类语言的“流动”规则。
- en: But let’s say we had this “symbolic discourse language”. What would we do with
    it? We could start off doing things like generating “locally meaningful text”.
    But ultimately we’re likely to want more “globally meaningful” results—which means
    “computing” more about what can actually exist or happen in the world (or perhaps
    in some consistent fictional world).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 但假设我们有了这种“符号话语语言”。我们可以开始做一些生成“局部有意义文本”的事情。但最终，我们可能会希望获得更多“全局有意义”的结果——这意味着“计算”更多关于实际存在或发生在世界中的事物（或者在某个一致的虚构世界中）。
- en: 'Right now in Wolfram Language we have a huge amount of built-in computational
    knowledge about lots of kinds of things. But for a complete symbolic discourse
    language we’d have to build in additional “calculi” about general things in the
    world: if an object moves from A to B and from B to C, then it’s moved from A
    to C, etc.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 目前在 Wolfram 语言中，我们拥有大量关于各种事物的内置计算知识。但对于一个完整的符号性论述语言，我们将不得不构建关于世界一般事物的额外“演算法”：如果一个物体从
    A 移动到 B，然后从 B 移动到 C，那么它就从 A 移动到 C，等等。
- en: Given a symbolic discourse language we might use it to make “standalone statements”.
    But we can also use it to ask questions about the world, “Wolfram|Alpha style”.
    Or we can use it to state things that we “want to make so”, presumably with some
    external actuation mechanism. Or we can use it to make assertions—perhaps about
    the actual world, or perhaps about some specific world we’re considering, fictional
    or otherwise.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个符号性论述语言，我们可以用它来做出“独立的陈述”。但我们也可以用它来问世界问题，“Wolfram|Alpha 风格”。或者我们可以用它来陈述我们“想要实现的事情”，可能有一些外部执行机制。或者我们可以用它来做出断言——也许是关于实际世界，或者是关于我们正在考虑的某个特定世界，无论是虚构的还是其他。
- en: Human language is fundamentally imprecise, not least because it isn’t “tethered”
    to a specific computational implementation, and its meaning is basically defined
    just by a “social contract” between its users. But computational language, by
    its nature, has a certain fundamental precision—because in the end what it specifies
    can always be “unambiguously executed on a computer”. Human language can usually
    get away with a certain vagueness. (When we say “planet” does it include exoplanets
    or not, etc.?) But in computational language we have to be precise and clear about
    all the distinctions we’re making.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 人类语言基本上是不精确的，至少因为它没有与特定计算实现“捆绑”，其含义基本上仅由其用户之间的“社会契约”定义。但计算语言，由于其本质，具有一定的基本精度——因为最终它指定的内容总是可以在计算机上“无歧义地执行”。人类语言通常可以容忍一定的模糊性。（当我们说“行星”时，是否包括系外行星等？）但在计算语言中，我们必须准确清晰地表达我们所做的所有区分。
- en: It’s often convenient to leverage ordinary human language in making up names
    in computational language. But the meanings they have in computational language
    are necessarily precise—and might or might not cover some particular connotation
    in typical human language usage.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建计算语言中，通常方便利用普通人类语言来构建名称。但它们在计算语言中的含义必须是精确的，可能或可能不涵盖典型人类语言用法中的某些特定内涵。
- en: How should one figure out the fundamental “ontology” suitable for a general
    symbolic discourse language? Well, it’s not easy. Which is perhaps why little
    has been done in these since the primitive beginnings Aristotle made more than
    two millennia ago. But it really helps that today we now know so much about how
    to think about the world computationally (and it doesn’t hurt to have a “fundamental
    metaphysics” from our [Physics Project](https://www.wolframphysics.org/) and the
    [idea of the ruliad](https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/)
    ).
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 如何确定适用于一般符号性论述语言的基本“本体论”？嗯，这并不容易。这也许是为什么自两千多年前亚里士多德做出原始开端以来，这方面的工作很少有所进展。但今天我们对如何以计算方式思考世界有了如此多的了解，这确实有所帮助（而且从我们的[物理项目](https://www.wolframphysics.org/)和[ruliad
    的概念](https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/)中得到“基本形而上学”也不会有害）。
- en: But what does all this mean in the context of ChatGPT? From its training ChatGPT
    has effectively “pieced together” a certain (rather impressive) quantity of what
    amounts to semantic grammar. But its very success gives us a reason to think that
    it’s going to be feasible to construct something more complete in computational
    language form. And, unlike what we’ve so far figured out about the innards of
    ChatGPT, we can expect to design the computational language so that it’s readily
    understandable to humans.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 但在 ChatGPT 的背景下，所有这些意味着什么呢？从其训练中，ChatGPT 已经有效地“拼凑”了相当（相当令人印象深刻）数量的语义语法。但它的成功让我们有理由认为，构建更完整的计算语言形式是可行的。与我们迄今为止对
    ChatGPT 内部的了解不同，我们可以期望设计计算语言，使其对人类容易理解。
- en: When we talk about semantic grammar, we can draw an analogy to syllogistic logic.
    At first, syllogistic logic was essentially a collection of rules about statements
    expressed in human language. But (yes, two millennia later) [when formal logic
    was developed](https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/#the-history)
    , the original basic constructs of syllogistic logic could now be used to build
    huge “formal towers” that include, for example, the operation of modern digital
    circuitry. And so, we can expect, it will be with more general semantic grammar.
    At first, it may just be able to deal with simple patterns, expressed, say, as
    text. But once its whole computational language framework is built, we can expect
    that it will be able to be used to erect tall towers of “generalized semantic
    logic”, that allow us to work in a precise and formal way with all sorts of things
    that have never been accessible to us before, except just at a “ground-floor level”
    through human language, with all its vagueness.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论语义语法时，我们可以将其类比为三段论逻辑。起初，三段论逻辑本质上是关于用人类语言表达的陈述的一系列规则。但是（是的，两千年后）[当形式逻辑被发展出来时](https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/#the-history)，三段论逻辑的最初基本构造现在可以用来构建包括现代数字电路操作在内的巨大“形式塔”。因此，我们可以期待，更一般的语义语法也会如此。起初，它可能只能处理简单模式，例如以文本形式表达。但是一旦建立了整个计算语言框架，我们可以期待它将被用于建立“广义语义逻辑”的高塔，使我们能够以精确和正式的方式处理以前从未可及的各种事物，除了通过人类语言的“地面层”以及其模糊性。
- en: 'We can think of the construction of computational language—and semantic grammar—as
    representing a kind of ultimate compression in representing things. Because it
    allows us to talk about the essence of what’s possible, without, for example,
    dealing with all the “turns of phrase” that exist in ordinary human language.
    And we can view the great strength of ChatGPT as being something a bit similar:
    because it too has in a sense “drilled through” to the point where it can “put
    language together in a semantically meaningful way” without concern for different
    possible turns of phrase.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将计算语言的构建和语义语法视为一种代表事物的终极压缩。因为它使我们能够谈论可能性的本质，而无需处理普通人类语言中存在的所有“措辞”。我们可以将ChatGPT的巨大优势视为有点类似：因为它也在某种意义上“深入研究”到了可以“以语义上有意义的方式组合语言”的程度，而不必担心不同可能的措辞。
- en: So what would happen if we applied ChatGPT to underlying computational language?
    The computational language can describe what’s possible. But what can still be
    added is a sense of “what’s popular”—based for example on reading all that content
    on the web. But then—underneath—operating with computational language means that
    something like ChatGPT has immediate and fundamental access to what amount to
    ultimate tools for making use of potentially irreducible computations. And that
    makes it a system that can not only “generate reasonable text”, but can expect
    to work out whatever can be worked out about whether that text actually makes
    “correct” statements about the world—or whatever it’s supposed to be talking about.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果我们将ChatGPT应用于基础计算语言会发生什么？计算语言可以描述可能发生的事情。但可以添加的是“流行的”感觉，例如基于阅读网络上所有内容。但是，通过计算语言操作意味着像ChatGPT这样的东西立即且根本地可以访问潜在不可简化计算的终极工具。这使得它不仅可以“生成合理的文本”，还可以期望解决关于该文本是否实际提出“正确”陈述的问题，或者它应该谈论的内容。
- en: So ... What Is ChatGPT Doing, and Why Does It Work?
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么...ChatGPT在做什么，为什么有效？
- en: The basic concept of ChatGPT is at some level rather simple. Start from a huge
    sample of human-created text from the web, books, etc. Then train a neural net
    to generate text that’s “like this”. And in particular, make it able to start
    from a “prompt” and then continue with text that’s “like what it’s been trained
    with”.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的基本概念在某种程度上相当简单。从网络、书籍等人类创作文本的大样本开始。然后训练神经网络生成“类似于这样”的文本。特别是，使其能够从“提示”开始，然后继续生成“与其训练内容相似”的文本。
- en: As we’ve seen, the actual neural net in ChatGPT is made up of very simple elements—though
    billions of them. And the basic operation of the neural net is also very simple,
    consisting essentially of passing input derived from the text it’s generated so
    far “once through its elements” (without any loops, etc.) for every new word (or
    part of a word) that it generates.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，ChatGPT中的实际神经网络由非常简单的元素组成，尽管有数十亿个。神经网络的基本操作也非常简单，基本上是将从生成的文本中派生的输入“通过其元素一次”（没有任何循环等）传递给每个新单词（或单词的一部分）。
- en: But the remarkable—and unexpected—thing is that this process can produce text
    that’s successfully “like” what’s out there on the web, in books, etc. And not
    only is it coherent human language, it also “says things” that “follow its prompt”
    making use of content it’s “read”. It doesn’t always say things that “globally
    make sense” (or correspond to correct computations)—because (without, for example,
    [accessing the “computational superpowers” of Wolfram|Alpha](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)
    ) it’s just saying things that “sound right” based on what things “sounded like”
    in its training material.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 但值得注意的，也是意想不到的是，这个过程可以产生成功地“类似于”网络上或书籍中的文本。它不仅是连贯的人类语言，还“说出”了“遵循其提示”的内容，利用了它“阅读”的内容。它并不总是说出“全局意义上有意义的”东西（或对应于正确计算）—因为（例如，没有[访问“沃尔夫拉姆|阿尔法的计算超能力”](https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/)），它只是根据在其训练材料中的东西“听起来像什么”来说出“听起来正确”的东西。
- en: 'The specific engineering of ChatGPT has made it quite compelling. But ultimately
    (at least until it can use outside tools) ChatGPT is “merely” pulling out some
    “coherent thread of text” from the “statistics of conventional wisdom” that it’s
    accumulated. But it’s amazing how human-like the results are. And as I’ve discussed,
    this suggests something that’s at least scientifically very important: that human
    language (and the patterns of thinking behind it) are somehow simpler and more
    “law like” in their structure than we thought. ChatGPT has implicitly discovered
    it. But we can potentially explicitly expose it, with semantic grammar, computational
    language, etc.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的具体工程使其非常引人注目。但最终（至少在它可以使用外部工具之前），ChatGPT只是从其积累的“常识统计”中提取出一些“连贯的文本”。但令人惊讶的是结果多么类似于人类。正如我所讨论的，这表明了至少在科学上非常重要的一点：人类语言（以及其背后的思维模式）在结构上比我们想象的要简单和更“法则化”。ChatGPT已经隐含地发现了这一点。但我们可能可以通过语义语法、计算语言等明确地揭示它。
- en: What ChatGPT does in generating text is very impressive—and the results are
    usually very much like what we humans would produce. So does this mean ChatGPT
    is working like a brain? Its underlying artificial-neural-net structure was ultimately
    modeled on an idealization of the brain. And it seems quite likely that when we
    humans generate language many aspects of what’s going on are quite similar.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT在生成文本方面的表现非常令人印象深刻，结果通常非常类似于我们人类会产生的结果。那么这是否意味着ChatGPT像大脑一样工作？它的基础人工神经网络结构最终是根据对大脑的理想化建模的。当我们人类生成语言时，很可能许多方面的情况都非常相似。
- en: 'When it comes to training (AKA learning) the different “hardware” of the brain
    and of current computers (as well as, perhaps, some undeveloped algorithmic ideas)
    forces ChatGPT to use a strategy that’s probably rather different (and in some
    ways much less efficient) than the brain. And there’s something else as well:
    unlike even in typical algorithmic computation, ChatGPT doesn’t internally “have
    loops” or “recompute on data”. And that inevitably limits its computational capability—even
    with respect to current computers, but definitely with respect to the brain.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及培训（又称学习）时，大脑和当前计算机的不同“硬件”（以及可能一些未开发的算法思想）迫使ChatGPT使用一种可能相当不同（在某些方面远不如大脑高效）的策略。还有另一点：与典型的算法计算甚至不同，ChatGPT内部没有“循环”或“在数据上重新计算”。这不可避免地限制了它的计算能力—即使与当前计算机相比，但绝对是相对于大脑。
- en: It’s not clear how to “fix that” and still maintain the ability to train the
    system with reasonable efficiency. But to do so will presumably allow a future
    ChatGPT to do even more “brain-like things”. Of course, there are plenty of things
    that brains don’t do so well— particularly involving what amount to irreducible
    computations. And for these both brains and things like ChatGPT have to seek “outside
    tools”—like [Wolfram Language](https://www.wolfram.com/language/) .
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 不清楚如何“修复这个问题”并仍然保持以合理效率训练系统的能力。但这样做很可能会让未来的ChatGPT能够做更多“类似大脑的事情”。当然，大脑也有很多做得不太好的事情，特别是涉及到不可简化计算的事情。对于这些，无论是大脑还是像ChatGPT这样的东西都必须寻求“外部工具”—比如[Wolfram
    Language](https://www.wolfram.com/language/)。
- en: But for now it’s exciting to see what ChatGPT has already been able to do. At
    some level it’s a great example of the fundamental scientific fact that large
    numbers of simple computational elements can do remarkable and unexpected things.
    But it also provides perhaps the best impetus we’ve had in two thousand years
    to understand better just what the fundamental character and principles might
    be of that central feature of the human condition that is human language and the
    processes of thinking behind it.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 但目前看到ChatGPT已经能够做到的事情令人兴奋。在某种程度上，它是一个很好的例子，说明大量简单的计算元素可以做出令人惊讶和意想不到的事情。但它也可能提供了我们两千年来最好的动力，来更好地理解人类语言的核心特征和原则，以及背后的思维过程。
- en: Thanks
  id: totrans-386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谢谢
- en: 'I’ve been following the development of neural nets now for about 43 years,
    and during that time I’ve interacted with many people about them. Among them—some
    from long ago, some from recently, and some across many years—have been: Giulio
    Alessandrini, Dario Amodei, Etienne Bernard, Taliesin Beynon, Sebastian Bodenstein,
    Greg Brockman, Jack Cowan, Pedro Domingos, Jesse Galef, Roger Germundsson, Robert
    Hecht-Nielsen, Geoff Hinton, John Hopfield, Yann LeCun, Jerry Lettvin, Jerome
    Louradour, Marvin Minsky, Eric Mjolsness, Cayden Pierce, Tomaso Poggio, Matteo
    Salvarezza, Terry Sejnowski, Oliver Selfridge, Gordon Shaw, Jonas Sjöberg, Ilya
    Sutskever, Gerry Tesauro and Timothee Verdier. For help with this piece, I’d particularly
    like to thank Giulio Alessandrini and Brad Klee.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经关注神经网络的发展大约43年了，在这段时间里我与许多人交流过关于它们的话题。其中—一些是很久以前的，一些是最近的，还有一些是跨越多年的—有：Giulio
    Alessandrini, Dario Amodei, Etienne Bernard, Taliesin Beynon, Sebastian Bodenstein,
    Greg Brockman, Jack Cowan, Pedro Domingos, Jesse Galef, Roger Germundsson, Robert
    Hecht-Nielsen, Geoff Hinton, John Hopfield, Yann LeCun, Jerry Lettvin, Jerome
    Louradour, Marvin Minsky, Eric Mjolsness, Cayden Pierce, Tomaso Poggio, Matteo
    Salvarezza, Terry Sejnowski, Oliver Selfridge, Gordon Shaw, Jonas Sjöberg, Ilya
    Sutskever, Gerry Tesauro和Timothee Verdier。在撰写本文时，我特别要感谢Giulio Alessandrini和Brad
    Klee的帮助。
