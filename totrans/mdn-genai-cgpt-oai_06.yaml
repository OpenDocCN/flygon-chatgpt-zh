- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Understanding Prompt Design
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解提示设计
- en: In the previous chapters, we mentioned the term **prompt** several times while
    referring to user input in ChatGPT and OpenAI models in general.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们多次提到“提示”这个术语，同时指的是ChatGPT和OpenAI模型中的用户输入。
- en: 'This chapter focuses in more depth on the importance of prompt design and engineering
    as a technique to improve the accuracy of the model. Prompts heavily impact the
    model’s generated output: a well-designed prompt can help guide the model toward
    generating relevant and accurate output, while a poorly designed prompt can lead
    to irrelevant or confusing output. Finally, it is also important to incorporate
    ethical considerations into the prompt to prevent the model from generating harmful
    content.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章更深入地探讨了提示设计和工程作为改善模型准确性的技术的重要性。提示对模型生成的输出产生重大影响：一个设计良好的提示可以帮助引导模型生成相关和准确的输出，而一个设计不良的提示可能导致无关或令人困惑的输出。最后，还重要的是将道德考虑因素纳入提示中，以防止模型生成有害内容。
- en: 'In this chapter, we will discuss the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: What is a prompt and why is it important?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是提示，为什么它重要？
- en: Zero-, one-, and few-shot learning – typical of transformers models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零、一和少次学习 - 变压器模型的典型特征
- en: Principles of well-defined prompts to obtain relevant and consistent results
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得相关和一致结果的明确定义提示的原则
- en: Avoiding the risk of hidden bias and taking into account ethical considerations
    in ChatGPT
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免隐藏偏见的风险，并考虑ChatGPT中的道德考虑因素
- en: By the end of this chapter, you will be able to get high-quality results from
    your ChatGPT and OpenAI model interactions thanks to proper prompt design.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将能够通过适当的提示设计从ChatGPT和OpenAI模型的交互中获得高质量的结果。
- en: What is a prompt and why is it important?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是提示，为什么它重要？
- en: In the context of generative AI, a prompt refers to the input the user provides
    to the generative models. When we talk about ChatGPT and OpenAI models, prompts
    mainly refer to a piece of text in natural language or – as we saw for Codex models
    – in programming languages.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式人工智能的背景下，提示是指用户提供给生成模型的输入。当我们谈论ChatGPT和OpenAI模型时，提示主要指的是自然语言中的一段文本，或者 -
    正如我们在Codex模型中看到的那样 - 是编程语言中的一段文本。
- en: Prompts are the only way users can control the output generated by those models.
    As such, there is no surprise in saying that the quality of the prompts used to
    engage the AI system in a conversation is key to determining its success.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是用户可以控制这些模型生成的输出的唯一方式。因此，毫无疑问地说，用于与AI系统进行对话的提示的质量对于确定其成功至关重要。
- en: Well-defined prompts are the recipe for a successful conversation that covers
    the topics of interest; poorly-defined prompts, on the other hand, not only prevent
    the conversation from being useful to the user but could also lead to potentially
    misleading content. As we saw in the previous chapter, ChatGPT still suffers from
    some limitations, such as the 2021 cut-off of its knowledge base, as well as another
    caveat typical of generative AI systems in general, such as the phenomenon of
    hallucination.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 明确定义的提示是成功对话的秘诀，涵盖了感兴趣的主题；相反，定义不清晰的提示不仅会阻止对话对用户有用，还可能导致潜在的误导性内容。正如我们在上一章中看到的，ChatGPT仍然存在一些限制，比如其知识库的2021年截止日期，以及生成式人工智能系统通常存在的另一个警告，比如幻觉现象。
- en: Namely, imagine that we want to learn about **Convolutional Neural Networks**
    (**CNNs**). We don’t have any knowledge about **Artificial Neural Networks** (**ANNs**),
    so we need to start with a gentle introduction. The idea is that, starting from
    the first output, we can deep dive into relevant elements.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，想象一下我们想要了解**卷积神经网络**（**CNNs**）。我们对**人工神经网络**（**ANNs**）一无所知，因此需要从一个简单的介绍开始。这个想法是，从第一个输出开始，我们可以深入研究相关元素。
- en: 'Let’s examine the result of a poorly-defined prompt in ChatGPT:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看ChatGPT中一个定义不清晰提示的结果：
- en: '![Figure 4.1 – Example of a poorly-defined prompt](img/Figure_4.1_B19904.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1 - 一个定义不清晰提示的示例](img/Figure_4.1_B19904.jpg)'
- en: Figure 4.1 – Example of a poorly-defined prompt
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 - 一个定义不清晰提示的示例
- en: The result is correct and accurate, but it’s going through many technical concepts
    we may have never seen before. What are fully connected layers? What is a pooling
    layer? This answer assumes we have previous knowledge of ANNs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是正确和准确的，但涉及了许多我们以前可能从未见过的技术概念。全连接层是什么？池化层是什么？这个答案假设我们有人工神经网络的先前知识。
- en: 'Let’s try to give more context to ChatGPT to get a result that is more useful
    to us:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试为ChatGPT提供更多上下文，以获得对我们更有用的结果：
- en: '![Figure 4.2 – Example of a well-defined prompt](img/Figure_4.2_B19904.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 - 良好定义提示的示例](img/Figure_4.2_B19904.jpg)'
- en: Figure 4.2 – Example of a well-defined prompt
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 - 良好定义提示的示例
- en: As you can see, the wording in this response is much more likely than the one
    I was looking for. In the introduction, it doesn’t use words such as *multi-layer
    perceptron* or *fully connected layer*. It also provides, as requested, an example
    of the process of image recognition. Then, it goes into further details, making
    sure to explain each step with simple words.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，这个回答中的措辞比我寻找的那个更有可能。在介绍中，它不使用诸如*多层感知器*或*全连接层*之类的词语。它还提供了一个图像识别过程的示例，然后进一步详细说明，确保用简单的词语解释每一步。
- en: I’m pretty satisfied with this response and, as a user, I could now start asking
    about the pooling layer in more detail, for example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我对这个回答感到非常满意，作为用户，我现在可以开始更详细地询问关于池化层的问题，例如。
- en: Consequently, prompt design and engineering has been gaining more and more traction
    and it’s growing as a discipline itself.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，快速设计和工程正在变得越来越受到关注，并且作为一个独立的学科正在发展。
- en: Now, let’s focus on how to improve ChatGPT’s responses by leveraging its few-shot
    learning capabilities.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们专注于如何通过利用其少量样本学习能力来改进ChatGPT的回应。
- en: Zero-, one-, and few-shot learning – typical of transformers models
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 零、一和少量样本学习 - 典型的变压器模型
- en: In the previous chapters, we mentioned how OpenAI models, and hence also ChatGPT,
    come in a pre-trained format. They have been trained on a huge amount of data
    and have had their (billions of) parameters configured accordingly.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们提到了OpenAI模型，因此也包括ChatGPT，以预训练的格式呈现。它们经过大量数据的训练，并相应地配置了它们的（数十亿个）参数。
- en: However, this doesn’t mean that those models can’t learn anymore. In [*Chapter
    2*](B19904_02.xhtml#_idTextAnchor030), we saw that one way to customize an OpenAI
    model and make it more capable of addressing specific tasks is by **fine-tuning**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不意味着这些模型不能再学习了。在[*第2章*](B19904_02.xhtml#_idTextAnchor030)中，我们看到定制OpenAI模型并使其更能够解决特定任务的一种方法是通过**微调**。
- en: Definition
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 定义
- en: Fine-tuning is the process of adapting a pre-trained model to a new task. In
    fine-tuning, the parameters of the pre-trained model are altered, either by adjusting
    the existing parameters or by adding new parameters so that they fit the data
    for the new task. This is done by training the model on a smaller labeled dataset
    that is specific to the new task. The key idea behind fine-tuning is to leverage
    the knowledge learned from the pre-trained model and fine-tune it to the new task,
    rather than training a model from scratch.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 微调是将预训练模型适应新任务的过程。在微调中，预训练模型的参数被改变，要么通过调整现有参数，要么通过添加新参数使其适应新任务的数据。这是通过在特定于新任务的较小标记数据集上训练模型来完成的。微调的关键思想是利用从预训练模型中学到的知识，并将其微调到新任务，而不是从头开始训练模型。
- en: Fine-tuning is a proper training process that requires a training dataset, compute
    power, and some training time (depending on the amount of data and compute instances).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 微调是一个适当的训练过程，需要一个训练数据集、计算能力和一些训练时间（取决于数据量和计算实例）。
- en: 'That is why it is worth testing another method for our model to become more
    skilled in specific tasks: **shot learning**.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么值得测试另一种方法，让我们的模型在特定任务上变得更加熟练：**少量样本学习**。
- en: The idea is to let the model learn from simple examples rather than the entire
    dataset. Those examples are samples of the way we would like the model to respond
    so that the model not only learns the content but also the format, style, and
    taxonomy to use in its response.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是让模型从简单的例子中学习，而不是整个数据集。这些例子是我们希望模型响应的方式的样本，以便模型不仅学习内容，还学习格式、风格和分类法来在其回应中使用。
- en: Furthermore, shot learning occurs directly via the prompt (as we will see in
    the following scenarios), so the whole experience is less time-consuming and easier
    to perform.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过提示直接进行学习（正如我们将在接下来的场景中看到的那样），整个体验更少耗时且更易执行。
- en: The number of examples provided determines the level of shot learning we are
    referring to. In other words, we refer to zero-shot if no example is provided,
    one-shot if one example is provided, and few-shot if more than 2-3 examples are
    provided.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的示例数量决定了我们所指的样本学习的级别。换句话说，如果没有提供示例，则我们称之为零样本，如果提供了一个示例，则称为单样本，如果提供了2-3个以上的示例，则称为少样本。
- en: 'Let’s focus on each of those scenarios:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于每一个场景：
- en: '**Zero-shot learning**. In this type of learning, the model is asked to perform
    a task for which it has not seen any training examples. The model must rely on
    prior knowledge or general information about the task to complete the task. For
    example, a zero-shot learning approach could be that of asking the model to generate
    a description, as defined in my prompt:'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零样本学习**。在这种学习中，模型被要求执行一个它没有见过训练示例的任务。模型必须依靠关于任务的先验知识或一般信息来完成任务。例如，零样本学习方法可能是要求模型生成一个描述，就像我在提示中定义的一样：'
- en: '![Figure 4.3 – Example of zero-shot learning](img/Figure_4.3_B19904.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – 零样本学习示例](img/Figure_4.3_B19904.jpg)'
- en: Figure 4.3 – Example of zero-shot learning
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 零样本学习示例
- en: '**One-shot learning**: In this type of learning, the model is given a single
    example of each new task it is asked to perform. The model must use its prior
    knowledge to generalize from this single example to perform the task. If we consider
    the preceding example, I could provide my model with a prompt-completion example
    before asking it to generate a new one:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单样本学习**：在这种类型的学习中，模型只提供每个新任务的单个示例。模型必须利用其先前的知识从这个单一示例中泛化，以执行任务。如果考虑前面的例子，我可以在要求其生成新的示例之前，向模型提供一个提示完成的示例：'
- en: '![Figure 4.4 – Example of one-shot learning](img/Figure_4.4_B19904.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 单样本学习示例](img/Figure_4.4_B19904.jpg)'
- en: Figure 4.4 – Example of one-shot learning
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 单样本学习示例
- en: 'Note that the way I provided an example was similar to the structure used for
    fine-tuning:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我提供示例的方式类似于微调所使用的结构：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Few-shot learning**: In this type of learning, the model is given a small
    number of examples (typically between 3 and 5) of each new task it is asked to
    perform. The model must use its prior knowledge to generalize from these examples
    to perform the task. Let’s continue with our example and provide the model with
    further examples:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**少样本学习**：在这种学习中，模型只提供了每个新任务的少量示例（通常在3到5个之间）。模型必须利用其先前的知识从这些示例中泛化，以执行任务。让我们继续我们的例子并提供模型更多的示例：'
- en: '![Figure 4.5 – Example of few-shot learning with three examples](img/Figure_4.5_B19904.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5 – 少样本学习示例](img/Figure_4.5_B19904.jpg)'
- en: Figure 4.5 – Example of few-shot learning with three examples
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 少样本学习示例，提供了三个示例
- en: 'The nice thing about few-shot learning is that you can also control model output
    in terms of how it is presented. You can also provide your model with a template
    of the way you would like your output to look. For example, consider the following
    tweet classifier:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习的好处在于，你还可以控制模型输出的呈现方式。你还可以为模型提供你希望输出看起来的模板。例如，考虑以下推文分类器：
- en: '![Figure 4.6 – Few-shot learning for a tweets classifier. This is a modified
    version of the original script from https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/completions](img/Figure_4.6_B19904.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 推文分类器的少样本学习。这是修改自https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/completions的原始脚本](img/Figure_4.6_B19904.jpg)'
- en: Figure 4.6 – Few-shot learning for a tweets classifier. This is a modified version
    of the original script from https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/completions
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 推文分类器的少样本学习。这是修改自https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/completions的原始脚本
- en: Let’s examine the preceding figure. First, I provided ChatGPT with some examples
    of labeled tweets. Then, I provided the same tweets but in a different data format
    (list format), as well as the labels in the same format. Finally, in list format,
    I provided unlabeled tweets so that the model returns a list of labels.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看前面的图。首先，我向ChatGPT提供了一些标记的推文示例。然后，我以不同的数据格式（列表格式）提供了相同的推文，以及相同格式的标签。最后，我以列表格式提供未标记的推文，以便模型返回标签列表。
- en: 'The output format is not the only thing you can teach your model, though. You
    can also teach it to act and speak with a particular jargon and taxonomy, which
    could help you obtain the desired result with the desired wording:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 输出格式并不是您可以教给您的模型的唯一内容。您还可以教它以特定的行话和分类法行事和言语，这可以帮助您以期望的措辞获得所需的结果：
- en: '![Figure 4.7 – Example of a conversation with ChatGPT acting as an interviewer](img/Figure_4.7_B19904.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – ChatGPT 充当面试官进行对话的例子](img/Figure_4.7_B19904.jpg)'
- en: Figure 4.7 – Example of a conversation with ChatGPT acting as an interviewer
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – ChatGPT 充当面试官进行对话的例子
- en: 'Or, imagine you want to generate a chatbot called Simpy that is very funny
    and sarcastic while responding:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，想象一下，你想生成一个名为 Simpy 的聊天机器人，回复时非常滑稽和讽刺：
- en: '![Figure 4.8 – Example of a chatbot that is funny and sarcastic, making fun
    of my request](img/Figure_4.8_B19904.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 一个滑稽而讽刺的聊天机器人的例子，取笑我的请求](img/Figure_4.8_B19904.jpg)'
- en: Figure 4.8 – Example of a chatbot that is funny and sarcastic, making fun of
    my request
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 一个滑稽而讽刺的聊天机器人的例子，取笑我的请求
- en: We have to say, with this last one, ChatGPT nailed it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不得不说，通过最后一个例子，ChatGPT 做得很好。
- en: Shot-learning possibilities are limitless (and often more useful than Simpy)
    – it’s only a matter of testing and a little bit of patience in finding the proper
    prompt design.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习的可能性是无限的（通常比 Simpy 更有用）– 这只是一个测试和一点耐心来找到适当的提示设计的问题。
- en: As mentioned previously, it is important to remember that these forms of learning
    are different from traditional supervised learning, as well as fine-tuning. In
    few-shot learning, the goal is to enable the model to learn from very few examples,
    and to generalize from those examples to new tasks.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，重要的是要记住，这些学习形式与传统的监督学习以及微调是不同的。在少样本学习中，目标是使模型能够从非常少的示例中学习，并从这些示例中推广到新任务。
- en: Now that we’ve learned how to let ChatGPT learn from examples, let’s focus on
    how to properly define our prompt to make the model’s response as accurate as
    possible.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了让 ChatGPT 从示例中学习，让我们专注于如何正确定义我们的提示，使模型的响应尽可能准确。
- en: Principles of well-defined prompts to obtain relevant and consistent results
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为获得相关和一致结果而定义良好提示的原则
- en: 'Previously, we saw how important prompt designing and engineering are when
    controlling models’ output. Here are some best practices you can use to improve
    your prompts, as well as some practices you should avoid:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在控制模型输出时，我们之前看到了设计和工程化提示的重要性。以下是一些您可以使用的最佳实践来改进您的提示，以及一些应该避免的做法：
- en: '**Clarity**: Use simple sentences and instructions that can easily be understood
    by ChatGPT.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**清晰性**：使用简单的句子和指令，ChatGPT 可以轻松理解。'
- en: '**Conciseness**: Favor short prompts and short sentences. This can be achieved
    by chunking your instructions into smaller sentences with clear intentions.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简洁性**：偏爱简短的提示和简短的句子。通过将指令分成更小的句子并明确表达意图，可以实现这一点。'
- en: '**Focus**: Keep the focus of the prompt on a well-defined topic so that you
    don’t risk your output being too generic.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专注**：将提示的焦点放在一个明确定义的主题上，这样您就不会冒险使输出过于普遍化。'
- en: '**Consistency**: Maintain a consistent tone and language during the conversation
    so that you can ensure a coherent conversation.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性**：在对话过程中保持一致的语气和语言，以确保对话连贯。'
- en: '**“Acting as…”**: The hack of letting ChatGPT act as someone or something has
    proven to be extremely powerful. You can shorten the context you have to provide
    to the model by simply asking him to *act like* the person or system you want
    information from. We’ve already seen the interview-candidate example, where ChatGPT
    acted as an interviewer for a data scientist position. A very interesting prompt
    is that of asking ChatGPT to act as a console. Here is an example of it:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**“充当…”**：让 ChatGPT 充当某人或某物的技巧被证明是非常强大的。您可以通过简单要求他*扮演*您想要获取信息的人或系统，缩短您必须向模型提供的上下文。我们已经看到了面试候选人的例子，ChatGPT
    充当了数据科学家职位的面试官。一个非常有趣的提示是要求 ChatGPT 充当控制台。以下是一个示例：'
- en: '![Figure 4.9 – Example of ChatGPT acting as a Python console](img/Figure_4.9_B19904.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9 – ChatGPT 充当 Python 控制台的例子](img/Figure_4.9_B19904.jpg)'
- en: Figure 4.9 – Example of ChatGPT acting as a Python console
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – ChatGPT 充当 Python 控制台的例子
- en: Note that the console, as it would be if it were real, is also reporting the
    error I made in the `for` cycle, indicating that I was missing the brackets.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，控制台，就像真实的情况一样，也在报告我在`for`循环中犯的错误，指出我遗漏了括号。
- en: 'There is a continuously growing list of *Act as* prompts you can try in the
    following GitHub repository: https://github.com/f/awesome-chatgpt-prompts.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的 GitHub 仓库中，你可以尝试一个不断增长的列表 *Act as* 提示：https://github.com/f/awesome-chatgpt-prompts。
- en: 'Considering the few-shot learning capabilities elaborated on in the previous
    paragraph, there are some good tips for leveraging this feature in prompt designing.
    An ideal conversation is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到前一段中详细阐述的少样本学习能力，有一些很好的提示可以帮助你在设计提示时充分利用这一特性。一个理想的对话如下所示：
- en: 'Start with a concise, clear, and focused prompt. This will help you have an
    overview of the topic you want to discuss, as well as provide food for thought
    and potential expansion of particular elements. Here’s an example:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从简明、清晰、有重点的提示开始。这将帮助你对你想讨论的主题有一个概览，同时为思考和特定元素的潜在扩展提供食粮。以下是一个示例：
- en: '![Figure 4.10 – Example of a clear and focused prompt to initiate a conversation
    with ChatGPT](img/Figure_4.10_B19904.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.10 – 一个清晰、有重点的提示，用于开始和 ChatGPT 的对话](img/Figure_4.10_B19904.jpg)'
- en: Figure 4.10 – Example of a clear and focused prompt to initiate a conversation
    with ChatGPT
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 一个清晰、有重点的提示，用于开始和 ChatGPT 的对话
- en: 'Once you have identified the relevant elements in the discussion, you can ask
    ChatGPT to elaborate on them with much more focus:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你在讨论中确定了相关元素，你可以要求 ChatGPT 更加聚焦地阐述这些元素：
- en: '![Figure 4.11 – Example of a deep-dive follow-up question in a conversation
    with ChatGPT](img/Figure_4.11_B19904.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.11 – 在与 ChatGPT 对话中进行深入追问的示例](img/Figure_4.11_B19904.jpg)'
- en: Figure 4.11 – Example of a deep-dive follow-up question in a conversation with
    ChatGPT
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – 在与 ChatGPT 对话中进行深入追问的示例
- en: 'Sometimes, it might be useful to remember the model and the context in which
    you are inquiring, especially if the question might apply to various domains:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有时候，记得模型和你提问的上下文可能非常有用，尤其是如果问题可能适用于各种领域时。
- en: '![Figure 4.12 – Example of a reminder about the context in a conversation with
    ChatGPT](img/Figure_4.12_B19904.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.12 – 在与 ChatGPT 对话中提醒上下文的示例](img/Figure_4.12_B19904.jpg)'
- en: Figure 4.12 – Example of a reminder about the context in a conversation with
    ChatGPT
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12 – 在与 ChatGPT 对话中提醒上下文的示例
- en: 'Finally, always keep in mind the limitations we mentioned in previous chapters.
    ChatGPT may provide partial or incorrect information, so it is always a good practice
    to double-check. One nice tip you could try is asking the model to provide documentation
    about its responses so that you can easily find proof of them:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，永远记住我们在前几章提到的限制。ChatGPT 可能会提供部分或不正确的信息，所以始终检查是一个很好的做法。你可以尝试的一个好方法是要求模型提供关于其回应的文档，这样你就可以轻松找到它们的证据：
- en: '![Figure 4.13 – Example of ChatGPT providing documentation supporting its previous
    responses](img/Figure_4.13_B19904.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.13 – ChatGPT 提供支持其先前回答的文档的示例](img/Figure_4.13_B19904.jpg)'
- en: Figure 4.13 – Example of ChatGPT providing documentation supporting its previous
    responses
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – ChatGPT 提供支持其先前回答的文档的示例
- en: 'On the other hand, there are some things you should avoid while designing your
    prompt:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在设计提示时，有一些事情是应该避免的：
- en: '**Information overload**: Avoid providing too much information to ChatGPT,
    since it could reduce the accuracy of the response.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息过载**：避免向 ChatGPT 提供过多的信息，因为这可能会降低响应的准确性。'
- en: '**Open-ended questions**: Avoid asking ChatGPT vague, open-ended questions.
    Prompts such as *What can you tell me about the world?* or *Can you help me with
    my exam?* are far too generic and will result in ChatGPT generating vague, useless,
    and sometimes hallucinated responses.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开放式问题**：避免向 ChatGPT 提出模糊、开放式的问题。像“你能告诉我一些关于世界的事情吗？”或“你能帮我复习考试吗？”这样的提示太泛泛了，会导致
    ChatGPT 产生模糊、无用甚至幻觉般的回应。'
- en: '**Lack of constraints**: If you are expecting an output with a specific structure,
    don’t forget to specify that to ChatGPT! If you think about the earlier example
    of ChatGPT acting as an interviewer, you can see how strict I was in specifying
    not to generate questions all at once. It took several tries before getting to
    the result since ChatGPT is thought to generate a continuous flow of text.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏约束**：如果你期望一个特定结构的输出，请不要忘记告诉 ChatGPT！如果你思考一下 ChatGPT 起到面试官的早期示例，你会看到我在明确不要一次性生成所有问题时是多么严格。在得到结果之前尝试了好几次，因为
    ChatGPT 被设计为产生连续的文本流。'
- en: Note
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: As a general consideration, we still have to remember that the knowledge base
    of ChatGPT is limited to 2021, so we should avoid asking questions about facts
    that occurred after that date. You can still provide context; however, all the
    responses will be biased toward the knowledge base before 2021.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一般性考虑，我们仍然必须记住，ChatGPT的知识库仅限于2021年，因此我们应避免询问发生在该日期之后的事实。您仍然可以提供背景信息；然而，所有的回答都会偏向于2021年之前的知识库。
- en: 'Furthermore, it is worth mentioning that in the last few months, a lot of research
    and development has been dedicated to the study of prompt design for **large language
    models** (**LLMs**) (not just **generative pretrained transformer** (**GPT**)),
    because of the extensive use of some specific techniques such as the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，值得一提的是，在过去几个月中，已经有大量的研究和开发致力于对**大型语言模型**（**LLMs**）（不仅仅是**生成式预训练变换器**（**GPT**））的提示设计进行研究，因为一些特定技术的广泛使用，例如以下技术：
- en: '**Chain-of-Thought** (**CoT**): Google researchers Jason Wei et al. have introduced
    a new technique called **CoT prompting** to improve the reasoning abilities of
    LLMs. The method divides intricate problems into smaller, manageable steps, which
    enables language models to solve complex reasoning tasks that cannot be handled
    by conventional promoting approaches.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**思维链**（**CoT**）：Google 研究员魏杰森等人提出了一种名为**CoT提示**的新技术，以提高LLM的推理能力。该方法将复杂问题分解为较小、可管理的步骤，使语言模型能够解决传统提示方法无法处理的复杂推理任务。'
- en: For example, let’s say we want to train a language model to solve a complex
    math problem, such as calculating the value of an algebraic expression. We can
    use CoT prompting to break down the problem into smaller, manageable steps.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想训练一个语言模型来解决一个复杂的数学问题，比如计算代数表达式的值。我们可以使用CoT提示将问题分解为较小、可管理的步骤。
- en: First, we can prompt the model to identify the variables and constants in the
    expression. Then, we can prompt the model to apply the order of operations to
    simplify the expression. Next, we can instruct the model to substitute the numerical
    values of the variables and constants. Finally, we can prompt the model to evaluate
    the expression to obtain the final result.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以提示模型识别表达式中的变量和常数。然后，我们可以提示模型应用运算顺序简化表达式。接下来，我们可以指导模型替换变量和常数的数值。最后，我们可以提示模型评估表达式以获得最终结果。
- en: By using CoT prompting, the language model can learn to solve complex math problems
    that require multi-step reasoning and problem-solving abilities.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用CoT提示，语言模型可以学会解决需要多步推理和解决问题能力的复杂数学问题。
- en: '**Active-Prompt**: Even if prompting with CoT reasoning has been proven effective,
    current CoT methods rely on a fixed set of human-annotated exemplars that may
    not be optimal for different tasks. In their paper, *Active Prompting with Chain-of-Thoughts
    for Large Language Models*, Shizhe Diao et al. propose a new method called **Active-Prompt**,
    which adapts LLMs to different tasks by selecting the most important and helpful
    questions to annotate from a pool of task-specific queries. The following approach
    involves querying the LLM with a few CoT examples and generating *k* possible
    answers for a set of training questions. An uncertainty metric is then calculated
    based on the disagreement among the *k* answers. The most uncertain questions
    are selected for annotation by humans, and the newly annotated exemplars are used
    to infer each question.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主动提示**：即使使用CoT推理提示已被证明有效，当前的CoT方法仍依赖于一组固定的人工注释示例，这些示例可能对不同任务不是最佳的。在他们的论文《使用思维链进行主动提示的大型语言模型》中，刁世哲等人提出了一种名为**主动提示**的新方法，通过从一组特定任务的查询中选择最重要和有帮助的问题来使LLM适应不同任务。以下方法涉及向LLM提出几个CoT示例的查询，并为一组训练问题生成*k*个可能的答案。然后根据*k*个答案之间的分歧计算不确定性度量。最不确定的问题被选中由人类进行注释，并使用新注释的示例来推断每个问题。'
- en: '**Reason and Act** (**ReAct**): This approach is based on human intelligence’s
    ability to seamlessly combine task-oriented actions with verbal reasoning.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理与行动**（**ReAct**）：这种方法基于人类智能无缝结合面向任务的行动和口头推理的能力。'
- en: For example, imagine a person trying to assemble a piece of furniture, such
    as a bookshelf. Between each specific action, the person may reason in language
    to track progress (“*Now that I’ve attached the sides, I need to connect the shelves*”),
    handle exceptions, or adjust the plan according to the situation (“*These screws
    don’t fit, so I need to find a different size*”), and to realize when external
    information is needed (“*I’m not sure which way this piece goes, let me look at
    the instructions*”). The person may also act by referring to the instructions,
    looking for the necessary tools, and positioning the pieces correctly to support
    the reasoning and to answer questions (“*Which screws go where?*”). This tight
    synergy between acting and reasoning enables the person to complete the task efficiently
    and effectively, even if they have never assembled a bookshelf before.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一个人试图组装一件家具，比如一本书架。在每个具体的动作之间，这个人可能会用语言来推理跟踪进度（“*现在我连接上了侧板，我需要连接上架子*”），处理异常情况，或者根据情况调整计划（“*这些螺丝不合适，我需要找到不同尺寸*”），并在需要外部信息时意识到（“*我不确定这个部件应该怎么放，让我看看说明书*”）。这个人还可能通过借助说明书、找到必要的工具，并正确摆放部件来支持推理和回答问题（“*哪些螺丝应该放在哪里？*”）。行动和推理之间的紧密协作使得这个人能够高效而有效地完成任务，即使他们以前从未组装过书架。
- en: 'Well, the ReAct paradigm introduced by Shunyu Yao et al. does exactly the same:
    it prompts LLMs to produce verbal reasoning traces and actions that are relevant
    to the task at hand in a seamlessly interleaved manner. By doing so, the model
    can engage in dynamic reasoning to create, adjust, and maintain high-level plans
    for acting while simultaneously interacting with external sources of information
    (such as Wikipedia) to incorporate additional insights into the reasoning process
    (act to reason). This approach facilitates a more comprehensive and effective
    way of using language models to solve complex problems, enabling them to perform
    both reasoning and acting in an integrated manner.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，姚顺宇等人介绍的ReAct范式正是这样做的：它提示LLMs产生与手头任务相关的口头推理轨迹和行为，以无缝交错的方式。通过这样做，模型可以进行动态推理，为行动创建、调整和维护高级计划，同时与外部信息源（如维基百科）交互，以将附加洞察融入推理过程中（行动用于推理）。这种方法有助于更全面、更有效地利用语言模型解决复杂问题，使其能够以一种集成的方式进行推理和行动。
- en: 'Those are just some of the next few newly developed techniques: since it is
    a new and emerging domain of research, we will probably see an explosion of experimentation
    and papers about prompt design in the coming months.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是一些最新开发的技术的一部分：由于这是一个新兴的研究领域，我们可能会在接下来的几个月看到关于提示设计的大量实验和论文。
- en: Finally, it is important to keep some ethical considerations about ChatGPT responses
    in mind. We will cover these in the next section.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，重要的是要对ChatGPT的回复保持一些伦理考虑。我们将在下一节中介绍这些内容。
- en: Avoiding the risk of hidden bias and taking into account ethical considerations
    in ChatGPT
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免隐藏偏见的风险，并考虑ChatGPT中的伦理问题。
- en: 'ChatGPT has been provided with the Moderator API so that it cannot engage in
    conversations that might be unsafe. The Moderator API is a classification model
    performed by a GPT model based on the following classes: violence, self-harm,
    hate, harassment, and sex. For this, OpenAI uses anonymized data and synthetic
    data (in zero-shot form) to create synthetic data.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT已经使用了Moderator API，因此它不会参与可能不安全的对话。Moderator API 是由基于以下类别的 GPT 模型执行的分类模型：暴力、自残、仇恨、骚扰和性。为此，OpenAI
    使用匿名化数据和合成数据（以零-shot形式）来创建合成数据。
- en: The Moderation API is based on a more sophisticated version of the content filter
    model available among OpenAI APIs. We discussed this model in [*Chapter 1*](B19904_01.xhtml#_idTextAnchor015),
    where we saw how it is very conservative toward false positives rather than false
    negatives.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Moderation API 是基于 OpenAI API 中可用的内容过滤模型的更复杂版本。我们在[*第一章*](B19904_01.xhtml#_idTextAnchor015)中讨论过这个模型，在那里我们看到它对假阳性而不是假阴性非常保守。
- en: However, there is something we can refer to as **hidden bias**, which derives
    directly from the knowledge base the model has been trained on. For example, concerning
    the main chunk of training data of GPT-3, known as the **Common Crawl**, experts
    believe that it was written mainly by white males from Western countries. If this
    is the case, we are already facing a hidden bias of the model, which will inevitably
    mimic a limited and unrepresentative category of human beings.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一些我们可以称之为**隐藏偏见**的东西，它直接源于模型所训练的知识库。例如，关于GPT-3的主要训练数据，即**Common Crawl**，专家认为这主要是由来自西方国家的白人男性编写的。如果是这样，我们已经面临着模型的隐藏偏见，它将不可避免地模仿一类有限和不具代表性的人类。
- en: In their paper, *Languages Models are Few-Shots Learners*, OpenAI’s researchers
    Tom Brown et al. (https://arxiv.org/pdf/2005.1416) created an experimental setup
    to investigate racial bias in GPT-3\. The model was prompted with phrases containing
    racial categories and 800 samples were generated for each category. The sentiment
    of the generated text was measured using Senti WordNet based on word co-occurrences
    on a scale ranging from -100 to 100 (with positive scores indicating positive
    words, and vice versa).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文《语言模型为少样本学习者》中，OpenAI的研究人员汤姆·布朗等（https://arxiv.org/pdf/2005.1416）创建了一个实验设置来调查GPT-3中的种族偏见。模型受到包含种族类别的短语的提示，并为每个类别生成了800个样本。使用Senti
    WordNet根据词共现来衡量生成文本的情感，情感范围从-100到100（正分数表示积极词语，反之亦然）。
- en: 'The results showed that the sentiment associated with each racial category
    varied across different models, with *Asian* consistently having a high sentiment
    and *Black* consistently having a low sentiment. The authors caution that the
    results reflect the experimental setup and that socio-historical factors may influence
    the sentiment associated with different demographics. The study highlights the
    need for a more sophisticated analysis of the relationship between sentiment,
    entities, and input data:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，与不同模型相关的每个种族类别的情绪不同，*亚洲*一直具有很高的情感，而*黑人*一直具有很低的情感。作者警告称，结果反映了实验设置，并且社会历史因素可能影响与不同人口统计数据相关联的情感。研究强调了在情感、实体和输入数据之间关系的更加复杂的分析的需要：
- en: '![Figure 4.14 – Racial sentiment across models](img/Figure_4.14_B19904.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图4.14—模型间的种族情绪](img/Figure_4.14_B19904.jpg)'
- en: Figure 4.14 – Racial sentiment across models
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14—模型间的种族情绪
- en: This hidden bias could generate harmful responses not in line with responsible
    AI principles.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这种隐藏偏见可能产生不符合负责任人工智能原则的有害反应。
- en: However, it is worth noticing how ChatGPT, as well as all OpenAI models, are
    subject to continuous improvements. This is also consistent with OpenAI’s AI **alignment**
    (https://openai.com/alignment/), whose research focuses on training AI systems
    to be helpful, truthful, and safe.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，值得注意的是ChatGPT以及所有OpenAI模型都在不断改进中。这也与OpenAI的AI **alignment**（https://openai.com/alignment/）一致，其研究侧重于训练AI系统成为有益、真实和安全的。
- en: 'For example, if we ask ChatGPT to formulate guesses based on people’s gender
    and race, it will not accommodate the request:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们要求ChatGPT基于人的性别和种族进行猜测，它不会满足这个请求：
- en: '![Figure 4.15 – Example of ChatGPT improving over time since it gives an unbiased
    response](img/Figure_4.15_B19904.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图4.15—ChatGPT随着时间的推移改善的示例，因为它给出了一个不带偏见的回答](img/Figure_4.15_B19904.jpg)'
- en: Figure 4.15 – Example of ChatGPT improving over time since it gives an unbiased
    response
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.15—ChatGPT随着时间的推移改善的示例，因为它给出了一个不带偏见的回答
- en: Overall, despite the continuous improvement in the domain of ethical principles,
    while using ChatGPT, we should always make sure that the output is in line with
    those principles and not biased.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，尽管在道德原则领域不断改进，但在使用ChatGPT时，我们应始终确保输出符合这些原则并且没有偏见。
- en: The concepts of bias and ethics within ChatGPT and OpenAI models have a wider
    collocation within the whole topic of responsible AI, which we are going to focus
    on in the last chapter of this book.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT和OpenAI模型中的偏见和伦理概念在整个负责任人工智能的主题中具有更广泛的搭配，在本书的最后一章中我们将重点关注这一点。
- en: Summary
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we have dived deeper into the concept of prompt design and
    engineering since it’s the most powerful way to control the output of ChatGPT
    and OpenAI models. We learned how to leverage different levels of shot learning
    to make ChatGPT more tailored toward our objectives: if we want the AI response
    to have a particular style and format, we can provide examples so that it can
    learn from them, as we saw when analyzing tweet sentiments. We also learned how
    to write an effective prompt with some nice examples – especially with the *Act
    as...* trick – and what to avoid, such as open-ended questions or information
    overload.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了提示设计和工程的概念，因为这是控制ChatGPT和OpenAI模型输出的最强大方式。我们学会了如何利用不同级别的shot learning，使ChatGPT更加符合我们的目标：如果我们希望AI的回应具有特定的风格和格式，我们可以提供示例让它从中学习，就像我们在分析推文情绪时所看到的那样。我们还学会了如何撰写有效的提示，附有一些不错的例子
    - 尤其是使用*Act as...*技巧 - 以及要避免的内容，比如开放式问题或信息过载。
- en: In the next few chapters, we will cover concrete examples of how ChatGPT can
    boost general users’ daily productivity, with easy prompts and tips you can replicate
    on your own.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几章中，我们将介绍ChatGPT如何提高普通用户的日常生产力的具体示例，提供易于复制的提示和技巧。
- en: Starting from the next chapter, we will dive deeper into different domains where
    ChatGPT can boost productivity and have a disruptive impact on the way we work
    today.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 从下一章开始，我们将深入探讨ChatGPT可以提高生产力并对我们今天的工作方式产生颠覆性影响的不同领域。
- en: References
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
- en: '[https://dl.acm.org/doi/10.1145/3442188.3445922](https://dl.acm.org/doi/10.1145/3442188.3445922)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://dl.acm.org/doi/10.1145/3442188.3445922](https://dl.acm.org/doi/10.1145/3442188.3445922)'
- en: '[https://openai.com/alignment/](https://openai.com/alignment/)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://openai.com/alignment/](https://openai.com/alignment/)'
- en: '[https://twitter.com/spiantado/status/1599462375887114240?ref _src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1599462375     887114240%7Ctwgr%5E1dc908b53fd4be487829472a6bc8590a9dc4aa2d%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fthestoryexchange.org%2F     chatgpt-and-the-hidden-bias-of-language-models%2F](https://twitter.com/spiantado/status/1599462375887114240?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1599462375887114240%7Ctwgr%5E1dc908b53fd4be487829472a6bc8590a9dc4aa2d%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fthestoryexchange.org%2Fchatgpt-and-the-hidden-bias-of-language-models%2F)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://twitter.com/spiantado/status/1599462375887114240?ref _src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1599462375     887114240%7Ctwgr%5E1dc908b53fd4be487829472a6bc8590a9dc4aa2d%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fthestoryexchange.org%2F     chatgpt-and-the-hidden-bias-of-language-models%2F](https://twitter.com/spiantado/status/1599462375887114240?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1599462375887114240%7Ctwgr%5E1dc908b53fd4be487829472a6bc8590a9dc4aa2d%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fthestoryexchange.org%2Fchatgpt-and-the-hidden-bias-of-language-models%2F)'
