# 【第 8 章】

# 【其他顶级 NLP 模型简介】

# 【介绍】

这张表描述了 NLP 领域中一些其他现有的高级模型，探索它们的结构和能力以及技术测试的性能。

| **名称** | **详情** |

| **BERT** | **模型：**该模型代表了 transformer 中输入标记的双向训练和随机屏蔽模型具有大约 24 个 Transformer 块，1024 隐藏，340M 参数，并使用 33 亿字的语料进行训练**性能：**GLUE 基准分数约为 80.4%，比以前最佳结果高出 7.6%；在 SQuAD 1.1 基准测试中的准确率为 93.2%，超过人类解释 2%**能力：**BERT 在构建情感分析工具方面更具优势，并且在使用聊天机器人提供更好的客户体验方面更加高效 |

| **XLnet** | **模型：**该模型代表了 TransformerXL 和 BERT 的核心概念的组合，TransformerXL 的自回归技术和 BERT 的双向性质，以解决两者的局限性**性能：**XLnet 成功地执行了 18 个不同的 NLP 任务，并在 20 个任务上表现优异**能力：**XLnet 在问答、情感分析、优先级排名方面更为出色，类似的对话式业务应用也可以在这里完成 |

| **RoBERTa** | **模型：**该模型的训练数据集比原始 BERT 多了近 10 倍，训练迭代时间更长，训练批次数量也增加到了 8000 字节对编码词汇表中有超过 50k 个子词单元**性能：**在各个方面几乎都超过了 BERT 的预期**能力：**RoBERTa 可以应用于类似的用例，如 BERT 和 XLnet，并具有更好的性能期望 |

| **ALBERT** | **模型：**旨在减少大型 NLP 模型中不必要的长度参数，并打破 NLP 模型构建中的摩尔定律，ALBERT 引入了参数减少机制，如分解嵌入参数化和跨层参数共享**性能：**在不观察到性能显着下降的情况下，ALBERT 通过减少 18 倍的参数和 1.7 倍的更快训练速度解决了模型臃肿的问题在 SQuAD 基准测试中取得了 92.2 的 F1 分数，GLUE 基准测试为 89.4**能力：**ALBERT 可以应用于类似的用例，如 BERT 和 XLnet，并具有更好的性能期望 |

| **PaLM** | **模型：**在这个模型中，大约有 540B 的训练参数，并且在训练阶段利用了两个云 TPU v4 pod 的数据并行化来有效地实现了 57.8%的硬件利用率**性能：**在 29 个主要的 NLP 任务中，它在 28 个任务上超过了许多大型模型。它超越了许多基准任务，如 SuperGLUE，BIG-bench，比其他模型要好得多。尽管需要的 Python 代码训练量少了 50 倍，PaLM 在改进的 Codex 12B 上表现出色，表明大型语言模型在从其他计算机语言和自然语言数据中转移知识方面更有效率**能力：**PaLM 可以用于各种下游活动，包括对话式人工智能、问答、机器翻译、文档分类、广告文案制作、代码问题纠正等。这与其他新宣布的预训练语言模型类似。|

| **MegaTron** | **模型：**该模型具有 5300 亿个参数，105 层，20480 个隐藏维度和 128 个注意力头。在这个模型中，使用了 8 路张量和 35 路管道并行，序列长度为 2048，批量大小为 1920。它是在包含 3390 亿个标记的 15 个数据集上进行训练的。在训练过程中，我们选择根据图 2 中给定的可变采样权重将数据集混合成异质批次，重点放在高质量的数据集上。我们对模型进行了 2700 亿个标记的训练。**性能：**它在 LAMBADA、RACE-h、BoolQ、PiQA、HellaSwag、WinoGrand、ANLI-R2、HANS、WiC 等知名基准测试中表现出色，包括少次、零次和一次测试。它在 Lambada、PiQA、HellaSwag 等方面表现尤为出色，并展现了在最后一个单词预测、问题回答、逻辑推理方面的性能。**能力：**MT 可用于各种下游活动，包括对话 AI、问题回答、机器翻译、文档分类、广告文案制作、代码问题纠正等。这与其他新宣布的预训练语言模型类似。它在数学推理方面也表现出色 |

**表 8.1：** *各种 NLP 模型*

# 加入我们书籍的 Discord 空间

加入书籍的 Discord 工作区，获取最新更新、优惠、世界各地的技术动态、新发布和与作者的交流：

[**https://discord.bpbonline.com**](https://discord.bpbonline.com)

![](images/dis.jpg)
