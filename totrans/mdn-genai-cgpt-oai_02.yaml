- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Introduction to Generative AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能简介
- en: Hello! Welcome to *Modern Generative AI with ChatGPT and OpenAI Models*! In
    this book, we will explore the fascinating world of generative **Artificial Intelligence**
    (**AI**) and its groundbreaking applications. Generative AI has transformed the
    way we interact with machines, enabling computers to create, predict, and learn
    without explicit human instruction. With ChatGPT and OpenAI, we have witnessed
    unprecedented advances in natural language processing, image and video synthesis,
    and many other fields. Whether you are a curious beginner or an experienced practitioner,
    this guide will equip you with the knowledge and skills to navigate the exciting
    landscape of generative AI. So, let’s dive in and start with some definitions
    of the context we are moving in.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你好！欢迎来到*ChatGPT和OpenAI模型的现代生成式人工智能*！在本书中，我们将探索生成式**人工智能**（**AI**）及其开创性应用的迷人世界。生成式人工智能已经改变了我们与机器互动的方式，使计算机能够在没有明确人类指导的情况下创建、预测和学习。通过ChatGPT和OpenAI，我们见证了自然语言处理、图像和视频合成等领域的前所未有的进步。无论您是一个好奇的初学者还是一个经验丰富的从业者，本指南将为您提供了解和掌握生成式人工智能激动人心的领域所需的知识和技能。让我们开始并从我们所处的背景的一些定义开始。
- en: This chapter provides an overview of the field of generative AI, which consists
    of creating new and unique data or content using **machine learning** (**ML**)
    algorithms.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了生成式人工智能领域，该领域利用**机器学习**（**ML**）算法创建新的独特数据或内容。
- en: It focuses on the applications of generative AI to various fields, such as image
    synthesis, text generation, and music composition, highlighting the potential
    of generative AI to revolutionize various industries. This introduction to generative
    AI will provide context for where this technology lives, as well as the knowledge
    to collocate it within the wide world of AI, ML, and **Deep Learning** (**DL**).
    Then, we will dwell on the main areas of applications of generative AI with concrete
    examples and recent developments so that you can get familiar with the impact
    it may have on businesses and society in general.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 它专注于将生成式人工智能应用于各个领域，如图像合成、文本生成和音乐创作，突出了生成式人工智能革新各行业的潜力。这个生成式人工智能的介绍将为您提供这项技术所处的背景，以及将其置于人工智能、机器学习和**深度学习**（**DL**）的广阔世界中的知识。然后，我们将深入探讨生成式人工智能的主要应用领域，提供具体示例和最新发展，以便您熟悉它可能对企业和社会产生的影响。
- en: Also, being aware of the research journey toward the current state of the art
    of generative AI will give you a better understanding of the foundations of recent
    developments and state-of-the-art models.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，了解研究生成式人工智能的当前最新技术发展历程将帮助您更好地理解最近发展和最新模型的基础。
- en: 'All this, we will cover with the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Understanding generative AI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解生成式人工智能
- en: Exploring the domains of generative AI
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索生成式人工智能的领域
- en: The history and current status of research on generative AI
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式人工智能研究的历史和当前状态
- en: By the end of this chapter, you will be familiar with the exciting world of
    generative AI, its applications, the research history behind it, and the current
    developments, which could have – and are currently having – a disruptive impact
    on businesses.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章结束时，您将熟悉生成式人工智能这个激动人心的世界，它的应用、背后的研究历史以及当前的发展，这些发展可能对企业产生影响，目前也正在产生影响。
- en: Introducing generative AI
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍生成式人工智能
- en: AI has been making significant strides in recent years, and one of the areas
    that has seen considerable growth is generative AI. Generative AI is a subfield
    of AI and DL that focuses on generating new content, such as images, text, music,
    and video, by using algorithms and models that have been trained on existing data
    using ML techniques.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: AI在近年来取得了显著进展，其中一个发展迅速的领域是生成式人工智能。生成式人工智能是人工智能和深度学习的一个子领域，专注于利用机器学习技术在现有数据上训练的算法和模型生成新内容，如图像、文本、音乐和视频。
- en: 'In order to better understand the relationship between AI, ML, DL, and generative
    AI, consider AI as the foundation, while ML, DL, and generative AI represent increasingly
    specialized and focused areas of study and application:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解人工智能、机器学习、深度学习和生成式人工智能之间的关系，请将人工智能视为基础，而机器学习、深度学习和生成式人工智能代表着越来越专业化和专注的研究和应用领域：
- en: AI represents the broad field of creating systems that can perform tasks, showing
    human intelligence and ability and being able to interact with the ecosystem.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能代表着创造能够执行任务、展示人类智能和能力并能够与生态系统互动的系统的广泛领域。
- en: ML is a branch that focuses on creating algorithms and models that enable those
    systems to learn and improve themselves with time and training. ML models learn
    from existing data and automatically update their parameters as they *grow*.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是一个专注于创建算法和模型的分支，使这些系统能够通过时间和训练学习和改进自己。机器学习模型从现有数据中学习，并在其*成长*过程中自动更新其参数。
- en: DL is a sub-branch of ML, in the sense that it encompasses deep ML models. Those
    deep models are called **neural networks** and are particularly suitable in domains
    such as **computer vision** or **Natural Language Processing** (**NLP**). When
    we talk about ML and DL models, we typically refer to discriminative models, whose
    aim is that of making predictions or inferencing patterns on top of data.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习（DL）是机器学习（ML）的一个子分支，因为它包含深度学习模型。这些深度模型被称为**神经网络**，特别适用于**计算机视觉**或**自然语言处理**（**NLP**）等领域。当我们谈论机器学习和深度学习模型时，我们通常指的是判别模型，其目的是在数据之上进行预测或推断模式。
- en: 'And finally, we get to generative AI, a further sub-branch of DL, which doesn’t
    use deep Neural Networks to cluster, classify, or make predictions on existing
    data: it uses those powerful Neural Network models to generate brand new content,
    from images to natural language, from music to video.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们来到生成式人工智能，这是深度学习的进一步子���支，它不使用深度神经网络来对现有数据进行聚类、分类或预测：它使用这些强大的神经网络模型来生成全新的内容，从图像到自然语言，从音乐到视频。
- en: 'The following figure shows how these areas of research are related to each
    other:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了这些研究领域之间的关系：
- en: '![Figure 1.1 – Relationship between AI, ML, DL, and generative AI](img/Figure_1.1_B19904.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 – 人工智能、机器学习、深度学习和生成式人工智能之间的关系](img/Figure_1.1_B19904.jpg)'
- en: Figure 1.1 – Relationship between AI, ML, DL, and generative AI
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 人工智能、机器学习、深度学习和生成式人工智能之间的关系
- en: Generative AI models can be trained on vast amounts of data and then they can
    generate new examples from scratch using patterns in that data. This generative
    process is different from discriminative models, which are trained to predict
    the class or label of a given example.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能模型可以在大量数据上进行训练，然后可以使用该数据中的模式从头开始生成新的示例。这种生成过程与判别模型不同，后者被训练用于预测给定示例的类别或标签。
- en: Domains of generative AI
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式人工智能领域
- en: In recent years, generative AI has made significant advancements and has expanded
    its applications to a wide range of domains, such as art, music, fashion, architecture,
    and many more. In some of them, it is indeed transforming the way we create, design,
    and understand the world around us. In others, it is improving and making existing
    processes and operations more efficient.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，生成式人工智能取得了重大进展，并将其应用扩展到了各种领域，如艺术、音乐、时尚、建筑等等。在其中一些领域，它确实正在改变我们创造、设计和理解周围世界的方式。在其他领域，它正在改进并使现有的流程和操作更加高效。
- en: The fact that generative AI is used in many domains also implies that its models
    can deal with different kinds of data, from natural language to audio or images.
    Let us understand how generative AI models address different types of data and
    domains.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能应用于许多领域的事实也意味着其模型可以处理不同类型的数据，从自然语言到音频或图像。让我们了解生成式人工智能模型如何处理不同类型的数据和领域。
- en: Text generation
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本生成
- en: One of the greatest applications of generative AI—and the one we are going to
    cover the most throughout this book—is its capability to produce new content in
    natural language. Indeed, generative AI algorithms can be used to generate new
    text, such as articles, poetry, and product descriptions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能（generative AI）最伟大的应用之一——也是我们在本书中将要重点介绍的——是其能够以自然语言生成新内容的能力。事实上，生成式人工智能算法可以用于生成新的文本，如文章、诗歌和产品描述。
- en: For example, a language model such as GPT-3, developed by OpenAI, can be trained
    on large amounts of text data and then used to generate new, coherent, and grammatically
    correct text in different languages (both in terms of input and output), as well
    as extracting relevant features from text such as keywords, topics, or full summaries.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，OpenAI开发的GPT-3等语言模型可以在大量文本数据上进行训练，然后用于生成新的、连贯且语法正确的文本，包括不同语言（输入和输出），以及从文本中提取关键词、主题或完整摘要等相关特征。
- en: 'Here is an example of working with GPT-3:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个使用GPT-3的示例：
- en: '![Figure 1.2 – Example of ChatGPT responding to a user prompt, also adding
    references](img/Figure_1.2_B19904.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2 – ChatGPT响应用户提示的示例，并添加参考资料](img/Figure_1.2_B19904.jpg)'
- en: Figure 1.2 – Example of ChatGPT responding to a user prompt, also adding references
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – ChatGPT响应用户提示的示例，并添加参考资料
- en: Next, we will move on to image generation.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将继续讨论图像生成。
- en: Image generation
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像生成
- en: One of the earliest and most well-known examples of generative AI in image synthesis
    is the **Generative Adversarial Network** (**GAN**) architecture introduced in
    the 2014 paper by I. Goodfellow et al., *Generative Adversarial Networks*. The
    purpose of GANs is to generate realistic images that are indistinguishable from
    real images. This capability had several interesting business applications, such
    as generating synthetic datasets for training computer vision models, generating
    realistic product images, and generating realistic images for virtual reality
    and augmented reality applications.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像合成中，最早且最知名的生成式AI示例之一是2014年I. Goodfellow等人发表的论文中介绍的**生成对抗网络**（**GAN**）架构，*生成对抗网络*。GAN的目的是生成与真实图像难以区分的逼真图像。这种能力有一些有趣的商业应用，如为训练计算机视觉模型生成合成数据集，生成逼真的产品图像，以及为虚拟现实和增强现实应用生成逼真图像。
- en: 'Here is an example of faces of people who do not exist since they are entirely
    generated by AI:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些由AI完全生成的不存在的人脸的例子：
- en: '![Figure 1.3 – Imaginary faces generated by GAN StyleGAN2 at https://this-person-does-not-exist.com/en](img/Figure_1.3_B19904.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3 – GAN StyleGAN2生成的虚构面孔，网址为https://this-person-does-not-exist.com/en](img/Figure_1.3_B19904.jpg)'
- en: Figure 1.3 – Imaginary faces generated by GAN StyleGAN2 at https://this-person-does-not-exist.com/en
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – GAN StyleGAN2生成的虚构面孔，网址为https://this-person-does-not-exist.com/en
- en: Then, in 2021, a new generative AI model was introduced in this field by OpenAI,
    **DALL-E**. Different from GANs, the DALL-E model is designed to generate images
    from descriptions in natural language (GANs take a random noise vector as input)
    and can generate a wide range of images, which may not look realistic but still
    depict the desired concepts.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在2021年，OpenAI在这一领域推出了一种新的生成式AI模型，**DALL-E**。与GAN不同，DALL-E模型旨在根据自然语言描述生成图像（GAN以随机噪声向量作为输入），可以生成各种图像，这些图像可能看起来不太真实，但仍描绘出所需的概念。
- en: DALL-E has great potential in creative industries such as advertising, product
    design, and fashion, among others, to create unique and creative images.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E在广告、产品设计、时尚等创意产业中具有巨大潜力，可以创造独特和创意的图像。
- en: 'Here, you can see an example of DALL-E generating four images starting from
    a request in natural language:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到DALL-E生成四幅图像的例子，从一个自然语言请求开始：
- en: '![Figure 1.4 – Images generated by DALL-E with a natural language prompt as
    input](img/Figure_1.4_B19904.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4 – DALL-E生成的图像，以自然语言提示作为输入](img/Figure_1.4_B19904.jpg)'
- en: Figure 1.4 – Images generated by DALL-E with a natural language prompt as input
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – DALL-E生成的图像，以自然语言提示作为输入
- en: Note that text and image generation can be combined to produce brand new materials.
    In recent years, widespread new AI tools have used this combination.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，文本和图像生成可以结合起来产生全新的材料。近年来，广泛使用这种组合的新AI工具已经出现。
- en: An example is Tome AI, a generative storytelling format that, among its capabilities,
    is also able to create slide shows from scratch, leveraging models such as DALL-E
    and GPT-3.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是Tome AI，一种生成式叙事格式，除了其能力外，还能从头开始创建幻灯片，利用诸如DALL-E和GPT-3的模型。
- en: '![Figure 1.5 – A presentation about generative AI entirely generated by Tome,
    using an input in natural language](img/Figure_1.5_B19904.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5 – 一份关于生成式AI的演示，完全由Tome生成，使用自然语言输入](img/Figure_1.5_B19904.jpg)'
- en: Figure 1.5 – A presentation about generative AI entirely generated by Tome,
    using an input in natural language
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 一份关于生成式AI的演示，完全由Tome生成，使用自然语言输入
- en: As you can see, the preceding AI tool was perfectly able to create a draft presentation
    just based on my short input in natural language.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，前述的AI工具完全能够根据我在自然语言中的简短输入创建一份草稿演示。
- en: Music generation
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音乐生成
- en: The first approaches to generative AI for music generation trace back to the
    50s, with research in the field of algorithmic composition, a technique that uses
    algorithms to generate musical compositions. In fact, in 1957, Lejaren Hiller
    and Leonard Isaacson created the Illiac Suite for String Quartet ([https://www.youtube.com/watch?v=n0njBFLQSk8](https://www.youtube.com/watch?v=n0njBFLQSk8)),
    the first piece of music entirely composed by AI. Since then, the field of generative
    AI for music has been the subject of ongoing research for several decades. Among
    recent years’ developments, new architectures and frameworks have become widespread
    among the general public, such as the WaveNet architecture introduced by Google
    in 2016, which has been able to generate high-quality audio samples, or the Magenta
    project, also developed by Google, which uses **Recurrent Neural Networks** (**RNNs**)
    and other ML techniques to generate music and other forms of art. Then, in 2020,
    OpenAI also announced Jukebox, a neural network that generates music, with the
    possibility to customize the output in terms of musical and vocal style, genre,
    reference artist, and so on.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 生成音乐的生成式人工智能的最初方法可以追溯到50年代，在算法作曲领域的研究中，这种技术使用算法生成音乐作品。事实上，1957年，Lejaren Hiller和Leonard
    Isaacson创作了《Illiac Suite for String Quartet》([https://www.youtube.com/watch?v=n0njBFLQSk8](https://www.youtube.com/watch?v=n0njBFLQSk8))，这是由AI完全创作的第一首音乐作品。从那时起，生成音乐的生成式人工智能领域一直是持续研究的课题。在近年的发展中，新的架构和框架已经在普通大众中广泛传播，例如谷歌在2016年推出的WaveNet架构，能够生成高质量的音频样本，或者由谷歌开发的Magenta项目，该项目使用**循环神经网络**（**RNNs**）和其他机器学习技术来生成音乐和其他形式的艺术。然后，在2020年，OpenAI还宣布了Jukebox，这是一个能够生成音乐的神经网络，可以根据音乐和声音风格、流派、参考艺术家等进行输出定制。
- en: Those and other frameworks became the foundations of many AI composer assistants
    for music generation. An example is Flow Machines, developed by Sony CSL Research.
    This generative AI system was trained on a large database of musical pieces to
    create new music in a variety of styles. It was used by French composer Benoît
    Carré to compose an album called *Hello World* ([https://www.helloworldalbum.net/](https://www.helloworldalbum.net/)),
    which features collaborations with several human musicians.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这些以及其他框架成为许多生成音乐AI作曲助手的基础。一个例子是由索尼CSL研究开发的Flow Machines。这个生成式人工智能系统在大量音乐作品数据库上进行训练，以在各种风格中创作新音乐。法国作曲家Benoît
    Carré使用它创作了一张名为*Hello World*的专辑([https://www.helloworldalbum.net/](https://www.helloworldalbum.net/))，其中与几位人类音乐家合作。
- en: 'Here, you can see an example of a track generated entirely by Music Transformer,
    one of the models within the Magenta project:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到一个完全由Magenta项目中的Music Transformer模型生成的曲目的示例：
- en: '![Figure 1.6 – Music Transformer allows users to listen to musical performances
    generated by AI](img/Figure_1.6_B19904.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图1.6 – Music Transformer允许用户听取由AI生成的音乐表演](img/Figure_1.6_B19904.jpg)'
- en: Figure 1.6 – Music Transformer allows users to listen to musical performances
    generated by AI
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 – Music Transformer允许用户听取由AI生成的音乐表演
- en: Another incredible application of generative AI within the music domain is speech
    synthesis. It is indeed possible to find many AI tools that can create audio based
    on text inputs in the voices of well-known singers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个音乐领域内生成式人工智能的令人难以置信的应用是语音合成。事实上，可以找到许多能够根据文本输入以知名歌手的声音创建音频的AI工具。
- en: For example, if you have always wondered how your songs would sound if Kanye
    West performed them, well, you can now fulfill your dreams with tools such as
    FakeYou.com ([https://fakeyou.com/](https://fakeyou.com/)), Deep Fake Text to
    Speech, or UberDuck.ai ([https://uberduck.ai/](https://uberduck.ai/)).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你一直想知道如果Kanye West演唱你的歌曲会是什么样子，那么现在你可以通过诸如FakeYou.com ([https://fakeyou.com/](https://fakeyou.com/))、Deep
    Fake Text to Speech或UberDuck.ai ([https://uberduck.ai/](https://uberduck.ai/))等工具实现你的梦想。
- en: '![Figure 1.7 – Text-to-speech synthesis with UberDuck.ai](img/Figure_1.7_B19904.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图1.7 – 使用UberDuck.ai进行文本转语音合成](img/Figure_1.7_B19904.jpg)'
- en: Figure 1.7 – Text-to-speech synthesis with UberDuck.ai
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 – 使用UberDuck.ai进行文本转语音合成
- en: I have to say, the result is really impressive. If you want to have fun, you
    can also try voices from your all your favorite cartoons as well, such as Winnie
    The Pooh...
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须说，结果真的令人印象深刻。如果你想玩得开心，你也可以尝试你所有最喜爱的卡通人物的声音，比如小熊维尼...
- en: Next, we move to see generative AI for videos.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看到用于视频的生成式人工智能。
- en: Video generation
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频生成
- en: Generative AI for video generation shares a similar timeline of development
    with image generation. In fact, one of the key developments in the field of video
    generation has been the development of GANs. Thanks to their accuracy in producing
    realistic images, researchers have started to apply these techniques to video
    generation as well. One of the most notable examples of GAN-based video generation
    is DeepMind’s **Motion to Video**, which generated high-quality videos from a
    single image and a sequence of motions. Another great example is NVIDIA’s **Video-to-Video
    Synthesis** (**Vid2Vid**) DL-based framework, which uses GANs to synthesize high-quality
    videos from input videos.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 视频生成的生成式人工智能与图像生成有着类似的发展时间线。事实上，在视频生成领域的关键发展之一就是GANs的发展。由于它们在生成逼真图像方面的准确性，研究人员开始将这些技术应用于视频生成。基于GAN的视频生成的最显著例子之一是DeepMind的**Motion
    to Video**，它可以从单个图像和一系列动作生成高质量的视频。另一个很好的例子是NVIDIA的**Video-to-Video Synthesis**（**Vid2Vid**）DL框架，它使用GANs从输入视频中合成高质量的视频。
- en: 'The Vid2Vid system can generate temporally consistent videos, meaning that
    they maintain smooth and realistic motion over time. The technology can be used
    to perform a variety of video synthesis tasks, such as the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Vid2Vid系统可以生成时间上连贯的视频，这意味着它们在时间上保持平滑和逼真的运动。这项技术可以用于执行各种视频合成任务，例如：
- en: Converting videos from one domain into another (for example, converting a daytime
    video into a nighttime video or a sketch into a realistic image)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个领域的视频转换为另一个领域（例如，将白天视频转换为夜晚视频或将素描转换为逼真图像）
- en: Modifying existing videos (for example, changing the style or appearance of
    objects in a video)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改现有视频（例如，更改视频中物体的风格或外观）
- en: Creating new videos from static images (for example, animating a sequence of
    still images)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从静态图像创建新视频（例如，将一系列静止图像制作成动画）
- en: In September 2022, Meta’s researchers announced the general availability of
    **Make-A-Video** ([https://makeavideo.studio/](https://makeavideo.studio/)), a
    new AI system that allows users to convert their natural language prompts into
    video clips. Behind such technology, you can recognize many of the models we mentioned
    for other domains so far – language understanding for the prompt, image and motion
    generation with image generation, and background music made by AI composers.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年9月，Meta的研究人员宣布了**Make-A-Video**（[https://makeavideo.studio/](https://makeavideo.studio/)）的普遍可用性，这是一个新的人工智能系统，允许用户将他们的自然语言提示转换为视频片段。在这样的技术背后，你可以认出我们迄今为止提到的许多其他领域的模型
    - 用于提示的语言理解，图像和运动生成与图像生成，以及由AI作曲家制作的背景音乐。
- en: Overall, generative AI has impacted many domains for years, and some AI tools
    already consistently support artists, organizations, and general users. The future
    seems very promising; however, before jumping to the ultimate models available
    on the market today, we first need to have a deeper understanding of the roots
    of generative AI, its research history, and the recent developments that eventually
    lead to the current OpenAI models.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，生成式人工智能多年来已经影响了许多领域，并且一些人工智能工具已经持续支持艺术家、组织和一般用户。未来看起来非常有前途；然而，在跳入当今市场上最终模型之前，我们首先需要更深入地了解生成式人工智能的根源、其研究历史以及最终导致当前OpenAI模型的最新发展。
- en: The history and current status of research
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 研究的历史和当前状态
- en: In previous sections, we had an overview of the most recent and cutting-edge
    technologies in the field of generative AI, all developed in recent years. However,
    the research in this field can be traced back decades ago.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几节中，我们概述了生成式人工智能领域中最新和尖端的技术，这些技术都是近年来开发的。然而，这一领域的研究可以追溯到几十年前。
- en: We can mark the beginning of research in the field of generative AI in the 1960s,
    when Joseph Weizenbaum developed the chatbot ELIZA, one of the first examples
    of an NLP system. It was a simple rules-based interaction system aimed at entertaining
    users with responses based on text input, and it paved the way for further developments
    in both NLP and generative AI. However, we know that modern generative AI is a
    subfield of DL and, although the first **Artificial Neural Networks** (**ANNs**)
    were first introduced in the 1940s, researchers faced several challenges, including
    limited computing power and a lack of understanding of the biological basis of
    the brain. As a result, ANNs hadn’t gained much attention until the 1980s when,
    in addition to new hardware and neuroscience developments, the advent of the **backpropagation**
    algorithm facilitated the training phase of ANNs. Indeed, before the advent of
    backpropagation, training Neural Networks was difficult because it was not possible
    to efficiently calculate the gradient of the error with respect to the parameters
    or weights associated with each neuron, while backpropagation made it possible
    to automate the training process and enabled the application of ANNs.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将生成AI领域的研究始于20世纪60年代，当时Joseph Weizenbaum开发了聊天机器人ELIZA，这是NLP系统的最早例子之一。它是一个简单的基于规则的交互系统，旨在通过基于文本输入的响应来娱乐用户，并为NLP和生成AI的进一步发展铺平了道路。然而，我们知道现代生成AI是DL的一个子领域，尽管最早的**人工神经网络**（**ANNs**）最早是在20世纪40年代引入的，研究人员面临着一些挑战，包括有限的计算能力和对大脑生物学基础的理解不足。因此，直到20世纪80年代，随着新硬件和神经科学的发展，**反向传播**算法的出现促进了ANNs的训练阶段。事实上，在反向传播算法出现之前，训练神经网络是困难的，因为无法有效地计算与每个神经元相关的参数或权重的误差梯度，而反向传播使得自动化训练过程成为可能，并实现了ANNs的应用。
- en: Then, by the 2000s and 2010s, the advancement in computational capabilities,
    together with the huge amount of available data for training, yielded the possibility
    of making DL more practical and available to the general public, with a consequent
    boost in research.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，到了21世纪初和2010年代，计算能力的进步，加上大量可用于训练的数据，使得DL更加实用和普及，随之而来的是研究的提升。
- en: In 2013, Kingma and Welling introduced a new model architecture in their paper
    *Auto-Encoding Variational Bayes*, called **Variational Autoencoders** (**VAEs**).
    VAEs are generative models that are based on the concept of variational inference.
    They provide a way of learning with a compact representation of data by encoding
    it into a lower-dimensional space called **latent space** (with the *encoder*
    component) and then decoding it back into the original data space (with the *decoder*
    component).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 2013年，Kingma和Welling在他们的论文*自动编码变分贝叶斯*中引入了一种新的模型架构，称为**变分自编码器**（**VAEs**）。VAEs是基于变分推断概念的生成模型。它们通过将数据编码为称为**潜在空间**（具有*编码器*组件）的低维空间，然后将其解码回原始数据空间（具有*解码器*组件）的方式提供了一种学习的方法。
- en: The key innovation of VAEs is the introduction of a probabilistic interpretation
    of the latent space. Instead of learning a deterministic mapping of the input
    to the latent space, the encoder maps the input to a probability distribution
    over the latent space. This allows VAEs to generate new samples by sampling from
    the latent space and decoding the samples into the input space.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: VAE的关键创新在于引入了潜在空间的概率解释。与学习输入到潜在空间的确定性映射不同，编码器将输入映射到潜在空间上的概率分布。这使得VAE能够通过从潜在空间中采样并将样本解码到输入空间中来生成新样本。
- en: For example, let’s say we want to train a VAE that can create new pictures of
    cats and dogs that look like they could be real.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，假设我们想训练一个VAE，它可以生成看起来像真实的猫和狗的新图片。
- en: To do this, the VAE first takes in a picture of a cat or a dog and compresses
    it down into a smaller set of numbers into the latent space, which represent the
    most important features of the picture. These numbers are called **latent variables**.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，VAE首先接收一张猫或狗的图片，并将其压缩成一组较小的数字进入潜在空间，这些数字代表图片的最重要特征。这些数字被称为**潜在变量**。
- en: Then, the VAE takes these latent variables and uses them to create a new picture
    that looks like it could be a real cat or dog picture. This new picture may have
    some differences from the original pictures, but it should still look like it
    belongs in the same group of pictures.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，VAE获取这些潜在变量，并使用它们创建一幅看起来像真实猫或狗图片的新图片。这幅新图片可能与原始图片有些差异，但它应该看起来像属于同一组图片。
- en: The VAE gets better at creating realistic pictures over time by comparing its
    generated pictures to the real pictures and adjusting its latent variables to
    make the generated pictures look more like the real ones.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，通过将生成的图片与真实图片进行比较并调整其潜在变量使生成的图片看起来更像真实图片，VAE变得更擅长创建逼真的图片。
- en: VAEs paved the way toward fast development within the field of generative AI.
    In fact, only 1 year later, GANs were introduced by Ian Goodfellow. Differently
    from VAEs architecture, whose main elements are the encoder and the decoder, GANs
    consist of two Neural Networks – a generator and a discriminator – which work
    against each other in a zero-sum game.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: VAE为生成式人工智能领域的快速发展铺平了道路。事实上，仅仅1年后，Ian Goodfellow提出了GAN。与VAE架构不同，GAN由两个神经网络组成
    - 生成器和判别器 - 它们在一个零和博弈中相互对抗。
- en: The generator creates fake data (in the case of images, it creates a new image)
    that is meant to look like real data (for example, an image of a cat). The discriminator
    takes in both real and fake data, and tries to distinguish between them – it’s
    the *critic* in our art forger example.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器创建假数据（在图像的情况下，它创建一幅新图像），旨在看起来像真实数据（例如，一幅猫的图像）。判别器接收真实数据和假数据，并试图区分它们 - 在我们的艺术赝品制作者示例中，它是*评论家*。
- en: During training, the generator tries to create data that can fool the discriminator
    into thinking it’s real, while the discriminator tries to become better at distinguishing
    between real and fake data. The two parts are trained together in a process called
    **adversarial training**.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，生成器试图创建可以欺骗判别器认为它是真实的数据，而判别器则试图变得更擅长区分真实数据和假数据。这两部分一起进行训练，这个过程称为**对抗训练**。
- en: Over time, the generator gets better at creating fake data that looks like real
    data, while the discriminator gets better at distinguishing between real and fake
    data. Eventually, the generator becomes so good at creating fake data that even
    the discriminator can’t tell the difference between real and fake data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，生成器变得更擅长创建看起来像真实数据的假数据，而判别器则变得更擅长区分真实数据和假数据。最终，生成器变得如此擅长创建假数据，以至于连判别器也无法区分真假数据。
- en: 'Here is an example of human faces entirely generated by a GAN:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是GAN完全生成的人脸的一个例子：
- en: '![Figure 1.8 – Examples of photorealistic GAN-generated faces (taken from Progressive
    Growing of GANs for Improved Quality, Stability, and Variation, 2017:  https://arxiv.org/pdf/1710.10196.pdf)](img/Figure_1.8_B19904.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图1.8 - 逼真的GAN生成的人脸示例（摘自2017年《逐步增长的GAN用于提高质量、稳定性和变化性》：https://arxiv.org/pdf/1710.10196.pdf)](img/Figure_1.8_B19904.jpg)'
- en: 'Figure 1.8 – Examples of photorealistic GAN-generated faces (taken from Progressive
    Growing of GANs for Improved Quality, Stability, and Variation, 2017: https://arxiv.org/pdf/1710.10196.pdf)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 - 逼真的GAN生成的人脸示例（摘自2017年《逐步增长的GAN用于提高质量、稳定性和变化性》：https://arxiv.org/pdf/1710.10196.pdf）
- en: Both models – VAEs and GANs – are meant to generate brand new data that is indistinguishable
    from original samples, and their architecture has improved since their conception,
    side by side with the development of new models such as PixelCNNs, proposed by
    Van den Oord and his team, and WaveNet, developed by Google DeepMind, leading
    to advances in audio and speech generation.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: VAE和GAN这两种模型旨在生成与原始样本无法区分的全新数据，并且它们的架构自提出以来已经得到改进，与Van den Oord及其团队提出的PixelCNNs和由Google
    DeepMind开发的WaveNet等新模型的发展并行，推动了音频和语音生成的进步。
- en: Another great milestone was achieved in 2017 when a new architecture, called
    *Transformer*, was introduced by Google researchers in the paper, *– Attention
    Is All You Need*, was introduced in a paper by Google researchers. It was revolutionary
    in the field of language generation since it allowed for parallel processing while
    retaining memory about the context of language, outperforming the previous attempts
    of language models founded on RNNs or **Long Short-Term Memory** (**LSTM**) frameworks.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年另一个重要的里程碑是谷歌研究人员在一篇名为*– Attention Is All You Need*的论文中引入了一种名为*Transformer*的新架构。这在语言生成领域具有革命性意义，因为它允许并行处理同时保留有关语言上下文的记忆，超越了以RNN或**长短期记忆**（**LSTM**）框架为基础的语言模型的先前尝试。
- en: Transformers were indeed the foundations for massive language models called
    **Bidirectional Encoder Representations from Transformers** (**BERT**), introduced
    by Google in 2018, and they soon become the baseline in NLP experiments.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器确实是谷歌于2018年推出的名为**双向编码器表示来自变压器**（**BERT**）的大规模语言模型的基础，并很快成为自然语言处理实验的基准。
- en: Transformers are also the foundations of all the **Generative Pre-Trained**
    (**GPT**) models introduced by OpenAI, including GPT-3, the model behind ChatGPT.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器也是由OpenAI推出的所有**生成式预训练**（**GPT**）模型的基础，包括ChatGPT背后的GPT-3模型。
- en: Although there was a significant amount of research and achievements in those
    years, it was not until the second half of 2022 that the general attention of
    the public shifted toward the field of generative AI.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在那些年里有大量的研究和成就，但直到2022年下半年，公众的注意力才开始转向生成式人工智能领域。
- en: 'Not by chance, 2022 has been dubbed the *year of generative AI*. This was the
    year when powerful AI models and tools became widespread among the general public:
    diffusion-based image services (MidJourney, DALL-E 2, and Stable Diffusion), OpenAI’s
    ChatGPT, text-to-video (Make-a-Video and Imagen Video), and text-to-3D (DreamFusion,
    Magic3D, and Get3D) tools were all made available to individual users, sometimes
    also for free.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 不是偶然的，2022年被誉为*生成式人工智能之年*。这一年，强大的人工智能模型和工具开始在普通大众中广泛传播：基于扩散的图像服务（MidJourney、DALL-E
    2和Stable Diffusion）、OpenAI的ChatGPT、文本到视频（Make-a-Video和Imagen Video）以及文本到3D（DreamFusion、Magic3D和Get3D）工具都向个人用户提供，有时还是免费的。
- en: 'This had a disruptive impact for two main reasons:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这对两个主要原因产生了颠覆性影响：
- en: Once generative AI models have been widespread to the public, every individual
    user or organization had the possibility to experiment with and appreciate its
    potential, even without being a data scientist or ML engineer.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦生成式人工智能模型普及到公众，每个个人用户或组织都有可能尝试并欣赏其潜力，即使不是数据科学家或机器学习工程师。
- en: The output of those new models and their embedded creativity were objectively
    stunning and often concerning. An urgent call for adaptation—both for individuals
    and governments—rose.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些新模型的输出及其内在的创造力在客观上令人惊叹，而且常常令人担忧。对于个人和政府来说，迫切需要适应。
- en: Henceforth, in the very near future, we will probably witness a spike in the
    adoption of AI systems for both individual usage and enterprise-level projects.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在不久的将来，我们可能会目睹人工智能系统在个人使用和企业级项目中的采用率激增。
- en: Summary
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored the exciting world of generative AI and its various
    domains of application, including image generation, text generation, music generation,
    and video generation. We learned how generative AI models such as ChatGPT and
    DALL-E, trained by OpenAI, use DL techniques to learn patterns in large datasets
    and generate new content that is both novel and coherent. We also discussed the
    history of generative AI, its origins, and the current status of research on it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了生成式人工智能及其各种应用领域，包括图像生成、文本生成、音乐生成和视频生成的令人兴奋的世界。我们了解到OpenAI训练的ChatGPT和DALL-E等生成式人工智能模型如何使用深度学习技术学习大型数据集中的模式，并生成既新颖又连贯的新内容。我们还讨论了生成式人工智能的历史、起源以及当前的研究现状。
- en: The goal of this chapter was to provide a solid foundation in the basics of
    generative AI and to inspire you to explore this fascinating field further.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是为生成式人工智能的基础知识提供坚实的基础，并激励您进一步探索这个迷人的领域。
- en: 'In the next chapter, we will focus on one of the most promising technologies
    available on the market today, ChatGPT: we will go through the research behind
    it and its development by OpenAI, the architecture of its model, and the main
    use cases it can address as of today.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.youtube.com/watch?v=Iy9vRvyRf_E](https://www.youtube.com/watch?v=Iy9vRvyRf_E)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://arxiv.org/abs/1912.04958](https://arxiv.org/abs/1912.04958)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*This person does not exist*: [this-person-does-not-exist.com](http://this-person-does-not-exist.com)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://arxiv.org/abs/1808.06601](https://arxiv.org/abs/1808.06601)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.microsoft.com/en-us/research/blog/a-deep-generative-model-trifecta-three-advances-that-work-towards-harnessing-large-scale-power/](https://www.microsoft.com/en-us/research/blog/a-deep-generative-model-trifecta-three-advances-that-work-towards-harnessing-large-scale-power/)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://tcwang0509.github.io/vid2vid/](https://tcwang0509.github.io/vid2vid/)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
