- en: 'AI MODELSArtificial intelligence is the human intelligence displayed by machines
    as carriers, also called machine intelligence (Machine Intelligence). The simulation
    of human intelligence can be achieved through logical reasoning centered on symbolism,
    inquiry, and search centered on problem-solving, machine learning centered on
    data-driven, reinforcement learning centered on behaviorism, and decision-making
    centered on game confrontation. Intelligent and other methods to achieve.This
    course systematically introduces the basic concepts and algorithms of artificial
    intelligence, which can help learners master the context of artificial intelligence,
    experience the power, enablement, and empowerment, and "know its meaning, understand
    its reason, Follow the rules and follow the rules." The course content includes
    the following: an overview of artificial intelligence, search, and solution, logic
    and reasoning, supervised learning, unsupervised learning, deep learning, reinforcement
    learning, and game confrontation.Those who come but do not lose their time; those
    who walk but do not lose are opportunities. Artificial intelligence is not simply
    a course, first-hand technology, a product, or an application, but a comprehensive
    ecosystem (AI ecosystem) with profound theory, vibrant technology, traction of
    product landing, and application empowerment of society. To strengthen the practical
    training, the course arranges useful training topics such as the Reversi AI algorithm
    with search and solution as the core, image restoration with linear regression
    as the core, and garbage classification with deep learning as the core.AI MODELS
    INCLUDE:'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型人工智能是机器作为载体展示的人类智能，也称为机器智能（Machine Intelligence）。通过以符号为中心的逻辑推理、以问题解决为中心的探究和搜索、以数据驱动为中心的机器学习、以行为主义为中心的强化学习以及以博弈对抗为中心的决策等方法，可以实现对人类智能的模拟。本课程系统地介绍了人工智能的基本概念和算法，可以帮助学习者掌握人工智能的背景，体验其力量、赋能和赋权，并“知其意，明其理，顺其规，从其法”。课程内容包括人工智能概述、搜索与解决方案、逻辑与推理、监督学习、无监督学习、深度学习、强化学习和博弈对抗。来者不拒而不失时机；行者不迷而不失机遇。人工智能不仅仅是一门课程，更是第一手技术、产品或应用，而是一个具有深刻理论、充满活力的技术、产品落地的牵引力和社会应用赋能的综合生态系统（AI生态系统）。为加强实践训练，课程安排了诸如以搜索与解决方案为核心的黑白棋AI算法、以线性回归为核心的图像恢复、以深度学习为核心的垃圾分类等实用训练主题。AI模型包括：
- en: Decision Tree
  id: totrans-1
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树
- en: 'The decision tree employs a tree structure to construct a decision model based
    on the properties of the data and to categorize the data. In the process of step-by-step
    response, a typical decision tree analysis will use hierarchical variables or
    decision nodes. Classification and regression issues are frequently solved using
    the decision tree approach. Take clothing purchase as an example, first determine
    whether you like it, don''t buy it if you don''t like it, look at the price if
    you want it, don''t buy it if the price is not suitable, check whether there is
    a right size if it is suiconvenienton''t buy it if you don''t havan appropriate
    size, and buy it if it is available, Based on the above selections, a simple stump
    structure can be drawn.Scenario examples: rule-based credit evaluation, horse
    racing result predictionStrengths: Good at evaluating a range of different characteristics,
    qualities, characteristics of people, places, thingsCommonly related algorithms:
    Classification and Regression Tree (CART), ID3 (Iterative Dichotomiser 3), GBDT,
    C4.5, Chi-squared Automatic Interaction Detection (CHAID), Decision Stump, Random
    Forest (Random Forest), Multiple Adaptive Regression Splines (MARS), Gradient
    Boosting Machine (GBM)Random forest:  The random forest algorithm improves the
    accuracy of decision trees by using multiple trees with randomly selected subsets
    of the data.Pros: Random forest methods have proven useful for large datasets
    and items with a large number of and sometimes irrelevant features'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树采用树形结构构建决策模型，基于数据的属性对数据进行分类。在逐步响应的过程中，典型的决策树分析将使用层次变量或决策节点。分类和回归问题经常使用决策树方法解决。以购买服装为例，首先确定是否喜欢，如果不喜欢就不买，如果喜欢就看价格，如果价格不合适就不买，如果方便就看是否有合适的尺码，如果没有合适的尺码就不买，如果有就购买。基于以上选择，可以绘制一个简单的树桩结构。场景示例：基于规则的信用评估，赛马结果预测优势：擅长评估不同特征、品质、人、地点、事物的特征常见相关算法：分类与回归树（CART），ID3（迭代二叉树3），GBDT，C4.5，卡方自动交互检测（CHAID），决策树桩，随机森林（Random
    Forest），多元自适应回归样条（MARS），梯度提升机（GBM）随机森林：随机森林算法通过使用随机选择的数据子集和多个树来提高决策树的准确性。优点：随机森林方法已被证明对于大型数据集和具有大量甚至有时是无关特征的项目非常有用
- en: Regression Algorithm
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回归算法
- en: 'A regression algorithm explores the relationship between variables by measuring
    the error and can outline the state relationship between the dependent variable
    and one or more dependent variables. A regression algorithm can be used to distinguish
    spam from non-spam. Typical standards include Ordinary Least Square, Linear Regression,
    Logistic Regression, Stepwise Regression, Multivariate Adaptive Regression Splines,
    Local Scatter Smoothing Estimation (Locally Estimated Scatterplot Smoothing)Scenario
    examples: road traffic flow analysis, email filteringPros: Regression can be used
    to identify continuous relationships between variables, even if the connection
    is not obvious'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 回归算法通过测量误差来探索变量之间的关系，并可以概述因变量与一个或多个自变量之间的状态关系。回归算法可用于区分垃圾邮件和非垃圾邮件。典型标准包括普通最小二乘法，线性回归，逻辑回归，逐步回归，多元自适应回归样条，局部散点平滑估计（局部估计散点平滑）场景示例：道路交通流量分析，电子邮件过滤优势：回归可用于识别变量之间的连续关系，即使连接并不明显
- en: Learning Algorithm Based on The Kernel Function
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于核函数的学习算法
- en: The most famous kernel-based algorithm is the Support Vector Machine (SVM).
    Kernel-based algorithms map the input data to a higher-order vector space in which
    some classification or regression problems can be solved more easily. Standard
    algorithms include support vector machine (Support Vector Machine, SVM), radial
    basis function (Radial Basis Function, RBF), and linear discriminant analysis
    (Linear Discriminate Analysis, LDA).Further reading Learning Algorithm Based on
    Kernel Function
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的基于核的算法是支持向量机（SVM）。基于核的算法将输入数据映射到更高维的向量空间，其中一些分类或回归问题可以更容易地解决。标准算法包括支持向量机（Support
    Vector Machine, SVM），径向基函数（Radial Basis Function, RBF），线性判别分析（Linear Discriminate
    Analysis, LDA）。进一步阅读基于核函数的学习算法
- en: Example-Based Algorithms
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于示例的算法
- en: It is often used to build models for decision-making problems. For example,
    the decision tree approach frequently solves classification and regression issues.
    In this way, the best matStandardfound. Standard algorithms include k-Nearest
    Neighbor (KNN), Learning Vector Quantization (LVQ), and Self-Organizing Map (SOM).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 它经常用于构建决策问题的模型。例如，决策树方法经常解决分类和回归问题。通过这种方式，找到最佳匹配。标准算法包括k-最近邻（KNN）、学习向量量化（LVQ）和自组织映射（SOM）。
- en: Neural Network
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络
- en: 'A neural network is also a classifier. It is a network composed of many virtual
    neurons. We can regard a neuron as a classifier, and the network of many neurons
    can classify samples many times.CNN (Convolutional Neural Networks) convolutional
    neural network is a feed-forward neural network. Its artificial neurons may respond
    to nearby units within a portion of the coverage area, performing well for large-scale
    image processing.Pros: Convolutional Neural Networks are helpful when there are
    large datasets, a large number of features, and complex classification tasksScenario
    examples : image recognition, text-to-speech, drug discovery, photo filters, face
    recognition, driverless cars, etc.RNN Recurrent Neural Networks) recurrent neural
    network, in any neural network, each neuron converts many inputs into a single
    output through one or more hidden layers. Recurrent Neural Networks (RNN) pass
    values ​​further layer by layer, making layer-by-layer learning possible. In other
    words, RNNs have some form of memory that allows previous outputs to influence
    later inputs.The recurrent neural network is a general term for two kinds of artificial
    neural networks: time recurrent neural network (recurrent neural network) and
    the structural recursive neural network (recursive neural network). The connection
    between temporal recurrent neural network neurons is a directed graph, while structural
    recurrent neural networks utilize similar neural network structures to recursively
    construct more complex deep networks. The algorithms trained by the two are different
    but belong to the same algorithm variant. Based on RNN, algorithms such as LSTM
    (Long-Short-Term-Memery) and GRU (Gated Recurrent Unit) have been derived. These
    algorithms can remember the past, so they can be used to process some data with
    time series attributes. Therefore, it has unique advantages in processing language,
    text, etc. LSTM and GRU have the same advantages as other recurrent neural networks
    but are more commonly used because they have better memory capabilities.Pros:
    Recurrent neural networks have predictive power in the presence of large amounts
    of ordered informationScenario examples: image classification and subtitle addition,
    political sentiment analysis, dialogue robot, machine translation, natural language
    recognition of iFlytek, article editing, etc.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络也是一种分类器。它是由许多虚拟神经元组成的网络。我们可以将一个神经元视为一个分类器，而许多神经元组成的网络可以多次对样本进行分类。CNN（卷积神经网络）是一种前馈神经网络。其人工神经元可能对覆盖区域内的附近单元做出响应，在大规模图像处理方面表现良好。优点：卷积神经网络在存在大型数据集、大量特征和复杂分类任务时非常有帮助。场景示例：图像识别、文本转语音、药物发现、照片滤镜、人脸识别、无人驾驶汽车等。RNN（循环神经网络）在任何神经网络中，每个神经元通过一个或多个隐藏层将许多输入转换为单个输出。循环神经网络（RNN）逐层传递值，使逐层学习成为可能。换句话说，RNN具有某种形式的记忆，允许先前的输出影响后续的输入。循环神经网络是人工神经网络的一个通用术语，包括时间循环神经网络（循环神经网络）和结构递归神经网络（递归神经网络）。时间循环神经网络神经元之间的连接是一个有向图，而结构循环神经网络利用类似的神经网络结构递归构建更复杂的深度网络。这两种训练的算法不同，但属于同一算法变体。基于RNN，派生出了诸如LSTM（长短期记忆）和GRU（门控循环单元）等算法。这些算法可以记住过去，因此可以用于处理具有时间序列属性的一些数据。因此，在处理语言、文本等方面具有独特优势。LSTM和GRU具有其他循环神经网络的相同优点，但更常用，因为它们具有更好的记忆能力。优点：循环神经网络在存在大量有序信息时具有预测能力。场景示例：图像分类和字幕添加、政治情绪分析、对话机器人、机器翻译、讯飞的自然语言识别、文章编辑等。
- en: Yebeis Algorithm
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Yebeis算法
- en: 'Bayesian is a theorem, which means that when you cannot accurately know the
    essence of a thing, you can rely on the occurrence of events related to the specific
    nature of the item to judge the probability of its essential attribute. When we
    find several such features and then use these features to combine them, we can
    consider them. Common algorithms include the Naive Bayesian algorithm, Averaged
    One-Dependence Estimators (AODE), and Bayesian Belief Network (BBN).For example,
    to identify whether an email is spam or not. We can randomly select 100 spam emails
    and analyze their characteristics. We find that the word "cheap" appears frequently,
    and this word appears in 40 of the 100 spam emails. Then we use this cognition
    to conclude: if there is "cheap," there is a 40% probability that this email is
    spam.Pros: Naive Bayes can quickly classify related objects with salient features
    on small datasetsScenario examples: sentiment analysis, consumer classification'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯是一个定理，意味着当你无法准确了解一件事物的本质时，可以依靠与该物品特定属性相关的事件发生来判断其本质属性的概率。当我们发现几个这样的特征，然后将这些特征结合起来使用时，我们可以考虑它们。常见的算法包括朴素贝叶斯算法、平均单依赖估计器（AODE）和贝叶斯信念网络（BBN）。例如，要识别一封电子邮件是否为垃圾邮件。我们可以随机选择100封垃圾邮件并分析它们的特征。我们发现单词“cheap”频繁出现，并且这个词在这100封垃圾邮件中出现了40次。然后我们使用这种认知得出结论：如果有“cheap”，那么这封邮件是垃圾邮件的概率为40%。优点：朴素贝叶斯可以快速对具有显著特征的相关对象进行分类。场景示例：情感分析、消费者分类
- en: Clustering
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚类
- en: Clustering is a form of unsupervised learning. Simply put, it is to divide the
    data into several groups through continuous iterative calculation so that all
    the data in this group are similar, and the data between distinct groups are not
    identical. Clustering techniques often integrate input data centrally or hierarchically.
    Clustering techniques often combine input data centrally or hierarchically. It
    can be used in image classification recognition, user behavior recognition, user
    portrait, and other fields. Standard algorithms include the k-Means and expectation
    maximization algorithms (Expectation Maximization, EM).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是一种无监督学习形式。简单来说，它是通过连续迭代计算将数据分成几组，使得该组中的所有数据相似，而不同组之间的数据并不相同。聚类技术通常集成输入数据中心或层次结构。聚类技术通常集成输入数据中心或层次结构。它可以用于图像分类识别、用户行为识别、用户画像等领域。标准算法包括k-Means和期望最大化算法（Expectation
    Maximization, EM）。
- en: Reinforcement Learning Model
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 强化学习模型
- en: In the absence of any answer, first, try some attempts, and determine whether
    the effort is correct through the rewards obtained from the step. This series
    of shots is used to adjust and optimize the algorithm continuously. Finally, the
    algorithm knows that in a specific situation, action can be taken to obtain the
    best result. His essence is to solve the "decision-making problem," that is, to
    learn to make decisions automatically and get the optimal result after making
    continuous decisions and getting feedback. For example, monkeys "learn" to do
    the arithmetic as mentioned above problems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有任何答案的情况下，首先尝试一些尝试，并通过从步骤中获得的奖励来确定努力是否正确。这一系列尝试用于不断调整和优化算法。最终，算法知道在特定情况下，可以采取行动以获得最佳结果。其本质是解决“决策问题”，即学会自动做出决策，并在做出连续决策并获得反馈后获得最佳结果。例如，猴子“学会”做算术如上述问题。
- en: Integrated Learning Model
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集成学习模型
- en: Train various relatively weak learning models independently on the same data,
    then combine the results for overall prediction. The ensemble algorithm's key
    challenge is determining which separate and more fragile learning models to connect
    and how to integrate the learning outcomes.We want to make models that perform
    better in all aspects of machine learning. But often, the reality is that our
    models have preferences and may only work better for specific situations. So,
    now, we want to combine several such models to get a better and more comprehensive
    model. This method is It's called ensemble learning. Common algorithms include
    Boosting, Bootstrapped Aggregation (Bagging), AdaBoost, Stacked Generalization
    (Blending), Gradient Boosting Machine (GBM), and Random Forest.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在相同数据上独立训练各种相对较弱的学习模型，然后将结果合并进行整体预测。集成算法的关键挑战在于确定要连接哪些独立且更脆弱的学习模型以及如何整合学习结果。我们希望创建在机器学习的各个方面表现更好的模型。但现实往往是，我们的模型有偏好，可能只在特定情况下表现更好。因此，现在，我们希望结合几个这样的模型以获得更好和更全面的模型。这种方法被称为集成学习。常见的算法包括Boosting、Bootstrapped
    Aggregation（Bagging）、AdaBoost、Stacked Generalization（Blending）、Gradient Boosting
    Machine（GBM）和Random Forest。
