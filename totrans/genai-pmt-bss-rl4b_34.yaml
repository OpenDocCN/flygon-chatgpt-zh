- en: This can raise concerns about accountability, particularly in areas such as
    criminal justice or national security, where decisions made by generative AI can
    have significant consequences. Therefore, taking a responsible and ethical approach
    to creating and applying generative AI to overcome these ethical issues is critical.
    This includes adopting ethical guidelines and standards for developing and deploying
    generative AI and developing mechanisms for ensuring transparency and accountability
    in the use of the technology.Additionally, engaging in ongoing dialogue and collaboration
    between developers, users, policymakers, and the general public is essential to
    ensure that generative AI is consistent with ethical and moral principles and
    promotes the common good.
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能引发对问责的担忧，特别是在刑事司法或国家安全等领域，生成式人工智能做出的决定可能产生重大后果。因此，采取负责任和道德的方式创建和应用生成式人工智能以克服这些道德问题至关重要。这包括采纳用于开发和部署生成式人工智能的道德准则和标准，并开发机制以确保技术使用的透明度和问责制。此外，进行持续的对话和合作，涉及开发人员、用户、政策制定者和普通公众，对确保生成式人工智能符合道德和道德原则，并促进共同利益至关重要。
- en: CONTROL AND INTERPRETABILITY
  id: totrans-1
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制和可解释性
- en: Generative AI models can generate content autonomously, making it challenging
    for humans to control or understand the output. For example, a generative AI model
    trained to generate text may generate offensive, biased, or inappropriate text,
    which can be difficult to anticipate or control. Similarly, a generative AI model
    trained to generate images may create images that contain sensitive or confidential
    information, which could have negative consequences if the pictures are released
    publicly.Moreover, generative AI models can be challenging to interpret, particularly
    when they generate unexpected or unusual content. It can be challenging for humans
    to understand how the AI model arrived at a particular output, making it difficult
    to detect and correct errors or biases in the production.Researchers are exploring
    new techniques for controlling and interpreting generative AI outputs to address
    this limitation. For example, researchers are working on developing methods for
    conditioning the output of generative AI models on specific input parameters,
    which can help to ensure that the production is aligned with the goals and values
    of the user.Additionally, researchers are exploring new methods for generating
    explanations and visualizations of how generative AI models arrive at respective
    outputs. This can increase the models' interpretability and make it easier for
    humans to detect and correct errors or biases in production.However, it is essential
    to note that significant progress is still needed in these areas before generative
    AI can be used effectively in contexts where control and interpretability are
    critical, such as in healthcare, finance, or national security.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能模型可以自主生成内容，这让人类难以控制或理解输出。例如，一个训练用于生成文本的生成式人工智能模型可能会生成具有攻击性、偏见或不当内容的文本，这可能难以预料或控制。同样，一个训练用于生成图像的生成式人工智能模型可能会创建包含敏感或机密信息的图像，如果这些图片被公开发布，可能会产生负面后果。此外，生成式人工智能模型在生成意外或异常内容时可能难以解释。人类可能难以理解人工智能模型是如何得出特定输出的，这使得难以检测和纠正生产中的错误或偏见。研究人员正在探索新技术，以控制和解释生成式人工智能的输出，以解决这一限制。例如，研究人员正在努力开发方法，通过特定输入参数对生成式人工智能模型的输出进行调节，这有助于确保生产与用户的目标和价值观保持一致。此外，研究人员正在探索新方法，生成解释和可视化生成式人工智能模型如何得出各自的输出。这可以增加模型的可解释性，使人类更容易检测和纠正生产中的错误或偏见。然而，需要指出的是，在这些领域取得重大进展之前，生成式人工智能才能在控制和可解释性至关重要的情境中有效使用，例如在医疗保健、金融或国家安全领域。
- en: POTENTIAL FOR MISUSE AND UNINTENDED CONSEQUENCES
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滥用和意外后果的潜在可能性
- en: Generative AI can be used for positive and negative purposes. However, predicting
    how the technology will be used or what unintended consequences may arise can
    be challenging.For example, generative AI models can generate convincing deep
    fakes, realistic but fake images, videos, or audio that can be used to deceive
    or manipulate people. Deepfakes can be used for malicious purposes, such as spreading
    false information or creating fake evidence, and have significant social and political
    consequences.Moreover, generative AI models can be used to automate tasks previously
    done by humans, which can lead to job displacement and economic disruption. While
    generative AI can create new opportunities and increase productivity, it can also
    lead to inequality and social unrest if the benefits of the technology are not
    distributed fairly.To address this limitation, it is essential to develop ethical
    guidelines and regulations for the use of generative AI and raise awareness among
    users and the public about the potential risks and benefits of the technology.
    Additionally, it is important to invest in research exploring the social, economic,
    and political implications of generative AI and to involve stakeholders from diverse
    backgrounds in developing and deploying the technology. By doing so, we can ensure
    that generative AI is used responsibly and beneficially, benefiting society.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能可以用于积极和消极的目的。然而，预测技术将如何被使用或可能出现的意外后果可能是具有挑战性的。例如，生成式人工智能模型可以生成令人信服的深度伪造，逼真但虚假的图像、视频或音频，可以用来欺骗或操纵人们。深度伪造可以被用于恶意目的，比如传播虚假信息或制造假证据，并且具有重大的社会和政治后果。此外，生成式人工智能模型可以用于自动化以前由人类完成的任务，这可能导致工作岗位的替代和经济动荡。虽然生成式人工智能可以创造新的机会并提高生产力，但如果技术的好处没有公平分配，也可能导致不平等和社会动荡。为了解决这一局限性，有必要为生成式人工智能的使用制定道德准则和法规，并提高用户和公众对技术的潜在风险和好处的意识。此外，重要的是投资于研究探索生成式人工智能的社会、经济和政治影响，并让来自不同背景的利益相关者参与制定和部署技术。通过这样做，我们可以确保生成式人工智能被负责任和有益地使用，造福社会。
- en: PRIVACY AND SECURITY
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 隐私和安全
- en: Generative AI models require large amounts of data to be trained effectively,
    which can raise privacy concerns if the data contains sensitive or personal information. 
    For example, a generative AI model trained on healthcare data may collect sensitive
    information about individuals' medical conditions, which could be exploited if
    the model is hacked or breached. Similarly, a generative AI model trained on financial
    data may contain sensitive information about individuals' financial transactions,
    which could be used for fraud or identity theft.Moreover, generative AI models
    can be vulnerable to adversarial attacks, which involve manipulating the input
    data to generate unexpected or malicious outputs. Hostile attacks can create deep
    fakes, bypass security systems, compromise privacy, and be difficult to detect
    or defend against.To address this limitation, it is important to develop robust
    data privacy and security measures for generative AI, including techniques for
    anonymizing or encrypting sensitive data and detecting and defending against adversarial
    attacks. Additionally, it is important to ensure that generative AI models are
    developed and deployed transparently and accountable, with precise data usage
    and governance guidelines.By addressing these privacy and security concerns, we
    can ensure that generative AI is used in a responsible and trustworthy way that
    protects the privacy and security of individuals and society as a whole.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能模型需要大量数据进行有效训练，如果数据包含敏感或个人信息，可能会引发隐私问题。例如，一个在医疗数据上训练的生成式人工智能模型可能会收集有关个人医疗状况的敏感信息，如果模型被黑客攻击或泄露，这些信息可能会被利用。同样，一个在金融数据上训练的生成式人工智能模型可能包含有关个人财务交易的敏感信息，这可能被用于欺诈或身份盗窃。此外，生成式人工智能模型可能容易受到对抗性攻击的影响，这涉及操纵输入数据以生成意外或恶意输出。敌对攻击可以制造深度伪造，绕过安全系统，危害隐私，并且难以检测或防御。为了解决这一局限性，重要的是为生成式人工智能制定强大的数据隐私和安全措施，包括对敏感数据进行匿名化或加密的技术，以及检测和防御对抗性攻击的方法。此外，重要的是确保生成式人工智能模型以透明和负责任的方式开发和部署，具有精确的数据使用和治理指南。通过解决这些隐私和安全问题，我们可以确保生成式人工智能以负责任和值得信赖的方式使用，保护个人和整个社会的隐私和安全。
