- en: Chapter 4
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第四章
- en: Understanding GPT Models in ChatGPT
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 了解 ChatGPT 中的 GPT 模型
- en: IN THIS CHAPTER
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本章内容
- en: '![](images/00003.jpg) Comparing three models in ChatGPT'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 在 ChatGPT 中比较三个模型'
- en: '![](images/00003.jpg) Understanding the difference the upgrades make'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 了解升级带来的差异'
- en: '![](images/00003.jpg) Creating plans to leverage the models'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 制定利用模型的计划'
- en: '![](images/00003.jpg) Grasping the importance of extended prompts'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 理解扩展提示的重要性'
- en: ChatGPT’s models have evolved quickly. The research model using GPT-3 was released
    in November 2022 for public training and testing. By January 2023, Open AI was
    quietly rolling out an upgrade, GPT-3.5, a more stable version and the precursor
    for GPT-4, which was released in March 2023\. In this chapter, you learn about
    these models and how each affects ChatGPT’s performance.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ChatGPT 的模型发展迅速。使用 GPT-3 的研究模型于 2022 年 11 月发布供公众训练和测试。到了 2023 年 1 月，Open AI
    悄悄推出了一个升级版，GPT-3.5，这是一个更加稳定的版本，也是 GPT-4 的前身，后者于 2023 年 3 月发布。在本章中，您将了解这些模型以及每个模型对
    ChatGPT 性能的影响。
- en: Summarizing Model Progress
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 总结模型进展
- en: As of this writing, ChatGPT defaults to GPT-3.5, but ChatGPT Plus users can
    choose from any of the models listed in the pull-down menu at the top center of
    the user interface, as shown in [Figure 4-1](#filepos175241).
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 截至目前，ChatGPT 默认使用 GPT-3.5，但 ChatGPT Plus 用户可以从用户界面顶部中心的下拉菜单中选择任何列出的模型，如 [图 4-1](#filepos175241)
    所示。
- en: Essentially, GPT-3.5 is an early and partial manifestation of GPT-4 before it
    was fully trained. OpenAI used Chat 3.5 to further develop several specialized
    systems, including ChatGPT.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本质上，GPT-3.5 是在完全训练之前的 GPT-4 的早期和部分体现。OpenAI 使用 Chat 3.5 进一步开发了几个专门的系统，包括 ChatGPT。
- en: '![](images/00056.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00056.jpg)'
- en: '[FIGURE 4-1:](#filepos174880) Model options and other selections for ChatGPT
    Plus users.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-1:](#filepos174880) ChatGPT Plus 用户的模型选项和其他选择。'
- en: The incremental rollout of GPT-3.5 was immediately useful to users and developers
    through its increased stability, better performance, and significant cost cut
    for developers.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-3.5 的逐步推出立即为用户和开发者带来了更高的稳定性、更好的性能以及显著的成本削减。
- en: GPT-3.5 is better than GPT-3 in a number of ways, but the two most prevalent
    are increased alignment with user intentions and more refined controls on toxic
    or biased content. GPT-3.5 is less likely to offend or hallucinate and more stable
    overall.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-3.5 在许多方面都优于 GPT-3，但最突出的两点是与用户意图更加一致，以及对有毒或偏见内容有更精细的控制。GPT-3.5 不太可能冒犯或产生幻觉，整体更加稳定。
- en: GPT-4 is the long-awaited and much ballyhooed full version release of this latest
    in the GPT series of models. While the jump between GPT-2 and GPT-3 was bigger
    and more impressive, the jump between GPT-3 and GPT-4 is more significant, useful,
    and notable, mainly because GPT-4 is a high-powered, more stable, and safer model.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-4 是 GPT 系列最新版本的期待已久且备受瞩目的完整版本发布。虽然 GPT-2 和 GPT-3 之间的跨越更大更令人印象深刻，但 GPT-3
    和 GPT-4 之间的跨越更为重要、有用和显著，主要是因为 GPT-4 是一个功能强大、更稳定和更安全的模型。
- en: Public interest in GPT-4 was high before its release, in March 2023\. ChatGPT
    has cycled through three model versions in a mere four months since the freebie
    research model became publicly available. That in itself is a remarkable achievement.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-4 发布前，公众对其的兴趣很高，时间是在 2023 年 3 月。自从免费研究模型公开发布以来，ChatGPT 在短短四个月内经历了三个模型版本的循环。这本身就是一个值得称赞的成就。
- en: Comparing GPT-4 to Earlier ChatGPT Models
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将 GPT-4 与早期的 ChatGPT 模型进行比较
- en: GPT-4, the latest version to power ChatGPT, is a multimodal model, which means
    this large language model (LLM) can work with images and text in the prompt, but
    its responses are rendered solely as text. ChatGPT-3.5 can use only text in prompts
    and in its responses. ChatGPT-4 also uses more computations on much larger databases
    than its predecessors.
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-4，作为驱动 ChatGPT 的最新版本，是一个多模态模型，这意味着这个大型语言模型（LLM）可以处理图像和提示中的文本，但其响应仅以文本形式呈现。ChatGPT-3.5
    只能在提示和响应中使用文本。ChatGPT-4 还使用比以往更大的数据库上更多的计算。
- en: Image interpretation is a unique AI skill often referred to as computer vision
    or machine vision, a nod of recognition of AI’s progression towards more humanlike
    qualities, in this case, the inclusion of sight as an input source.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图像解释是一种独特的人工智能技能，通常被称为计算机视觉或机器视觉，这是对人工智能向更具人类特质的进展的一种认可，即将视觉作为输入源之一。
- en: With this skill, AI is not just analyzing or matching images but also extracting
    data from them as a human would. For example, a person can look at a receipt and
    immediately understand the exact cost of that transaction or calculate an appropriate
    tip or both.
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 借助这种技能，AI不仅仅是分析或匹配图像，还可以像人类一样从中提取数据。例如，一个人可以查看收据并立即了解该交易的确切成本或计算适当的小费或两者兼而有之。
- en: Similarly, AI can use image inputs to extract the data needed to perform face
    recognition, read content in the image, find evidence in the image of a crime
    scene, or spot a health condition in an X-ray film.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 同样，AI可以使用图像输入提取执行面部识别所需的数据，阅读图像中的内容，在犯罪现场的图像中找到证据，或在X光片中发现健康状况。
- en: Thus, an AI model that can use images as an input is a very big deal. It's not
    a skill that earlier forms of AI could typically master. Even so, you might wonder
    why it’s notable now, given that multimodal models already exist. After all, OpenAI’s
    own DALL-E 2 is multimodal, with prompts that can be comprised of alphanumeric
    text, images, or both. Plus, DALL-E 2 outputs images. Does this mean it's using
    a better multimodal model than ChatGPT?
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 因此，一个可以使用图像作为输入的AI模型是一件大事。这不是早期形式的AI通常能够掌握的技能。即便如此，您可能会想知道为什么现在值得注意，考虑到多模态模型已经存在。毕竟，OpenAI自己的DALL-E
    2是多模态的，提示可以由字母数字文本、图像或两者组成。此外，DALL-E 2输出图像。这是否意味着它使用比ChatGPT更好的多模态模型？
- en: The answer is no. DALL-E 2 uses the same GPT models as ChatGPT. But the GPT-4
    model enhances DALL-E 2 with greater creativity, more realism in image creation
    and editing, and far better resolution. DALL-E is an image generator and DALL-E
    2 remains an image generator but with a far more powerful engine.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 答案是否定的。DALL-E 2使用与ChatGPT相同的GPT模型。但GPT-4模型通过更大的创造力、更真实的图像创建和编辑，以及更好的分辨率增强了DALL-E
    2。DALL-E是一个图像生成器，DALL-E 2仍然是一个图像生成器，但具有更强大的引擎。
- en: By comparison, ChatGPT was previously a single modality system, designed for
    only alphanumeric prompts. Now that ChatGPT uses the GPT-4 model, it has been
    adapted to be multimodal, meaning it can now accept images in its prompts. However,
    ChatGPT is a text generator and remains a text generator, with a few impressive
    upgrades courtesy of the new GPT-4 model.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 相比之下，ChatGPT以前是一个单模态系统，仅设计用于字母数字提示。现在ChatGPT使用GPT-4模型，已经适应为多模态，这意味着它现在可以在提示中接受图像。然而，ChatGPT仍然是一个文本生成器，并且仍然是一个文本生成器，得益于新的GPT-4模型的一些令人印象深刻的升级。
- en: Those upgrades in capabilities surpass the capabilities of earlier AI systems.
    For example, GPT-4 can interpret images, explain visual humor, and base its reasoning
    on visual input.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些功能升级超越了早期AI系统的功能。例如，GPT-4可以解释图像，解释视觉幽默，并基于视觉输入进行推理。
- en: Expanding the types of input enables the model to do more complex tasks and
    deeper, more refined analyses. In short, ChatGPT-4 has enhanced problem-solving,
    creative superpowers (for an AI model), and a mind-blowingly massive general knowledge
    base. It’s the largest of the large language models to date.
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 扩展输入类型使模型能够执行更复杂的任务和更深入、更精细的分析。简而言之，ChatGPT-4具有增强的问题解决能力，创造性超能力（对于AI模型而言），以及一个令人惊叹的庞大通用知识库。这是迄今为止最大的大型语言模型。
- en: However, as mentioned, ChatGPT-4 can't output images. It generates text only,
    just like earlier ChatGPT models, but with more depth in its considerations of
    your input and expectations.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 然而，正如前面提到的，ChatGPT-4无法输出图像。它仅生成文本，就像早期的ChatGPT模型一样，但在考虑您的输入和期望方面更加深入。
- en: Choosing ChatGPT Models
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 选择ChatGPT模型
- en: ChatGPT gives you the option of selecting the model you want to use, as shown
    in [Figure 4-2](#filepos181106). Given that ChatGPT-4 can't generate images, if
    you don’t have any images to add to the prompt, do you still need ChatGPT-4? Or
    could you just stick with an earlier version and proceed as usual?
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ChatGPT为您提供选择要使用的模型的选项，如[图4-2](#filepos181106)所示。鉴于ChatGPT-4无法生成图像，如果您没有任何图像要添加到提示中，您是否仍然需要ChatGPT-4？或者您可以坚持使用早期版本并像往常一样继续吗？
- en: '![](images/00076.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00076.jpg)'
- en: '[FIGURE 4-2:](#filepos180796) You can choose the GPT model to use in your chat.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-2：](#filepos180796)您可以选择要在聊天中使用的GPT模型。'
- en: The answer depends on what you’re doing with ChatGPT and what you expect or
    need from it. If higher performance is important, reliability measures place the
    GPT-4 model well ahead of GPT-3 and GPT-3.5\. For example, GPT-4 scores alongside
    the top 10 percent of humans taking a simulated bar exam. By comparison, GPT-3.5
    scored with the bottom 10 percent. And that’s not the only human-to-AI comparative
    test in which GPT-4 has rated high. [Figure 4-3](#filepos182274) shows a list
    of academic and professional exams with GPT-4 scores compiled from OpenAI’s GPT-4
    Technical Report, which you can find at [`https://cdn.openai.com/papers/gpt-4.pdf`](https://cdn.openai.com/papers/gpt-4.pdf).
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 答案取决于你如何使用 ChatGPT 以及你对它的期望或需求。如果性能更重要，可靠性措施将使 GPT-4 模型遥遥领先于 GPT-3 和 GPT-3.5。例如，GPT-4
    在模拟法律考试中的得分与排名前 10% 的人类并驾齐驱。相比之下，GPT-3.5 的得分与排名最后 10% 的人类相当。而且 GPT-4 在其他人类与人工智能比较测试中也表现出色。[图
    4-3](#filepos182274) 展示了从 OpenAI 的 GPT-4 技术报告中整理出的 GPT-4 在学术和专业考试中的得分，你可以在 [`https://cdn.openai.com/papers/gpt-4.pdf`](https://cdn.openai.com/papers/gpt-4.pdf)
    找到。
- en: '![](images/00019.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00019.jpg)'
- en: '[FIGURE 4-3:](#filepos181891) GPT-4 rankings on academic and professional exams.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-3：](#filepos181891) GPT-4 在学术和专业考试中的排名。'
- en: GPT-4 performs better because it is better trained. It is built on GPT-3's training,
    including lessons learned from the ChatGPT research model, and is further aligned
    with user intention by OpenAI’s adversarial testing program. The result is a powerful,
    more stable, and higher-performance large language model with multimodal input
    capabilities.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-4 表现更好是因为它接受了更好的训练。它建立在 GPT-3 的训练基础上，包括从 ChatGPT 研究模型中学到的经验教训，并通过 OpenAI
    的对抗测试计划进一步与用户意图保持一致。结果是一个功能强大、更稳定、性能更高的大型语言模型，具有多模态输入能力。
- en: Multimodality is a rising trend in AI research. Two examples of competing multimodal
    models are Microsoft’s recently released Kosmos-1 and Google’s recently enhanced
    PaLM language model.
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 多模态是人工智能研究中的一个新兴趋势。微软最近发布的 Kosmos-1 和谷歌最近增强的 PaLM 语言模型是竞争的两个多模态模型的例子。
- en: But ChatGPT-4 and other multimodal models also carry greater and new risks given
    their increased capability and the tremendous scale of their training. OpenAI
    has taken significant steps to make ChatGPT-4 safer, but safer is a relative term
    and not a guarantee of anything one might consider to be unquestionably safe.
    I say this not to diminish OpenAI’s work in installing significant safety measures,
    but to make sure your expectations are reasonable and you know to proceed with
    caution.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但是，ChatGPT-4 和其他多模态模型也带来了更大和新的风险，因为它们的能力增强了，训练规模也巨大。OpenAI 已经采取了重要措施使 ChatGPT-4
    更安全，但“更安全”是一个相对的术语，并不是任何人可能认为绝对安全的保证。我说这话并不是为了贬低 OpenAI 在安装重要安全措施方面的工作，而是为了确保你的期望是合理的，并且你知道要谨慎行事。
- en: Determine what level of risk acceptance is comfortable for you and then take
    any additional steps as necessary. Precautionary steps should include routinely
    editing and fact-checking ChatGPT responses. But you might want to take additional
    steps, such as consulting an attorney before accepting or implementing ChatGPT
    responses to legal questions or legal documents it has created for you. Consult
    a physician before accepting medical advice from a ChatGPT response regarding
    a correct and safe treatment. And so forth.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 确定你对风险接受的舒适程度，然后根据需要采取任何额外步骤。预防措施应包括定期编辑和事实核查 ChatGPT 的回应。但你可能需要采取额外步骤，比如在接受或实施
    ChatGPT 对法律问题或为你创建的法律文件的回应之前，咨询律师。在接受关于正确和安全治疗的医疗建议时，应咨询医生。等等。
- en: Compared to earlier models, ChatGPT-4 has a far greater capacity for reasoning
    and better regulated guardrails that tend to keep the model from shying away from
    questions unnecessarily or boldly offending. Those are reasons enough to use the
    newer model, even if you have neither the need nor the desire to add images to
    the prompt.
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与早期模型相比，ChatGPT-4 在推理能力和更好的监管措施方面有了显著提升，这些措施可以防止模型不必要地回避问题或大胆冒犯。这些已经足够的理由来使用新模型，即使你既没有需要也没有愿望在提示中添加图片。
- en: But this is not to say that ChatGPT-3.5 or ChatGPT-3 are obsolete. These models
    are magnificent technological accomplishments and among the largest of large language
    models. Both continue to work well in many use cases. Either can be a good choice
    for several reasons, including if you're on the ChatGPT-4 waitlist or facing a
    traffic-jammed queue for ChatGPT-4 access.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但这并不意味着ChatGPT-3.5或ChatGPT-3已经过时。这些模型是了不起的技术成就，是最大的大型语言模型之一。它们在许多用例中仍然表现良好。无论是因为你在ChatGPT-4的等待列表上，还是因为面临ChatGPT-4访问的交通拥堵队列，任何一个都可能是一个不错的选择。
- en: None of these models is an AI lightweight. Understand the model differences
    and choose according to your needs and preferences. Your ChatGPT chat history
    follows you from model to model, unless you clear it, so you don't need to worry
    about losing any of your earlier work if you trade up (subject to storage and
    token limits).
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些模型都不是AI轻量级。了解模型的差异，并根据您的需求和偏好进行选择。您的ChatGPT聊天记录会随着模型的更换而保留，除非您清除它，因此您不必担心如果升级会丢失之前的任何工作（受存储和令牌限制）。
- en: However, most users will elect to use GPT-4 or whatever subsequent new model
    arises, either to intentionally benefit from the upgrade or as a consequence of
    the product’s default setting.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 然而，大多数用户将选择使用GPT-4或任何随后出现的新模型，无论是有意从升级中受益还是作为产品默认设置的结果。
- en: Learning about GPT-4 Advancements
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 了解GPT-4的进展
- en: Of all the advancements in the GPT-4 model, the one that is the most important
    and relevant in terms of overall performance is predictability. The model produces
    outputs that AI human trainers can predict. Predictability is not a strong suit
    in previous ChatGPT versions.
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在GPT-4模型的所有进展中，就整体性能而言，最重要和相关的是可预测性。该模型产生的输出可以被AI人类训练者预测。可预测性并不是以前ChatGPT版本的强项。
- en: Being able to predict outputs is essential in determining an AI model’s reliability
    and accuracy. For example, if the machine — be it a simple calculator or a generative
    AI model— is presented with the problem of 2+5 and solves it for the answer 7
    every time, the machine is 100 percent accurate and reliable for that calculation.
    However, if it answers 7 only half the time and answers with random numbers the
    other half of the time, it is not considered sufficiently reliable even though
    it gets the answer correct 50 percent of the time.
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 能够预测输出对于确定AI模型的可靠性和准确性至关重要。例如，如果机器——无论是简单的计算器还是生成式人工智能模型——被提出2+5的问题，并且每次都解决为答案7，那么该机器在该计算中是100%准确和可靠的。然而，如果它一半时间回答为7，另一半时间回答为随机数字，那么即使它一半时间回答正确，也不被认为是足够可靠的。
- en: OpenAI researchers were able to accurately predict at least some of GPT-4’s
    performance, which is a major achievement in AI development. To get to that enviable
    point, OpenAI researchers spent the past two years rebuilding their entire deep
    learning stack and codesigning a supercomputer with Microsoft, as described in
    [Chapter 2](index_split_004.html#filepos95605). They used this method also to
    produce the GPT-3.5 upgrade, which OpenAI explains was a “first test run” of the
    GPT-4 model to work out the bugs and improve its foundations.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI的研究人员能够准确预测GPT-4的一些性能，这是人工智能发展的一个重大成就。为了达到这一令人羡慕的地步，OpenAI的研究人员花了过去两年重建他们整个深度学习堆栈，并与微软共同设计了一台超级计算机，如[第2章](index_split_004.html#filepos95605)所述。他们还使用这种方法来生产GPT-3.5升级，OpenAI解释说这是GPT-4模型的“第一次测试运行”，以解决错误并改善其基础。
- en: The company released GPT-4's text input capabilities via ChatGPT and the API.
    OpenAI collaborated with a partner, Be My Eyes, to aid with the image input capability
    via the Virtual Volunteer tool, which Be My Eyes used GPT-4 to build. It’s a real-world
    realization of the classic idiom “one hand washes the other and both wash the
    face.”
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 公司通过ChatGPT和API发布了GPT-4的文本输入功能。OpenAI与合作伙伴Be My Eyes合作，通过虚拟志愿者工具帮助实现图像输入功能，Be
    My Eyes使用GPT-4构建了该工具。这是经典谚语“一手洗另一手，两手一起洗脸”的现实实现。
- en: As a recap of ChatGPT model performance measures, consider the comparative ratings
    with state-of-the-art (SOTA) models in [Figure 4-4](#filepos188299).
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为对ChatGPT模型性能指标的回顾，请考虑与最先进（SOTA）模型的比较评级在[图4-4](#filepos188299)中。
- en: '![](images/00044.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00044.jpg)'
- en: '[FIGURE 4-4:](#filepos188185) Comparison of ChatGPT models using traditional
    benchmarks provided by OpenAI.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-4：](#filepos188185) 比较使用OpenAI提供的传统基准测试的ChatGPT模型。'
- en: Adjusting to GPT-4's Limitations
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 适应GPT-4的限制
- en: GPT-4 also has limitations. It can still hallucinate, that is, deliver information
    as facts that are not facts and make reasoning errors accordingly. Even so, the
    frequency of hallucinatory events is greatly decreased. GPT-4 consistently scores
    40 percent higher than GPT-3.5 on OpenAI’s internal adversarial factuality evaluations
    (battling AI models that test each other's results; think of it as very fast adversarial
    fact-checking).
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-4也有局限性。它仍然可能产生幻觉，即提供不实际为事实的信息并相应地出现推理错误。尽管如此，幻觉事件的频率大大降低。GPT-4在OpenAI内部对抗事实性评估中的得分始终比GPT-3.5高出40%。
- en: GPT-4 is blind to current events and information, given its data age is cut
    off at September 2021\. In other words, its database is largely comprised of data
    scraped from the internet up until that date and has not been updated as of this
    writing. For ChatGPT-4, which is built on GPT-4, to consider recent data or data
    not available on the internet, you must enter that data in the prompt, use a specialized
    plug-in such as Wolfram or Zapier, or use the Browsing plug-in to connect ChatGPT-4
    to the live internet.
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 鉴于其数据截止日期为2021年9月，GPT-4对当前事件和信息视而不见。换句话说，其数据库主要由截至该日期从互联网上抓取的数据组成，并且截至目前为止尚未更新。对于建立在GPT-4上的ChatGPT-4，要考虑最新数据或互联网上不可用的数据，您必须在提示中输入该数据，使用专门的插件（如Wolfram或Zapier），或使用浏览插件将ChatGPT-4连接到实时互联网。
- en: GPT-4 is highly confident in its answers. However, it doesn't always double-check
    its work for errors, so it can hallucinate (be highly confident of an answer that
    is provably wrong).
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-4对其答案非常自信。然而，它并不总是为了错误而再次检查其工作，因此它可能会产生幻觉（对一个明显错误的答案非常自信）。
- en: Risks common to all AI models are increased by virtue of GPT-4's increase in
    scalability — a reference to the sheer size of the database, model parameters,
    and number of users. However, these risks are known and OpenAI lessens their effect
    in GPT-4 through the addition of several safety properties and model-level interventions.
    It can still be manipulated to behave badly, but OpenAI is steadily working to
    make this much harder to do with each new iteration.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有AI模型普遍存在的风险因GPT-4的可扩展性增加而增加 — 这指的是数据库规模、模型参数和用户数量的庞大。然而，这些风险是已知的，OpenAI通过增加几项安全属性和模型级干预来减轻GPT-4中的影响。它仍然可以被操纵以表现不佳，但OpenAI正在稳步努力使每一次新迭代都更难做到这一点。
- en: OpenAI uses OpenAI Evals, which is the framework for creating and running benchmarks
    for evaluating AI models such as GPT-4\. OpenAI recently open-sourced this framework
    to enable crowdsourcing and sharing of benchmarks to produce more reliable AI
    models through better testing and training.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI使用OpenAI Evals，这是用于创建和运行评估AI模型（如GPT-4）基准测试的框架。OpenAI最近开源了这个框架，以便通过更好的测试和训练进行众包和共享基准测试，从而产生更可靠的AI模型。
- en: Users should take care to fact-check outputs by any ChatGPT model. But this
    extra step isn’t so different from checking your own work or someone else's prior
    to publishing or moving to production, now is it?
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用户应该注意通过任何ChatGPT模型的输出进行事实核查。但这一额外步骤与在发布或投入生产之前检查自己的工作或他人的工作并没有太大不同，对吧？
- en: As of this writing, OpenAI has not made entering images in the prompt an available
    option for the public. This feature is currently being tested by select users
    and developers. There is a developer waitlist for the API in anticipation of a
    future rollout date.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 截至目前，OpenAI尚未使公众能够在提示中输入图像成为可用选项。这一功能目前正在由特定用户和开发人员进行测试。有一个API的开发者等待列表，以期待未来的发布日期。
