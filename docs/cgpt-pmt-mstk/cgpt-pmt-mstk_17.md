| ![图像](img/chapter_title_corner_decoration_left.png) |  | ![图像](img/chapter_title_corner_decoration_right.png) |
| --- | --- | --- |

![图像](img/chapter_title_above.png)

# 固有偏见

![图像](img/chapter_title_below.png)

ChatGPT 可能会无意中再现其训练数据中存在的偏见，比如性别、种族或政治偏见。这是由于在训练过程中其接触到了来自互联网的大量多样化文本数据。

解决方案：意识到这个局限性，并谨慎对待模型的输出，特别是在敏感的情境中。
