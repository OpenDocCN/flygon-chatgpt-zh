# 1 生成模型是什么？

## 加入我们的书籍社区Discord

[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)

![自动生成的二维码描述](../media/file0.png)

**人工智能**（**AI**）取得了重大进展，影响着企业、社会和个人。在过去的十年左右，深度学习已经发展到可以处理和生成文本、图像、视频等非结构化数据。这些基于深度学习的先进AI模型在各行各业中备受青睐，包括**大型语言模型**（**LLMs**）。目前，媒体和行业对AI存在相当大的炒作。这是由多种因素驱动的，包括技术的进步、知名应用以及在多个领域产生变革性影响的潜力。在本章中，我们将讨论生成模型，特别是LLMs，以及它们在文本、图像、声音和视频等领域的应用。我们将介绍一些技术背景，解释它们的工作原理以及它们是如何训练的。我们将从介绍开始，澄清我们在技术发展的最前沿所处的位置，以及炒作的原因。

## 为什么会有这样的炒作？

媒体广泛报道了与AI相关的突破性进展及其潜在影响。这些进展涵盖了从自然语言处理和计算机视觉的进步到像GPT-3这样的复杂语言模型的发展。媒体经常强调AI的能力以及其颠覆性潜力，例如在医疗保健、金融、交通等行业的革新。特别是，生成模型因其能够生成文本、图像和其他创意内容（往往难以与人类生成的内容区分开）而受到了广泛关注。这些模型还提供了广泛的功能，包括语义搜索、内容操作和分类。这可以通过自动化实现成本节约，并使人类能够以前所未有的水平发挥创造力。这张图表受到了Stephen McAleese在LessWrong上关于GPT-4预测的博文的启发，展示了LLMs在**大规模多任务语言理解**（**MMLU**）基准测试中的改进，该测试旨在量化基本数学、美国历史、计算机科学、法律等领域的知识和问题解决能力。

![图1.1：大型语言模型（LLM）在大规模多任务语言理解（MMLU）基准测试中的平均表现。请注意，大多数基准测试结果来自5-shot，少数GPT-2、PaLM和PaLM-2的结果是指微调模型。](../media/file1.png)

图1.1：大型语言模型（LLM）在大规模多任务语言理解（MMLU）基准测试中的平均表现。请注意，大多数基准测试结果来自5-shot，少数GPT-2、PaLM和PaLM-2的结果是指微调模型。

近年来在基准测试中可以看到进展。特别值得强调的是OpenAI通过公共用户界面提供的模型的进步，特别是从GTP-2到GPT-3再到GPT-3.5再到GPT-4的改进。这些模型最近才开始表现优于平均人类评分者，但仍未达到人类专家的水平。这些人类工程的成就令人印象深刻；然而，应该注意到这些模型的表现取决于领域；大多数模型在小学数学单词问题的GSM8K基准测试中仍表现不佳。

> **OpenAI**是一个旨在推广和发展友好人工智能的美国人工智能研究实验室。它成立于2015年，得到了几位有影响力的人物和公司的支持，他们承诺向这个项目投资超过10亿美元。该组织最初致力于非营利性，通过向公众开放其专利和研究成果与其他机构和研究人员合作。2018年，埃隆·马斯克因担心与特斯拉的角色存在潜在利益冲突而辞去了董事会职务。2019年，OpenAI转变为营利性组织，随后微软对OpenAI进行了重大投资，导致OpenAI系统与微软基于Azure的超级计算平台以及必应搜索引擎的整合。该公司最重要的成就包括用于训练强化学习算法的OpenAI Gym，以及最近推出的GPT-n模型和DALL-E，另一个能够从文本生成图像的深度学习模型。

**生成式预训练变换器**（**GPT**）模型，如最近推出的OpenAI的ChatGPT，是LLM领域人工智能进步的典范。ChatGPT通过在更大规模上训练并比以往模型更大，极大地提升了聊天机器人的能力。这些基于人工智能的聊天机器人可以生成类似人类的实时反馈给客户，并可应用于从软件开发和测试到诗歌和商业沟通等各种用例。在行业内，人们对人工智能的能力和其对业务运营的潜在影响感到越来越兴奋。我们将在*第10章*，*生成模型的未来*中更详细地探讨这一点。随着OpenAI的GPT等人工智能模型的不断改进，它们可能成为需要多样知识和技能的团队不可或缺的资产。例如，GPT-4可以被视为一个“博学多才”的人工智能，可以在不要求报酬（除了订阅或API费用）的情况下不知疲倦地工作，在数学、语言、统计学、宏观经济学、生物学甚至通过司法考试等学科提供帮助。随着这些人工智能模型变得更加熟练和易于访问，它们可能在塑造未来工作和学习方面发挥重要作用。通过使知识更易获取和适应，这些模型有潜力拉平竞争场地，为来自各行各业的人们创造新机会。这些模型在需要更高层次推理和理解的领域显示出潜力，尽管进展因所涉及任务的复杂性而有所不同。至于具有图像的生成模型，我们可以期待具有更好能力的模型协助创建视觉内容，并可能改进计算机视觉任务，如目标检测、分割、字幕等等。让我们更清晰地澄清术语，并更详细地解释生成模型、人工智能、深度学习和机器学习的含义。

### 生成模型是什么？

在媒体上，当提到这些新模型时，经常使用术语人工智能。值得更清楚地区分一下生成模型这个术语与人工智能、深度学习、机器学习和语言模型的区别：

+   **人工智能**（**AI**）是计算机科学的一个广泛领域，涉及创建智能代理的系统，这些系统可以自主推理、学习和行动。

+   **机器学习**（**ML**）是人工智能的一个子集，涉及开发能够从数据中学习的算法。机器学习算法在一组数据上进行训练，然后可以使用该数据进行预测或决策。

+   **深度学习**（**DL**）是机器学习的一个子集，它使用人工神经网络从数据中学习。神经网络受人脑启发，能够从数据中学习复杂模式。

+   **生成模型**是一种可以生成新数据的ML模型。生成模型在一组数据上进行训练，然后它们可以利用该数据创建类似于训练数据的新数据。

+   **语言模型**是预测序列中的标记（通常是单词）的统计模型。其中一些模型，能够执行更复杂的任务，包含许多参数（数量达到数十亿甚至数万亿），因此被称为**大型语言模型**。

生成模型与其他类型的ML模型的主要区别在于，生成模型不仅仅是做出预测或决策。它们实际上可以创建新数据。这使得生成模型非常强大，可以用于各种任务，如生成图像，文本，音乐和视频。以下是总结AI，ML，DL，语言模型和生成模型之间区别的表格：

| **术语** | **定义** |
| --- | --- |
| 人工智能 | 一门涉及智能代理创建的计算机科学广泛领域。 |
| 机器学习 | 处理可以从数据中学习的算法开发的AI的一个子集。 |
| 深度学习 | 使用人工神经网络从数据中学习的ML的一个子集。 |
| 生成模型 | 一种可以生成新数据的ML模型。 |
| 语言模型 | 一种模型，现在主要是深度学习模型，可以预测上下文中的标记。 |

图1.2：术语 - 人工智能，机器学习，深度学习和生成模型。生成模型是一种强大的AI类型，可以生成类似于训练数据的新数据样本。生成AI模型已经取得了长足的进步，通过数据中的模式生成新的示例。这些模型可以处理不同类型的数据，并在各个领域中使用，包括文本生成，图像生成，音乐生成和视频生成。对于语言模型，重要的是要注意，其中一些模型，特别是新一代的模型，是生成型的，可以生成语言（文本），而其他模型则不是。这些生成模型有助于创建**合成数据**来训练AI模型，当真实数据稀缺或受限时。这种数据生成方式降低了标记成本并提高了训练效率。微软研究采用了这种方法（“只需教科书”，2023年6月）来训练他们的phi-1模型，他们使用GPT-3.5创建了合成教科书和练习作为他们的训练数据集。在接下来的章节中，我们将探讨生成模型的不同领域，如文本，图像，声音，视频。这些应用主要围绕内容生成，编辑和处理（识别）。让我们从文本开始！

### 文本

文本生成，例如OpenAI的GPT-4，可以生成连贯和语法正确的诗歌，或者用不同语言编写代码并提取关键词和主题等特征。这些模型在内容创作和**自然语言处理**（**NLP**）等领域具有实际应用，其最终目标是创建能够解释人类语言的算法。语言建模旨在根据序列中的前一个词、字符甚至句子来预测下一个词。在这个意义上，语言建模作为一种将语言的规则和结构编码成机器可理解的方式。大型语言模型捕捉了人类语言的语法、句法和语义结构。这些模型很重要，因为它们构成了许多更大的NLP任务的基础，如内容创作、翻译、摘要、机器翻译和文本编辑任务，如拼写纠正。在其核心，语言建模，以及更广泛的自然语言处理，严重依赖于表示学习的质量。一个训练良好的语言模型对其训练的文本编码信息，并根据这些学习生成新文本，从而承担文本生成的任务。最近，大型语言模型已经应用于文章生成、代码开发、翻译和理解基因序列等任务。语言模型的更广泛应用涉及多个领域，例如：

+   **问答系统**：AI聊天机器人和虚拟助手可以提供个性化和高效的帮助，减少客户支持中的响应时间，从而增强客户体验。这些系统可用于解决特定问题，如餐厅预订和购票。

+   **自动摘要**：语言模型可以创建文章、研究论文和其他内容的简洁摘要，使用户能够快速消化和理解信息。

+   **情感分析**：通过分析文本中的意见和情感，语言模型可以帮助企业更有效地理解客户反馈和意见。

+   **主题建模**和**语义搜索**：这些模型可以识别、按主题分类和压缩文档为简洁向量，使组织更容易进行内容管理和发现。

+   **机器翻译**：由人工智能驱动的语言模型可以将一种语言的文本翻译成另一种语言，支持企业在全球扩张努力中。新的生成模型可以与商业产品（例如谷歌翻译）竞争。

尽管取得了显著的成就，语言模型在处理复杂的数学或逻辑推理任务时仍面临限制。目前尚不清楚不断增加语言模型规模是否必然会导致新的推理能力。正如前文所述，我们还必须考虑数据质量和规模的重要性，因为这些因素在改善语言模型在不同任务和领域中的性能方面起着重要作用。生成模型的另一个领域是图像生成，让我们看看这是怎么回事！

### 图像

生成人工智能广泛用于生成3D图像、头像、视频、图表、虚拟或增强现实中的插图、视频游戏图形设计、标志创建、图像编辑或增强。这张图展示了从具有稳定扩散的文本提示生成图像（来源：“改进生成过程的重新启动采样”作者为Yilun Xu等人，来自麻省理工学院和谷歌研究，2023年6月；https://arxiv.org/pdf/2306.14878.pdf）：

![图1.3：从文本提示“由玻璃制成的透明鸭子雕塑”生成图像。](../media/file2.png)

图1.3：从文本提示“由玻璃制成的透明鸭子雕塑”生成图像。

使用稳定扩散模型，您可以看到仅通过对模型的初始设置进行最小更改或者 - 如本例中 - 数值求解器和采样器，就可以看到各种各样的结果。尽管它们有时会产生引人注目的结果，但这种不稳定性和不一致性是将这些模型更广泛应用的重要挑战。像**MidJourney**、**DALL-E 2**和**Stable Diffusion**这样的服务提供了从文本输入或其他图像派生的创意和逼真图像。像**DreamFusion**、**Magic3D**和**Get3D**这样的服务使用户能够将文本描述转换为3D模型和场景，推动设计、游戏和虚拟体验的创新。主要有三个应用场景：

1.  **图像生成**：模型可以生成各种图像，如绘画、照片和草图。这可以用于各种目的，如创作艺术、设计产品和生成逼真的视觉效果。

1.  **图像编辑**：模型可以执行诸如移除对象、更改颜色和添加效果等任务。这可以用于提高图像质量，并使其更具视觉吸引力。

1.  **图像识别**：大型基础模型可用于识别图像，包括场景分类，还有物体检测，例如检测人脸。

像生成对抗网络（GANs）和 DALL-E 这样的模型。GANs 生成逼真的图像，具有许多商业应用，而 DALL-E 则根据文本描述创建图像，对于设计广告、产品和时尚等创意产业非常有帮助。图像编辑涉及通过改变内容或样式属性来修改图像的语义，使用面部属性编辑或图像变形等技术。基于优化和学习的方法通过使用预训练的 GAN 模型（如 StyleGAN）的潜在表示生成具有风格的图像。扩散模型最近被用于高级图像编辑任务，例如通过文本引导无缝连接手动设计的遮罩区域或生成 3D 对象操作。这些技术实现了灵活的图像生成，但面临着有限多样性问题，可以通过将其他文本输入纳入过程中来缓解。图像编辑的范畴还包括图像恢复等任务，这意味着从受损版本中恢复清晰图像，包括图像超分辨率、修补、去噪、去雾和去模糊等任务。基于深度学习的方法使用 CNN 和 transformer 架构，由于与传统方法相比具有更优越的视觉质量。生成模型如 GANs 和扩散模型（DMs）用于恢复，但可能遭受复杂的训练过程和模式崩溃。多扭曲数据集和具有注意力模块或引导子网络的单网络方法提高了处理多种退化类型的效果。接下来我们将看看模型可以如何处理声音和音乐。

### 声音和音乐

生成模型可以根据文本输入开发歌曲和音频剪辑，识别视频中的物体并创建相应的音频，以及创作定制音乐。我们可以粗略地将应用程序再次分类为生成、编辑和识别：

+   **音乐生成**：生成模型可用于生成音乐，如歌曲、节拍和旋律。这可以用于各种目的，如创作新音乐、谱写配乐和生成个性化播放列表。

+   **声音编辑**：生成模型可用于编辑声音，如消除噪音、改变音调和添加效果。这可以用于提高声音质量，并使其在听觉上更具吸引力。

+   **声音识别**：生成模型可用于识别声音，如识别乐器、分类流派和检测语音。这可以用于各种目的，如音乐分析、搜索和推荐系统。

音乐生成算法始于20世纪50年代的算法作曲，并见证了像谷歌的WaveNet和OpenAI的Jukebox这样的最新创新。这些模型导致了AI作曲助手的出现，可以以各种风格生成音乐，并实现新的应用，如语音合成。作��一个特例，语音到文本生成，也称为**自动语音识别**（**ASR**），是将口语转换为文本的过程。它们是在声音和文本上进行训练的。ASR系统变得越来越准确，现在被广泛应用于各种应用中。然而，仍然存在一些需要解决的挑战，比如处理嘈杂环境和不同口音的能力。随着许多潜在应用，如语音拨号和像Alexa和Siri这样的计算机辅助个人助手，ASR背后的技术从马尔可夫模型发展到依赖于GPT。接下来我们将看到视频。

### 视频

视频生成模型，如**DeepMind**的Motion to Video和**NVIDIA**的**Vid2Vid**依赖于**GANs**进行高质量视频合成。它们可以在不同领域之间转换视频，修改现有视频，并使静态图像动画化，展示了视频编辑和媒体制作的巨大潜力。像Make-a-Video和Imagen Video这样的工具将自然语言提示转换为视频片段，简化了视频制作和内容创作过程。这些应用的广泛类别是：

+   **视频生成**：生成模型可以用于生成视频，如短片、动画和广告。这可以用于创作新内容、广告产品和生成逼真的视觉效果。

+   **视频编辑**：我们可以编辑视频，如移除物体、更改颜色和添加效果。这可以帮助提高视频质量，并使其更具视觉吸引力。

+   **视频识别**：模型可以识别视频，如识别物体、分类场景和检测人脸。这可以帮助应用于安全、搜索和推荐系统等领域。

一些模型可以在多个领域或模态中生成内容。这些被称为多模型。

### 多模

多模生成模型可以生成**文本**、**图像**、**声音**和**视频**。这使它们能够创造更加逼真和沉浸式的体验。多模型仍处于发展的早期阶段，但它们有潜力彻底改变我们与计算机互动和体验世界的方式。例如，这些进展显著提高了图像字幕任务的性能，即通过自然语言描述图像内容的过程。多模型采用融合图像和字幕的生成架构，形成一个共享学习空间的单一模型。这个过程涉及两步编码器-解码器架构：视觉编码和语言解码。我们可以区分这些潜在的用例：

+   **虚拟现实**：这些模型可以用来创建更加逼真和沉浸式的虚拟现实体验。这对于游戏、教育和培训都有帮助。

+   **增强现实**：它们可以创建增强现实体验，将数字内容叠加在现实世界上。这对于导航、购物和娱乐都是有用的。

在接下来的部分，我们将讨论大型语言模型的技术背景。

## 什么是 GPT？

**大型语言模型**（**LLMs**）是深度训练的神经网络，擅长理解和生成人类语言。当前一代的LLMs，如ChatGPT，是利用Transformer模型的深度神经网络架构，在广泛的文本数据上进行无监督学习的预训练，使其能够学习语言模式和结构。最新一代LLMs的显著优势在于作为对话接口（ChatBot）时，能够生成连贯和上下文适当的回应，即使在开放式对话中也是如此。通过基于前面的单词生成下一个单词，该模型经常产生流畅和连贯的文本，往往难以与人类产生的文本区分开。然而，OpenAI在免责声明中表达了ChatGPT“有时会写出听起来合理但不正确或荒谬的答案”的观察。这被称为幻觉，这只是围绕LLMs的关注之一。**Transformer**是一种深度学习架构，于2017年首次由谷歌和多伦多大学的研究人员引入（在一篇名为“注意力机制是你所需要的一切”的文章中），它包括自注意力和前馈神经网络，使其能够有效地捕捉句子中的单词关系。注意机制使模型能够专注于输入序列的不同部分。**生成式预训练变换器**（**GPTs**）是由OpenAI的研究人员于2018年推出的，与他们的首个同名GPT模型GPT-1一起发布，并发表为“通过生成式预训练改进语言理解”。预训练过程涉及预测文本序列中的下一个单词，增强模型对语言的理解，这可以通过输出质量来衡量。在预训练之后，模型可以针对特定的语言处理任务进行微调，如情感分析、语言翻译或聊天。无监督和监督学习的结合使GPT模型在各种NLP任务中表现更好，并减少了训练LLMs所面临的挑战。LLMs的训练语料库规模急剧增加。OpenAI于2018年推出的GPT-1是在包含985百万个单词的BookCorpus上进行训练的。BERT在同一年发布，是在**BookCorpus**和**英文维基百科**的合并语料库上进行训练的，总计**33亿个单词**。现在，LLMs的训练语料库已经扩展到数万亿个标记。这张图说明了LLMs的规模一直在不断增长：

![图1.4：从BERT到GPT-4的大型语言模型 - 大小、训练预算和组织。](../media/file3.png)

图1.4：从BERT到GPT-4的大型语言模型 - 大小、训练预算和组织。

数据点的大小表示以petaFLOP天为单位的训练成本。对于一些模型，特别是专有和闭源模型，这些信息是未知的 - 在这些情况下，我放了一个叉。例如，对于XLNet，论文没有提供有关flops计算的信息，然而，训练是在512个TPU v3芯片上进行的，历时2.5天。数据点的颜色显示了开发模型的公司或组织 - 由于这些颜色可能在打印版或Kindle上不明显（除非您有一款彩色Kindle），您可以在此URL找到此图的彩色版本：GPT模型的发展取得了显著进展，OpenAI的GPT-n系列引领着创建基础AI模型的道路。LLM的训练语料库规模急剧增加。OpenAI于2018年推出的GPT-1是在包含985百万个单词的BookCorpus上进行训练的。BERT于同一年发布，是在BookCorpus和英文维基百科的合并语料库上进行训练的，总计33亿个单词。现在，LLM的训练语料库已经扩展到数万亿个标记。

> **基础模型**（有时称为基础模型）是一个大型模型，它在规模上经过大量数据的训练，以便可以适应各种下游任务。在GPT模型中，这种预训练是通过自监督学习完成的。

经过对3000亿标记的训练，**GPT-3**拥有**1750亿参数**，这是深度学习模型中前所未有的规模。**GPT-4**是该系列中最新的版本，尽管由于竞争和安全问题，其规模和训练细节尚未公布，但不同的估计将其参数放在**200到5000亿之间**。*Sam Altman*，OpenAI的首席执行官表示，训练**GPT-4**的成本超过了1亿美元。ChatGPT是一个对话模型，由**OpenAI**于2022年11月发布。基于之前的**GPT**模型（特别是**GPT-3**）并针对对话进行了优化，它使用人类生成的角色扮演对话和人类标记者演示所需模型行为的数据集。该模型展示了出色的能力，如广泛的知识保留和在多轮对话中精确的上下文跟踪。另一个重大进展是**GPT-4**，于2023年3月推出，它不仅限于文本输入，还包括多模态信号。**GPT-4**在各种评估任务上表现出优越的性能，同时由于训练期间六个月的迭代对齐，对恶意或挑衅性查询的响应避免能力显著提高。除OpenAI之外，其他值得注意的基础GPT模型还包括谷歌的**PaLM2**。尽管**GPT-4**在性能方面领先大多数基准测试，但这些和其他模型在某些任务中表现出可比较的性能，并促进了基于生成变压器的语言模型的进步。Meta的**LLaMA**训练了**1.4万亿标记**，而谷歌聊天机器人**Bard**背后的模型**PaLM2**由**3400亿参数**组成，比以前的LLM规模小，但在至少100种语言的训练数据上似乎具有更大的规模。

> 有相当多的**公司和组织正在开发LLM**，并以不同的条件发布它们。OpenAI发布了GPT-2，随后的模型是闭源的，但可以通过他们的网站或API使用。Meta发布了从RoBERTa、BART到LLaMA的模型，包括模型的参数（权重），尽管在非商业许可下，以及用于设置和训练模型的源代码。Google AI及其DeepMind部门开发了许多大型语言模型，包括BERT、GPT-2、LaMDA、Chinchilla、Gopher、PaLM和PaLM2。他们已经在开源许可下发布了一些模型的代码和权重，尽管最近他们在开发中更趋向于保密。微软开发了许多大型语言模型，包括Turing NLG和Megatron-Turing NLG，但他们已将OpenAI模型整合到Microsoft 365和必应中。阿布扎比政府资助的科技创新研究所（TII）已经为研究和商业用途开源了Falcon LLM。

GPT模型还可以处理文本以外的输入和输出形式，正如GPT-4能够处理图像输入和文本一样。此外，它们还为文本到图像技术（如扩散和并行解码）奠定了基础，从而实现了与图像一起工作的**视觉基础模型**（**VFMs**）的发展。总之，GPT模型发展迅速，为创建适用于各种下游任务和形式的多功能基础人工智能模型奠定了基础，最终推动了各种应用和行业的创新。在接下来的部分中，我们将回顾深度学习和生成模型近年来取得的进展，这些进展导致了明显能力的爆炸性增长以及这些模型所受到的关注。

### 为什么现在？

2022年生成式人工智能成功进入公众视野的原因可以归因于几个相互关联的推动因素。生成模型的发展和成功依赖于改进的算法、计算能力和硬件设计的显著进步、大规模标记数据集的可用性，以及积极合作的研究社区帮助发展一套工具和技术。更复杂的数学和计算方法的发展在生成模型的进步中发挥了至关重要的作用。上世纪80年代由杰弗里·辛顿、大卫·鲁梅尔哈特和罗纳德·威廉姆斯引入的反向传播算法就是一个例子。它提供了一种有效训练多层神经网络的方法。在21世纪初，**神经网络**开始重新流行，研究人员开发了更复杂的架构。然而，深度学习的出现，一种具有众多层的神经网络，标志着这些模型性能和能力的重大转折点。有趣的是，尽管深度学习的概念已存在一段时间，但生成模型的发展和扩展与硬件的显著进步相关，特别是**图形处理单元**（**GPU**），这些硬件在推动该领域向前发展方面起到了关键作用。正如前面提到的，更便宜和更强大的硬件的可用性是发展更深层模型的关键因素。这是因为深度学习模型需要大量的计算能力来训练和运行。这涉及到处理能力、内存和磁盘空间的所有方面。这张图显示了随着时间推移，不同介质（如磁盘、固态、闪存和内存）的计算机存储成本，以每TB美元的价格计算（来源：Our World in Data；[https://ourworldindata.org/moores-law](https://ourworldindata.org/moores-law)）：

![图1.5：自1950年代以来每TB的计算机存储成本。](../media/file4.png)

图1.5：自1950年代以来每TB的计算机存储成本。

过去，训练深度学习模型的成本非常昂贵，但随着硬件成本的降低，现在可以在更大的数据集上训练更大的模型。模型大小是决定模型能够多好地逼近（以困惑度衡量）训练数据集的因素之一。

> **LLM中参数数量的重要性**：模型的参数越多，其捕捉单词和短语之间关系的能力就越强。举个简单的例子来说明这些高阶相关性，LLM可以学习到单词“猫”如果前面是“追逐”这个词，那么后面更可能是“狗”，即使中间有其他词。一般来说，模型的困惑度越低，它的表现就越好，比如在回答问题方面。特别是，在由20亿到70亿参数组成的模型中，似乎会出现新的能力，比如生成不同的创意文本格式，如诗歌、代码、脚本、音乐作品、电子邮件、信件，并以信息丰富的方式回答问题，即使这些问题是开放性和具有挑战性的。

这种朝着更大模型的趋势始于2009年，当Nvidia推动了深度学习的“大爆炸”。GPU特别适合进行训练深度学习神经网络所需的矩阵/向量计算，因此显著提高了这些系统的速度和效率，将运行时间从几周缩短到几天。特别是，Nvidia的**CUDA**平台允许直接编程GPU，使研究人员和开发人员可以更轻松地尝试和部署复杂的生成模型。在2010年代，不同类型的生成模型开始受到关注。自编码器是一种可以学习将数据从输入层压缩到表示层，然后重构输入的神经网络，为更高级的模型如2013年首次提出的**变分自编码器**（**VAEs**）奠定了基础。**VAEs**与传统自编码器不同，它使用变分推断来学习数据的分布，也称为输入数据的潜在空间。与此同时，**生成对抗网络**（**GANs**）在2014年由Ian Goodfellow等人提出。训练GANs的设置如下图所示（摘自“使用生成对抗网络进行文本生成的调查”，G de Rosa和J P. Papa，2022年；[https://arxiv.org/pdf/2212.11119.pdf](https://arxiv.org/pdf/2212.11119.pdf)）：

![图1.6：生成对抗网络（GAN）训练。](../media/file5.png)

图1.6：生成对抗网络（GAN）训练。

GANs由两个网络组成，在类似游戏的设置中相互对抗 - 生成器生成新数据，通常是图像，鉴别器估计新数据为真实数据的概率。随着它们相互竞争，GANs在任务中变得更加优秀，能够生成逼真的图像和其他类型的数据。在过去的十年中，深度学习中使用的基本算法取得了重大进展，如更好的优化方法，更复杂的模型架构和改进的正则化技术。Transformer模型于2017年推出，建立在这一进展的基础上，实现了像GPT-3这样的大规模模型的创建。Transformers依赖于注意力机制，并导致生成模型性能的进一步飞跃。这些模型，如谷歌的BERT和OpenAI的GPT系列，可以生成高度连贯和上下文相关的文本。迁移学习技术的发展也是显著的，它允许在一个任务上预训练的模型在另一个类似任务上进行微调，这些技术使训练大型生成模型更加高效和实用。此外，生成模型的崛起部分归因于专门设计用于处理这些人工神经网络的软件库和工具（**TensorFlow**，**PyTorch**，**Keras**），简化了构建、训练和部署它们的过程。为了进一步推动生成模型的发展，研究界定期举办像ImageNet这样的图像分类挑战赛，并已开始为生成模型做同样的事情，如生成对抗网络（GAN）竞赛。除了更便宜和更强大的硬件的可用性外，标记数据的大型数据集的可用性也是生成模型发展的关键因素。这是因为深度学习模型，特别是生成模型，需要大量的文本数据进行有效训练。互联网上数据的爆炸性增长，尤其是在过去的十年中，为这些模型蓬勃发展创造了适当的环境。随着互联网的普及，收集大量文本、图像和其他数据集变得更加容易。这使得在比过去可能的更大数据集上训练生成模型成为可能。总之，生成建模是一个迷人且快速发展的领域。它有潜力彻底改变我们与计算机的互动方式以及我们创造新内容的方式。我很期待看到这个领域的未来。让我们深入了解细节 - 这是如何工作的？

### 这是如何工作的？

诸如BERT和GPT之类的模型得以实现，得益于**Transformer**深度神经网络架构，这对自然语言处理产生了深远影响。Transformer架构旨在避免递归，以允许并行计算，不同变体的Transformer架构不断推动自然语言处理和生成式人工智能领域的可能性边界。Transformer的一个显著特征是注意力机制。传统的序列到序列模型经常面临处理长依赖性的问题 - 如果序列过长，它们很难记住相关信息。Transformer模型引入了注意力机制来解决这个问题。自注意力机制，通常被称为Transformer模型的核心，为序列中的每个单词分配一个分数，确定应该给予该单词多少关注。Transformer由可以堆叠的模块组成，从而创建可以学习大规模数据集的非常大的模型。这些在这里的图表中指示出来：

![图1.7：Transformer架构（来源：Yuening Jia，Wikimedia Commons）](../media/file6.png)

图1.7：Transformer架构（来源：Yuening Jia，Wikimedia Commons）

促成Transformer成功的架构特征：

+   **编码器-解码器结构**：Transformer模型遵循编码器-解码器结构。编码器接受输入序列并为每个单词计算一系列表示（上下文嵌入）。这些表示不仅考虑单词的固有含义（语义值），还考虑它们在序列中的上下文。解码器然后使用这些编码信息逐个生成输出序列项，利用先前生成项的上下文。

+   **位置编码**：由于Transformer不是按顺序处理单词，而是同时处理所有单词，它缺乏单词顺序的概念。为了弥补这一点，将单词在序列中的位置信息通过位置编码注入模型中。这些编码被添加到表示每个单词的输入嵌入中，从而使模型能够考虑序列中单词的顺序。

+   **层归一化**：为了稳定网络的学习，Transformer使用一种称为层归一化的技术。这种技术在特征维度上对模型的输入进行归一化（而不是批量维度，如批量归一化），从而提高了学习的整体速度和稳定性。

+   **多头注意力**：Transformer不是一次应用注意力，而是并行多次应用注意力 - 提高了模型关注不同类型信息的能力，从而捕捉到更丰富的特征组合。

另一个可选的架构特性，不特定于变压器的是跳跃连接（也称为残差连接）。这些被引入以减轻网络变得更深时的退化问题，使用了跳跃连接。这允许梯度在层间不变地流动，通过将输入直接传递给更深的层。变压器在自然语言处理中推动了NLP的发展，特别是在翻译和语言理解方面。**神经机器翻译**（**NMT**）是一种使用深度学习捕捉句子中长距离依赖关系的机器翻译主流方法。基于变压器的**NMT**优于以往的方法，如使用循环神经网络，特别是**长短期记忆**（**LSTM**）网络。这可以归因于这种强大的架构，首先是注意力，它允许变压器模型以灵活的方式处理单词顺序，无论它们之间有多远，这对每种特定情况都是最佳的。此外，这些架构特性的组合使其能够成功处理涉及理解和生成人类语言以及其他领域的任务。OpenAI强大的用于语言生成的GPT模型也是一个变压器，同样，DeepMind的AlphaFold 2是一个从基因序列预测蛋白质结构的模型。变压器能够比其他模型更好地在较长序列上保持性能，例如循环神经网络。这一直是它们成功的原因，然而，变压器架构意味着它们只能捕捉固定输入宽度内的依赖关系。早期的注意力机制随着数据点数量的平方级增长，使其在具有大量输入的情况下无法应用。已经提出了许多方法来获得效率提升，例如稀疏的、低秩的自注意力和潜在的瓶颈，仅举几例。其他工作尝试扩展超出固定输入大小的序列，如Transformer-XL架构通过存储已编码句子的隐藏状态来重新引入递归，以便在后续编码下一个句子时利用它们。GPT的特殊之处及其名称的起源在于预训练。让我们看看这些LLM是如何训练的！

#### 预训练

训练**大型语言模型**（**LLM**）的第一步是进行标记化。这个过程涉及将单词转换为数字，以便模型可以处理它们，因为**LLMs**是需要数字输入和输出的数学函数。为了进行这种标记化，**LLMs**使用独特的标记器。标记器将文本中的单词映射到相应的整数列表。在训练**LLM**之前，标记器通常会适应整个训练数据集，然后被冻结。常用的标记器类型是字节对编码。需要注意的是，标记器不会产生任意整数。相反，它们输出特定范围内的整数 - 从到，其中表示标记器的词汇量。现在，考虑输出，当LLM接收到文本时，主要产生一个落在的向量。然后，将该输出向量通过softmax函数传递，产生另一个向量，称为概率向量。由于其条目为非负且总和为，这个向量可以被解释为**LLM**词汇的概率分布。此外，需要指出**LLMs**只能基于不超过其上下文窗口的一系列标记生成标记。这个上下文窗口指的是**LLM**可以使用的最长标记序列的长度。如果提供了比这个窗口更长的序列，**LLM**需要截断序列或使用算法修改来处理它。**LLMs**的典型上下文窗口大小可以在大约1,000到10,000个标记之间。训练**LLMs**涉及特定的过程，将输入数据标记化，馈送到模型中，并生成一个概率分布，覆盖模型的词汇。这个过程中的具体机制，如softmax函数和上下文窗口，有助于促进**LLMs**对输入数据的理解和响应。**负对数似然**（**NLL**）和**困惑度**（**PPL**）是在训练和评估语言模型过程中使用的重要指标。**NLL**是机器学习算法中使用的损失函数，旨在最大化正确预测的概率。较低的**NLL**表示网络已成功从训练集中学习到模式，因此它将能够准确预测训练样本的标签。需要提到**NLL**是一个在正区间内约束的值。另一方面，**困惑度**（**PPL**）是**NLL**的指数，提供了更直观地理解模型性能的方式。较小的**PPL**值表示训练良好的网络可以准确预测，而较高的值表示学习性能差。直观地说，我们可以说低困惑度意味着模型对下一个词不太惊讶。因此，在预训练中的目标是最小化困惑度，这意味着模型的预测更符合实际结果。在比较不同的语言模型时，困惑度通常被用作各种任务的基准指标。它提供了关于语言模型表现如何的想法，较低的困惑度表示模型对其预测更有把握。因此，与困惑度较高的其他模型相比，困惑度较低的模型将被认为表现更好。

#### 缩放

至少简要讨论架构的选择以及为什么这些模型如此庞大是值得的。在2020年的一篇来自OpenAI的研究人员Kaplan等人的论文中，他们讨论了缩放定律和参数选择。有趣的是，他们比较了许多不同的架构选择，并且在其他方面表明，变压器在很大程度上由于更好地利用长上下文而优于**LSTMs**作为语言模型，而这些循环网络在不到100个标记后就达到了平稳状态，而变压器则通过整个上下文改进。因此，变压器不仅在训练和推理速度上比变压器更好，而且在查看相关上下文时也表现更好。此外，他们发现数据集大小、模型大小（参数数量）和训练计算量之间存在幂律关系，换句话说，为了将性能提高一定因子，其中一个因素必须按照该因子的幂进行扩展，然而，为了获得最佳性能，这三个因素必须同时扩展，以避免出现瓶颈效应。DeepMind的研究人员（Hoffmann等人，2022年）分析了**LLMs**的训练计算量和数据集大小，并得出结论，根据缩放定律，**LLMs**在计算预算和数据集大小方面训练不足。他们预测，如果大型模型比现在大大缩小并且训练时间更长，大型模型将表现更好，并且事实上，通过将**70亿参数的Chinchilla模型**与他们的Gopher模型（包含**2800亿参数**）在基准测试中进行比较，他们验证了他们的预测。最近，该团队发现，以更多的纪元进行更长时间的训练或以更多的petaflops进行更多的计算似乎不再改善性能，而较小的网络和更高质量的数据集可以提供非常有竞争力的性能。

#### 条件化

对大型语言模型进行条件化是指为特定任务调整模型。不同的条件化方法包括微调、提示、指令调整和强化学习：

+   微调涉及通过监督学习在特定任务上训练预训练的语言模型。例如，为了使模型更适合与人类对话，模型会在自然语言指令形式的任务示例上进行训练（指令调整）。

+   提示技术将问题呈现为文本提示，并期望模型完成。

对于微调，通常，强化学习将监督微调与使用人类反馈的强化学习相结合，根据人类偏好训练模型。LLMs可以在一个由LLM生成的示例训练集上进行训练（从一小部分人类生成的初始示例引导），例如Microsoft Research的phi-1的训练集（"只需教科书"，2023年6月）。通过提示技术，将呈现类似问题及其解决方案的文本示例。零-shot提示涉及没有解决的示例，而少量-shot提示包括少量类似（问题，解决方案）对的示例。这些调节方法不断发展，变得更加有效，对各种应用非常有用。*第8章* *提示工程*将进一步探讨提示工程和调节方法。

### 如何尝试一下？

你可以通过他们的网站或API访问OpenAI的模型。如果你想在笔记本电脑上尝试其他大型语言模型，开源LLMs是一个很好的起点。这里有一大堆东西！你可以通过Hugginface或其他提供商访问这些模型。你甚至可以下载它们，微调它们，或者 - 如果你感觉很高级 - 完全训练一个模型。我们将在*第9章* *LLM在生产中的应用*中更详细地讨论如何使用这些模型。在下一节中，我们将看看稳定扩散以及它是如何工作的。

## 什么是稳定扩散模型？

图像生成模型是一种生成模型，可用于生成图像。图像生成模型是一个强大的工具，可用于生成逼真和创意的图像。它们仍处于早期开发阶段，但有潜力彻底改变我们创建和消费图像的方式。最受欢迎的图像生成模型之一是**稳定扩散**，另一个是**Midjourney**。简单来说，这些是一种深度学习模型，根据文本提示创建图像。Google Brain在2022年宣布了两个文本到图像模型的创建，**Imagen**和**Parti**。

### 它是如何工作的？

**稳定扩散**模型是由慕尼黑路德维希·马克西米利安大学的计算机视觉组和Runway的研究人员开发的一种深度学习文本到图像模型。它生成根据文本描述条件的详细图像，并利用潜在扩散模型架构。该模型的源代码甚至权重已经在**CreativeML** **OpenRAIL**-**M许可证**下公开发布，该许可证“不对重用、分发、商业化、适应性施加任何限制”。该模型可以在配备适度GPU的消费者硬件上运行（例如**GeForce 40**系列）。**稳定扩散**是一种使用Gumbel分布向图像添加噪声的扩散模型。Gumbel分布是一种连续概率分布，通常在机器学习中使用，因为它易于抽样，并且具有更稳定的特性。稳定性意味着模型不太可能陷入局部最小值，这可能会发生在其他类型的扩散模型中。该模型由**变分自动编码器**（**VAE**）、**U-Net**和**文本编码器**组成。**VAE**有两部分，编码器和解码器，将原始高维图像压缩成较低维的潜在空间，并将其重构回图像空间。潜在空间显著降低了计算复杂性，使扩散过程更快。**VAE**编码器将图像压缩到潜在空间，而**U-Net**通过前向扩散进行去噪以获得潜在表示。然后**VAE**解码器生成最终图像。该模型可以灵活地根据各种形式进行条件化，并利用交叉注意机制来整合条件信息。**U-Net**是一种流行的对称编码器-解码器结构的卷积神经网络（CNN）。它通常用于图像分割任务，但在稳定扩散的背景下，它用于预测图像中的噪声。U-Net将嘈杂图像作为输入，并通过一系列卷积层处理以提取特征和学习表示。这些卷积层通常组织在一个收缩路径中，减少空间维度同时增加通道数。一旦收缩路径达到U-Net的瓶颈，它通过对称扩展路径进行扩展。在扩展路径中，应用转置卷积（也称为上采样或反卷积）逐渐上采样空间维度同时减少通道数。在扩散过程中，U-Net的扩展路径接受嘈杂图像并从前向扩散中重建潜在表示。通过将重建的潜在表示与真实潜在表示进行比较，U-Net预测原始图像中的噪声估计。这种噪声的预测有助于在反向扩散过程中恢复原始图像。扩散模型通过类似于物理学中的扩散的过程运作。它通过向图像添加噪声进行**前向扩散过程**，直到图像变得不典型和嘈杂。这个过程类似于一滴墨水落入水杯中逐渐扩散的过程。这里的独特之处在于**反向扩散过程**，模型试图从嘈杂、无意义的图像中恢复原始图像。通过逐步从嘈杂图像中减去估计的噪声，最终恢复类似于原始图像的图像。去噪过程在这个图中展示（来源：维基共享资源用户Benlisquare）：

![图1.8：在日本创造的欧式城堡，使用稳定扩散V1-5 AI扩散模型。仅显示40步生成过程中的步骤。](../media/file7.png)

图1.8：在日本创造的欧式城堡，使用稳定扩散V1-5 AI扩散模型。仅显示40步生成过程中的步骤。

在图中，您可以逐步看到图像生成过程，使用DDIM采样方法的U-Net去噪过程，该方法重复去除高斯噪声，然后将去噪输出解码为像素空间。稳定扩散是一种利用扩散过程从文本提示生成图像的深度学习模型，通过几个清晰的步骤：

1.  它从在潜在空间中生成一个随机张量（随机图像）开始，这作为我们初始图像的噪声。

1.  一个噪声预测器（**U-Net**）接收潜在嘈杂图像和提供的文本提示，并预测噪声。

1.  模型然后从潜在图像中减去潜在噪声。

1.  步骤2和3会重复进行一定数量的采样步骤，例如，在图中显示的40次。

1.  最后，**VAE**的解码器组件将潜在图像转换回像素空间，提供最终输出图像。

在图像生成模型的训练过程中，使用损失函数来评估生成图像的质量。一个常用的损失函数是**均方误差**（**MSE**）损失，它量化生成图像与目标图像之间的差异。模型被优化以最小化这种损失，鼓励它生成与期望输出密切相似的图像。该模型是在一个名为**LAION-5B**的数据集上训练的，该数据集源自Common Crawl数据，包括数十亿的图像-文本对。训练数据集根据语言、分辨率、水印可能性和美学评分进行分类。稳定扩散是在该数据集的子集上进行训练的。该模型的训练数据来源多样，其中有相当大一部分来自**Pinterest**、**WordPress**、**Blogspot**、**Flickr**、**DeviantArt**等网站。总的来说，像稳定扩散和Midjourney这样的图像生成模型将文本提示处理成生成的图像，利用正向和反向扩散过程的概念，并在较低维度的潜在空间中运行以提高效率。到目前为止，**稳定扩散**有两个主要版本，**版本1**和**2**。让我们看看它们有何不同。

#### 模型差异

**稳定扩散 v1** 和 **v2** 在文本处理、训练数据和结果方面有所不同。在文本处理方面，**稳定扩散 v2** 使用 **OpenClip** 进行文本嵌入，而 **v1** 使用 **Open AI** 的 **CLIP ViT-L/14** 进行文本嵌入。**OpenClip** 比 **CLIP** 大五倍，提高了图像质量，也让研究人员在研究和优化模型时更加透明。关于训练数据，**稳定扩散 v1.4** 使用三个不同的数据集进行训练，而 **稳定扩散 v2** 则是在一个经过过滤的 **LAION-5B** 子集上进行训练，该子集过滤了明确的色情材料（**NSFW 过滤器**）和美学评分高于阈值的内容。**LAION 5B** 数据集是一个包含 58.5 亿个 CLIP 过滤的图像文本对的大规模数据集。数据集中超过 23 亿个样本包含英语，而**22 亿个样本**来自其他 100 多种语言。剩下的 10 亿个样本不允许特定语言分配，比如姓名。数据集的获取流程复杂，需要大量处理。它包括对 PB 级 Common Crawl 数据集的分布式处理，图像的分布式下载，以及少量 **GPU** 节点的数据后处理，生成最终数据集。过滤还删除了重复样本，并将数据集从 500 亿个候选样本削减到不到 60 亿个 **CLIP** 过滤的图像文本对。在结果方面，稳定扩散 v2 更难用于控制风格和生成名人。这种差异可能是由于训练数据的不同，因为 Open AI 的专有数据可能包含更多艺术作品和名人照片，这些内容不包含在稳定扩散 v2 的训练数据中。总之，**稳定扩散 v2** 使用了不同的文本嵌入模型，并在不同的数据子集上进行了训练，与 **稳定扩散 v1** 相比产生了不同的结果。虽然 **稳定扩散 v2** 可能更透明，更适合长期发展，但 **稳定扩散 v1** 可能在特定用例中表现更好，比如控制风格或生成名人，这是由于其训练数据的原因。现在我们将看一下文本到图像使用案例中模型的条件。

### 条件化

条件过程允许这些模型受到输入文本提示或其他输入类型（如深度图或轮廓）的影响，以便更精确地创建相关图像。在条件过程中，提示被标记化，每个标记被转换为一个嵌入，一个长度为某个特定值的向量，有时是768个值。这些嵌入考虑了单词之间的语义关系，然后由文本变压器处理，并馈送给噪声预测器，引导其生成与文本提示相符的图像。在文本到图像的过程中，模型使用文本提示生成一个全新的图像。文本提示被编码到潜在空间中，扩散过程逐渐添加噪声（由去噪强度控制）以使初始图像演变为输出图像。让我们总结本章！

## 总结

像大型语言模型（LLMs）这样的生成模型因其在革新许多行业和任务方面的潜力而受到广泛关注。特别是它们在文本生成和图像合成方面的应用引起了媒体的极大关注。领先的公司如OpenAI正在推动LLMs的边界，他们的生成式预训练变压器（GPT）系列因其出色的语言生成能力而受到广泛关注。在本章中，我们讨论了最新突破所吸引的媒体关注，深度学习和人工智能的最近历史，生成模型，LLMs和预训练生成模型（GPT）以及支撑它们的理论思想，特别是变压器架构。我们还讨论了图像的扩散模型以及文本，图像，声音和视频的应用。下一章将探讨生成和特别是LLMs的工具化，重点介绍Langchain框架的基础知识，实施和使用这个特定工具来优化和增强LLMs。我认为在阅读技术书籍时检查自己是否消化了材料是一个好习惯。我为本章创建了一些问题。

## 问题

如果你已经阅读并理解了本章，你应该能够回答这些问题：

1.  什么是生成模型？

1.  生成模型有哪些应用？

1.  什么是大型语言模型（LLM）以及它的作用是什么？

1.  我们如何从LLMs中获得更好的性能？

1.  使这些模型成为可能的条件是什么？

1.  哪些公司和组织是开发LLMs的主要参与者？

1.  什么是变压器，它由什么组成？

1.  GPT是什么意思？

1.  稳定扩散是如何工作的？

1.  稳定扩散是如何训练的？

如果你在回答这些问题时遇到困难，请回到本章的相应部分，确保你已经理解了材料。
