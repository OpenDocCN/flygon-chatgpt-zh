- en: Chapter 5
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第5章
- en: Warnings, Ethics, and Responsible AI
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 警告、伦理和负责任的人工智能
- en: IN THIS CHAPTER
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在本章中
- en: '![](images/00003.jpg) Learning about the Responsible AI movement'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 学习有关负责任人工智能运动的知识'
- en: '![](images/00003.jpg) Paying attention to OpenAI warnings'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 关注OpenAI的警告'
- en: '![](images/00003.jpg) Losing copyright and IP protections'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 失去版权和知识产权保护'
- en: '![](images/00003.jpg) Reaching for reliability and trust'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 追求可靠性和信任'
- en: '![](images/00003.jpg) Reducing your risks'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00003.jpg) 降低风险'
- en: Each model improvement aims to increase stability and overall performance in
    terms of reliability, accuracy, and ethics. In this chapter, you learn what that
    means and why the effort is critical.
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 每个模型改进的目标是增加稳定性和整体性能，包括可靠性、准确性和伦理。在本章中，您将了解这意味着什么，以及为什么这一努力至关重要。
- en: Making Responsible AI
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 制定负责任的人工智能
- en: Almost everyone has an instinctive desire for caution or a sense of foreboding
    when it comes to AI. A broad industry effort called Responsible AI was formed
    to ensure that AI is responsibly developed by design. This movement is aimed at
    ensuring that AI models are built on specific principles from the ground up as
    opposed to having piecemeal measures tacked on after maturity or deployment or
    — yikes! — disregarded altogether.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 几乎每个人在涉及人工智能时都有一种谨慎或前兆感。一个名为负责任人工智能的广泛行业努力成立，旨在确保人工智能是通过设计负责任地开发的。这一运动旨在确保人工智能模型从一开始就建立在特定原则之上，而不是在成熟或部署后再添加零碎措施，或者更糟糕的是完全忽视。
- en: 'Many AI providers and communities embrace the baseline principals promoted
    by the Responsible AI movement, which include the following:'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 许多人工智能提供商和社区都支持负责任人工智能运动提倡的基本原则，其中包括以下内容：
- en: Accountability
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 责任制
- en: Bias evaluation
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏见评估
- en: Reliability and safety
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可靠性和安全性
- en: Fairness and accessibility
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公平和可访问性
- en: Transparency and explainability
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 透明度和可解释性
- en: Privacy and security
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐私和安全
- en: OpenAI, the creator of ChatGPT, has repeatedly stated a commitment to Responsible
    AI principles. It has also contributed to the movement in a number of ways, including
    open-sourcing Evals, its framework for evaluating OpenAI models and an open-source
    registry of benchmarks, and contributing policy research papers.
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ChatGPT的创建者OpenAI已多次表示承诺负责任人工智能原则。它还以多种方式为该运动做出了贡献，包括开源Evals，用于评估OpenAI模型的框架，以及开源基准注册表，并贡献政策研究论文。
- en: OpenAI's partners and collaborators also work toward the principles of Responsible
    AI, but current economic stressors are putting corporate commitments to the test.
    For example, in line with many recent tech industry layoffs, in March 2023 Microsoft
    laid off its AI ethics and society team, which was charged with ensuring Responsible
    AI principles made it into Microsoft products before they ship. Microsoft isn’t
    likely to be the last of the large AI product and services producer to do so.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI的合作伙伴和合作者也致力于负责任人工智能的原则，但当前的经济压力正在考验企业对此的承诺。例如，在与许多最近的科技行业裁员一致的情况下，2023年3月微软裁减了其AI伦理和社会团队，该团队负责确保负责任人工智能原则在微软产品发货前得到落实。微软不太可能是最后一个裁减其AI产品和服务生产商的大公司。
- en: Troubling developments
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 令人担忧的发展
- en: Until recently, AI was the domain of a relatively few learned scientists with
    highly specialized skills. But ChatGPT’s explosive arrival on the public scene
    spurred intense interest across the board. Now it appears that almost everyone
    is interested in using AI. And quite a few are keen to develop their own; the
    tools and costs are such that almost anyone can do it.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 直到最近，人工智能是相对少数具有高度专业技能的学者的领域。但是ChatGPT在公众场合的爆炸性出现引发了广泛的兴趣。现在几乎每个人都对使用人工智能感兴趣。而且有相当多的人渴望开发自己的人工智能；工具和成本使几乎任何人都可以做到。
- en: For example, researchers at Stanford University built Alpaca AI to perform similarly
    to ChatGPT on several tasks. Alpaca AI was built on an open-source small language
    model called LLaMA (developed by Meta, formerly known as Facebook). Stanford researchers
    trained it for less than $600, making it a rough equivalent of a cheap counterfeit
    copy of ChatGPT.
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，斯坦福大学的研究人员构建了Alpaca AI，在几项任务上表现类似于ChatGPT。Alpaca AI是建立在一个名为LLaMA的开源小型语言模型上的（由Meta，前身为Facebook，开发）。斯坦福的研究人员花了不到600美元对其进行训练，使其成为ChatGPT的廉价仿冒品。
- en: 'However, cheap AI can prove to be costly AI. Alpaca AI is very unsafe, in that
    it frequently produces wrong and toxic responses, and Stanford responded responsibly
    by yanking it offline shortly after launch. However, the dataset and code for
    fine-tuning that model is still available on GitHub for anyone to use. The researchers
    are working on releasing the Alpaca AI model’s weights there, too. (Weights rank
    the importance of various algorithm inputs.) The intention behind making all this
    accessible is noble: providing a lightweight model for the AI community to study
    several AI deficiencies in the hopes of making more Responsible AI.'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 然而，便宜的 AI 可能会变成昂贵的 AI。Alpaca AI 非常不安全，经常产生错误和有毒的回应，斯坦福在推出后不久负责地将其下线。然而，用于微调该模型的数据集和代码仍然可以在
    GitHub 上供任何人使用。研究人员正在努力发布 Alpaca AI 模型的权重，这也是为了提供一个轻量级模型供 AI 社区研究多个 AI 缺陷，希望能够制定更负责任的
    AI。
- en: But the nightmare in the story is that anyone can now build an AI model using
    the dataset and code on GitHub — for about $100 if the processes are optimized,
    according to Stanford. That’s not a far-fetched estimate considering that even
    cloud computing costs can be reduced or eliminated. We already have multiple reports
    of people running Alpaca’s code on Raspberry Pi computers and Pixel 6 smartphones,
    thereby skipping any need for cloud computing.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但故事中的噩梦是，现在任何人都可以使用 GitHub 上的数据集和代码构建一个 AI 模型 —— 如果流程经过优化，大约只需花费约 $100，根据斯坦福的说法。考虑到即使云计算成本也可以降低或消除，这并不是一个牵强的估计。我们已经有多份报告显示人们在树莓派计算机和
    Pixel 6 智能手机上运行 Alpaca 的代码，从而避免了对云计算的需求。
- en: Meanwhile, AI models are popping up in shady communities online too. For example,
    a week after its launch, the entirety of Meta’s LLaMA model was reportedly leaked
    on 4chan. When it comes to AI, cheaper is far, far worse, at least in terms of
    safety for humans. For example, an AI model can deliver wrong or harmful information
    that can physically hurt people if it’s acted on, and misinformation can fuel
    harmful conspiracy theories or spur public unrest. Now think of someone building
    AI with intentional malice using a model with few to no safeguards. The thought
    is not comforting.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与此同时，AI 模型也在网络上的不良社区中出现。例如，Meta 的 LLaMA 模型在推出一周后据称在 4chan 上泄露了全部内容。就 AI 而言，便宜的往往更糟糕，至少在人类安全方面是如此。例如，如果对其采取行动，AI
    模型可能提供错误或有害信息，这可能会对人们造成身体伤害，而错误信息可能助长有害的阴谋论或引发公众动荡。现在想象一下，有人使用几乎没有保障的模型恶意构建 AI。这种想法并不令人安心。
- en: Don’t forget that nation states sometimes have dubious intentions as well. AI
    of all types is currently in use by most governments, with much of it classified
    information and therefore unavailable for public scrutiny. Governments worldwide
    are also concerned about AI being used in terrorist attacks, cyberattacks, or
    public uprisings.
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 别忘了，有时国家也可能有可疑的意图。目前，几乎所有政府都在使用各种类型的 AI，其中大部分是机密信息，因此无法供公众审查。全球各国政府也担心 AI 被用于恐怖袭击、网络攻击或公众起义。
- en: Concerns over what might be done with AI led to both OpenAI and the Chinese
    government barring individuals in China from using ChatGPT. But a Chinese company
    called Baidu has already released its alternative model known in English as Enhanced
    Representation from kNowledge IntEgration, or Ernie Bot for short.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于 AI 可能被用于何种目的的担忧导致 OpenAI 和中国政府禁止中国个人使用 ChatGPT。但一家名为百度的中国公司已经发布了其替代模型，英文名为
    Enhanced Representation from kNowledge IntEgration，简称 Ernie Bot。
- en: Ernie Bot differs from ChatGPT-4 in two major ways. Ernie Bot produces multimodal
    outputs, meaning it generates texts and images, whereas ChatGPT-4 generates only
    text. And Ernie Bot can’t analyze images in prompts but ChatGPT-4 can.
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Ernie Bot 与 ChatGPT-4 在两个主要方面有所不同。Ernie Bot 生成多模式输出，意味着它生成文本和图像，而 ChatGPT-4
    仅生成文本。而 Ernie Bot 无法分析提示中的图像，但 ChatGPT-4 可以。
- en: Ernie Bot may differ in safety measures as well. It’s hard to tell at this point
    whether Baidu is working on sufficient safety precautions for Ernie Bot. Everyone
    is in a big rush to launch their answer to ChatGPT as fast as possible, which
    isn't good news in terms of ensuring that proper safety and ethical measures are
    in place and working.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Ernie Bot 在安全措施上可能有所不同。目前很难确定百度是否正在为 Ernie Bot 制定足够的安全预防措施。每个人都急于尽快推出他们的 ChatGPT
    答案，这对确保适当的安全和道德措施得以实施并发挥作用并不是个好消息。
- en: Previously, Baidu released Ernie 3.0, which is largely regarded as a GPT-3 equal.
    In 2022, it released Ernie-ViLG, which generates images from text prompts. Other
    ChatGPT-like bots from China-based entities include MOSS, by Fudan University
    researchers, and Inspo, by a startup called MiniMax.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 之前，百度发布了被广泛认为与GPT-3相当的Ernie 3.0。2022年，他们发布了Ernie-ViLG，可以根据文本提示生成图像。中国实体发布的其他类似ChatGPT的机器人包括复旦大学研究人员开发的MOSS和一家名为MiniMax的初创公司开发的Inspo。
- en: The US and China have been keenly interested and heavily involved in developing
    and using AI for years. So have other countries. AI in this context has consequences
    in both cold and hot wars, world commerce, individual freedom, human rights, and
    other national, geopolitical, and international policy issues.
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 多年来，美国和中国一直对开发和使用人工智能充满兴趣并积极参与其中。其他国家也是如此。在这种背景下，人工智能对冷战和热战、世界商业、个人自由、人权以及其他国家、地缘政治和国际政策问题都产生影响。
- en: Protecting humans from humans using AI
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 保护人类免受利用人工智能的人类
- en: On the flipside, several countries are working to contain consequences from
    the proliferation of AI models. For example, in December 2022, the European Council
    of the European Union (EU) proposed a regulation called the Artificial Intelligence
    Act, which aims to “ensure that artificial intelligence (AI) systems placed on
    the EU market and used in the Union are safe and respect existing law on fundamental
    rights and Union values.” The US has a new blueprint for an AI Bill of Rights
    as of October 2022\. In the UK, a “Roadmap to an effective AI assurance ecosystem”
    was published by the Centre for Data Ethics and Innovation in 2021\. The World
    Economic Forum also stepped up with a set of standards and guidelines that it
    published in 2022 titled “Quantum Computing Governance Principles.”
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 另一方面，一些国家正在努力遏制人工智能模型扩散的后果。例如，2022年12月，欧盟欧洲理事会提出了一项名为《人工智能法案》的法规，旨在“确保在欧盟市场上投放和在联盟中使用的人工智能系统安全并尊重现有的基本权利和联盟价值观”。截至2022年10月，美国已有一份新的人工智能权利法案蓝图。英国的“有效人工智能保证生态系统路线图”于2021年由数据伦理与创新中心发布。世界经济论坛也发布了一套标准和指南，于2022年发布了名为“量子计算治理原则”的文件。
- en: Numerous legitimate integrations of powerful generative AI models like ChatGPT
    are popping up in existing software almost everywhere. For example, ChatGPT is
    already in many Microsoft products, from Bing to Office365\. GPT-4 APIs can be
    used to integrate the model with almost any software. Competitive AI models for
    legitimate uses are also on the rise. One example is Adobe’s Firefly tool, which
    is powered by a generative adversarial network (GAN) AI model.
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 几乎在各种现有软件中都可以看到像ChatGPT这样强大生成人工智能模型的合法集成。例如，ChatGPT已经出现在许多微软产品中，从必应到Office365。GPT-4
    API可以用于将该模型集成到几乎任何软件中。用于合法用途的竞争性人工智能模型也在不断增加。一个例子是由生成对抗网络（GAN）人工智能模型驱动的Adobe的Firefly工具。
- en: Understanding the good, the bad, and the ugly
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 了解好的、坏的和丑陋的
- en: By now you’re beginning to realize just how accessible and varied AI truly is!
    But so are AI providers. How long will they remain interested in responsibly building
    and retraining AI models when their work can be stolen and counterfeited for mere
    pennies and in use within a few hours? Now add to that hit on ROI the recent rise
    in economic pressures to cut costs. Does that mean Responsible AI teams are on
    the chopping block first?
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在你开始意识到人工智能的可及性和多样性有多么强大了！但人工智能提供商也是如此。当他们的工作可以被窃取和伪造，几个小时内就可以使用，他们会继续有责任地构建和重新训练人工智能模型多久？现在再加上最近经济压力上升导致削减成本的情况。这是否意味着负责任的人工智能团队首先被裁员？
- en: Where does that leave AI? Where does that leave us?
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这将使人工智能处于何种境地？这将使我们处于何种境地？
- en: Even Sam Altman, CEO of OpenAI, has publicly admitted that he’s “a little bit
    scared” of AI. He’s also sounding the warning that some AI developers working
    on ChatGPT-like tools won’t apply safety limits. It’s just a matter of time until
    AI models spiral out of control.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 即使是OpenAI的CEO山姆·奥尔特曼也公开承认他对人工智能“有点害怕”。他还发出警告，一些开发类似ChatGPT工具的人工智能开发者不会应用安全限制。人工智能模型失控只是时间问题。
- en: Given the huge scale and sweeping capabilities of AI models like GPT-4 and applications
    such as ChatGPT, it's tantamount that individuals, citizen protection agencies
    and groups, governments, AI providers, and others join, insist on, or recommit
    to sustained efforts in containing AI within strong and well-reasoned guardrails
    designed to protect humans. Costs and corners can't be cut without incurring dire
    repercussions.
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 鉴于像GPT-4这样的AI模型和ChatGPT等应用的巨大规模和广泛能力，个人、公民保护机构和团体、政府、AI提供商等必须加入、坚持或重新致力于持续努力，以将AI限制在旨在保护人类的强大和合理的防护措施内。不能削减成本和抄近路，否则将招致严重后果。
- en: Heeding OpenAI Warnings
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 注意OpenAI的警告
- en: OpenAI released each ChatGPT version with clearly posted public warnings. It's
    essential to heed those. But if you haven’t yet read through the opening warning
    posts or you want to check to see if the warnings have been updated, just ask
    ChatGPT to list the latest warnings, as I did in [Figure 5-1](#filepos204880).
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI发布每个ChatGPT版本时都会明确发布公开警告。务必注意这些警告。但如果您尚未阅读开头的警告帖子，或者想要检查警告是否已更新，只需询问ChatGPT列出最新的警告，就像我在[图5-1](#filepos204880)中所做的那样。
- en: 'Pay special heed to the warning regarding your privacy. ChatGPT is still in
    training, in all of its models from ChatGPT-3 to ChatGPT-4\. This means anything
    you enter as a prompt (image or text) is likely to be used as training material.
    Therefore, any of the following conditions may or may not happen:'
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 特别注意有关您隐私的警告。ChatGPT仍处于训练阶段，从ChatGPT-3到ChatGPT-4的所有模型都是如此。这意味着您输入的任何提示（图像或文本）可能会被用作训练材料。因此，以下任何条件可能会发生或不会发生：
- en: '![](images/00039.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00039.jpg)'
- en: '[FIGURE 5-1:](#filepos204393) ChatGPT-4 lists warnings about its use after
    prompted.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-1：](#filepos204393) ChatGPT-4在提示后列出了有关其使用的警告。'
- en: Security is likely not at the same level as is usually afforded to personal
    identifiable information (PII).
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性可能不会像通常为个人可识别信息（PII）提供的那样高。
- en: Privacy shields, if there are any, may not extend to or follow after any data
    transfers.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有的话，隐私屏障可能不会延伸或跟随任何数据传输。
- en: Training material may become open-sourced or shared at some point.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练材料可能会在某个时候变为开源或共享。
- en: Your prompts may become a permanent part of training databases for future AI
    models and therefore almost impossible to ever delete.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的提示可能会成为未来AI模型的培训数据库的永久部分，因此几乎不可能永远删除。
- en: OpenAI researchers and AI trainers may see your prompts with images and text
    in their reviews of ChatGPT’s performance.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI的研究人员和AI训练者可能会在审查ChatGPT性能时看到您的提示与图像和文本。
- en: For your own peace of mind, proceed with prompts as though all these situations
    can be realized.
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了您自己的安心，请按照所有这些情况都可能实现的方式继续进行提示。
- en: '![](images/00023.jpg) Although all the listed warnings are important, I would
    single out the incomplete or incorrect information warning. One downside of ChatGPT
    is that it can be intentionally used to generate highly convincing disinformation
    and propaganda. I warn you in other chapters but it bears repeating: A more insidious
    threat is ChatGPT''s capability to hallucinate, or produce responses that sound
    highly plausible but are totally wrong. In short, don’t trust a word that AI says
    or writes. Double-check everything it outputs.'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00023.jpg) 尽管列出的所有警告都很重要，但我要特别提到不完整或不正确信息的警告。ChatGPT的一个缺点是它可以被有意用来生成高度令人信服的虚假信息和宣传。我在其他章节中警告过您，但需要重申：ChatGPT更隐匿的威胁是其能力产生幻觉，或产生听起来非常可信但完全错误的回应。简而言之，不要相信AI说的或写的任何话。请仔细检查它输出的每一条信息。'
- en: Considering Copyright and IP Protections
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑版权和知识产权保护
- en: OpenAI has been clear from the start that any text generated by ChatGPT in response
    to your prompts belongs to you. That’s all well and good unless you’re trying
    to copyright it and exclusively use it to make money.
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI从一开始就明确表示，ChatGPT生成的任何文本都属于您。这一切都很好，除非您试图对其进行版权保护并专门用于赚钱。
- en: The US Copyright Office ruled that any works containing AI-generated content
    can be copyrighted only to the extent of human authorship. In other words, whatever
    part AI writes is not copyright protected by law. If you write the work but use
    AI-generated images to illustrate it, your words are copyright protected but the
    images are not. If you reword some of the text that ChatGPT generated, only the
    words you wrote are protected by copyright. The rest is essentially left in the
    public domain for anyone else to use.
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 美国版权局裁定，任何包含人工智能生成内容的作品只能在人类创作程度范围内受版权保护。换句话说，AI写的部分不受法律版权保护。如果您撰写了作品但使用AI生成的图像来说明，您的文字受版权保护，但图像不受保护。如果您改写了ChatGPT生成的部分文本，只有您写的文字受版权保护。其余部分基本上留在公共领域供他人使用。
- en: Lest you think that this is the result of an American quirk or AI bias, consider
    that the World Intellectual Property Organization (WIPO) reports that most jurisdictions,
    including Spain and Germany, ruled the same on machine-generated copyright protections
    decades ago. It remains to be seen if they’ll change their minds and consider
    GPT in general and ChatGPT in particular as original content creators. Right now,
    the big money is on a resounding “No!”
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不要以为这是美国的怪癖或人工智能偏见的结果，世界知识产权组织（WIPO）报告称，包括西班牙和德国在内的大多数司法管辖区几十年前就对机器生成的版权保护做出了相同的裁决。目前尚不清楚他们是否会改变主意，将GPT总体和ChatGPT特别视为原创内容创作者。目前，大多数人都坚定地认为“不可能！”
- en: Publishers and agents worldwide said they were flooded with books, e-books,
    and other content by people hoping to make quick and easy money on ChatGPT-generated
    works. Almost none passed editorial muster and no one got a big bag of easy cash.
    Incidentally, anyone can now copy those works because they are considered fair
    game.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 全球出版商和代理商表示，他们被希望通过ChatGPT生成的作品快速轻松赚钱的人们的书籍、电子书和其他内容淹没。几乎没有一本通过编辑审核，也没有人获得大量轻松的现金。顺便说一句，任何人现在都可以复制这些作品，因为它们被视为公平竞争。
- en: Further, ChatGPT and other GPT models such as DALL-E may be found guilty of
    copyright infringement. Copyright-protected works and other protected intellectual
    property were added to the models’ training database when massive amounts of data
    were indiscriminately scraped from the internet without payment or permission.
    The potential infringement liability is currently under debate. In addition, because
    copyright-protected works are in ChatGPT’s training database, it may occasionally
    replicate exact word usage — that is, plagiarize — which could create liability
    issues for unaware users. A court case may be required to sort out all the legal
    details.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 此外，ChatGPT和其他GPT模型（如DALL-E）可能被判有侵犯版权的行为。当大量数据被不加选择地从互联网上抓取而未经付款或许可时，受版权保护的作品和其他受保护的知识产权被添加到模型的训练数据库中。目前，潜在的侵权责任正在进行讨论。此外，由于受版权保护的作品在ChatGPT的训练数据库中，它可能偶尔复制确切的用词使用
    — 也就是，抄袭 — 这可能为不知情的用户带来责任问题。可能需要一场法庭案件来澄清所有法律细节。
- en: Keep an eye on rising liability issues, new court actions, and evolving regulations
    because they may contain emerging threats to your endeavors if you’re using ChatGPT
    or an AI model of similar ilk.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请密切关注不断增加的责任问题、新的法庭诉讼和不断发展的法规，因为如果您正在使用ChatGPT或类似的人工智能模型，它们可能包含对您努力的新威胁。
- en: Searching for Predictability
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找可预测性
- en: AI can be objectively judged on predictability, meaning the percentage of times
    if delivers the right answer to the same or similar questions. Typically, AI models
    do not score 100 percent predictability on all questions; rather they have different
    scores on various types of questions.
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能可以客观地根据可预测性来评判，即在相同或类似问题上提供正确答案的百分比。通常，人工智能模型在各种类型的问题上并不都能得到100%的可预测性得分；而是在不同类型的问题上有不同的得分。
- en: But few users rely on actual predictability scoring to determine how much they
    trust AI. Instead, people are more prone to lean on their perception of AI and
    their own gut feeling about its responses. In this section, you see how machine
    tests and human feelings can affect your work with ChatGPT.
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但很少有用户依赖实际的可预测性评分来确定他们对人工智能的信任程度。相反，人们更倾向于依赖他们对人工智能的感知和对其回应的直觉。在本节中，您将看到机器测试和人类感觉如何影响您与ChatGPT的工作。
- en: Reaching for reliability
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 追求可靠性
- en: In its GPT-4 Technical Report OpenAI asserts that GPT-4 scored 19 percentage
    points higher than the latest GPT-3.5 iteration on OpenAI’s internal adversarially
    designed factuality evaluation. Specific scores in model comparisons are shown
    in [Figure 5-2](#filepos212274), which depicts the performance of various ChatGPT
    models in nine categories.
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在其GPT-4技术报告中，OpenAI断言GPT-4在OpenAI内部对抗性设计的事实性评估中比最新的GPT-3.5迭代高出19个百分点。模型比较中的具体得分显示在[图5-2](#filepos212274)中，该图描述了各种ChatGPT模型在九个类别中的表现。
- en: On public benchmarks such as TruthfulQA, which tests how well the model separates
    facts from incorrect statements, the base model of GPT-4 scores only slighter
    better than GPT-3.5\. After additional RLHF (reinforcement learning from human
    feedback) post-training, the GPT-4 model outperformed GPT-3.5 by a wider margin.
    Counterintuitively, the pretrained model’s confidence in its answers generally
    matched the probability of being correct while the opposite was true of the post-trained
    model’s confidence.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在像TruthfulQA这样的公共基准测试中，该测试评估模型在将事实与不正确陈述区分开的能力，GPT-4的基础模型仅比GPT-3.5稍微好一点。在额外的RLHF（从人类反馈中强化学习）后训练后，GPT-4模型的表现比GPT-3.5更好。令人感到反直觉的是，预训练模型对其答案的置信度通常与正确性的概率相匹配，而后训练模型的置信度则相反。
- en: Neither GPT-4 nor GPT-3.5 models have any knowledge of facts and events that
    occurred after the 2021 cutoff date. These models also do not learn from experience,
    which can result in gullibility to prompts, reasoning errors, and mistakes that
    resemble human errors. Biases in the reasoning also exist.
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 无论是GPT-4还是GPT-3.5模型都不知道2021年截止日期之后发生的事实和事件。这些模型也不会从经验中学习，这可能导致对提示的轻信、推理错误和类似人类错误的错误。推理中也存在偏见。
- en: '![](images/00069.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00069.jpg)'
- en: '[FIGURE 5-2:](#filepos211148) ChatGPT performance scores in various categories.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-2：](#filepos211148) ChatGPT在各个类别中的表现得分。'
- en: '![](images/00023.jpg) In short, ChatGPT, regardless of the model used, has
    a reliability problem. Although this problem has improved over the evolution of
    models, it''s significant enough that outputs should always be fact-checked, especially
    when ChatGPT content is used for critical functions and decision making.'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00023.jpg) 简而言之，ChatGPT，无论使用何种模型，都存在可靠性问题。尽管随着模型的演进，这个问题有所改善，但仍然很重要，因此输出应始终经过事实核查，特别是在将ChatGPT内容用于关键功能和决策时。'
- en: Readers should always be aware of the inherent unreliability in outputs and
    not be swayed by the convincing language generated by ChatGPT as reason to skip
    the verifying step.
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 读者应始终意识到输出的固有不可靠性，并不要被ChatGPT生成的令人信服的语言所影响，以免跳过验证步骤。
- en: Hallucinating versus accuracy
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 幻觉与准确性
- en: If you read about generative AI models, mention of confident AI or an AI model’s
    level of confidence eventually comes up. In the context of machine learning, confidence
    is a measure of the AI model’s estimated probability that its answer (output)
    is correct based on the information it has (input or prompt).
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你了解生成式AI模型，你会提到自信的AI或AI模型的置信水平。在机器学习的背景下，置信度是AI模型根据其拥有的信息（输入或提示）估计其答案（输出）正确性的概率度量。
- en: The four categories used to determine the level of confidence an AI has in its
    response are repeatability, believability, sufficiency, and adaptability.
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用于确定AI对其响应的置信水平的四个类别是可重复性、可信度、充分性和适应性。
- en: '![](images/00079.jpg) When an AI model is said to have a high degree of confidence,
    it does not mean that the user can also have a high degree of confidence in the
    AI’s answer. ChatGPT can be extremely confident that it gave you a correct answer
    when it clearly and demonstrably delivered a wrong answer. This behavior is known
    in AI industry parlance as a hallucination.'
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00079.jpg) 当说一个AI模型有很高的置信度时，并不意味着用户也可以对AI的答案有很高的信心。当ChatGPT明显且可证明地给出错误答案时，它可能非常确信自己给出了正确答案。这种行为在AI行业术语中被称为幻觉。'
- en: AI hallucinations are not coming from any sense of malice; the machine is not
    lying to you intentionally. It simply did the math, spouted babble, and rated
    itself as brilliantly correct, much like people suffering from the Dunning Kruger
    effect or delusions of grandeur might do.
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: AI的幻觉并非出于恶意；机器并非有意欺骗你。它只是做了数学运算，胡言乱语，自我评价为极其正确，就像患有邓宁-克鲁格效应或妄想症的人可能会做的那样。
- en: And to paraphrase a character in Gone with the Wind, frankly, my dear, it doesn’t
    give a damn. ChatGPT and its ilk do not care when they hallucinate. The model
    delivers an answer that it's highly confident is correct and that’s the end of
    it. Perhaps one day AI researchers will be able to teach AI models to double-check
    their homework with at least a smidge of humility and to be properly embarrassed
    when they fail.
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 而且借用《飘》中的一位角色的话，坦率地说，亲爱的，它并不在乎。当ChatGPT及其同类产生幻觉时，它们并不在乎。该模型提供一个它高度确信是正确的答案，就此打住。也许有一天，AI研究人员将能够教导AI模型至少谦卑地复核作业，并在失败时感到适当的尴尬。
- en: When ChatGPT hallucinates, it outputs a convincing bit of nonsense that, if
    you acted upon it or accepted it unquestionably as true, could prove harmful to
    you or others. This inaccuracy cloaked in sweet nothings is what researchers are
    usually referring to when they call a model unsafe. The model is not reliably
    accurate and therefore it is unsafe for you to believe anything it outputs at
    face value.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当ChatGPT产生幻觉时，它会输出一个令人信服的胡言乱语，如果你采取行动或毫无疑问地接受它为真，可能会对你或他人造成伤害。这种包裹在甜言蜜语中的不准确性通常是研究人员在谈论模型不安全时所指的。该模型不可靠准确，因此你不能毫无保留地相信它输出的任何内容。
- en: As Google puts it, machines learn, but they don't know anything if you equate
    knowledge with certitude, which is often the case in Western thinking.
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 正如谷歌所说，机器学习，但如果你将知识等同于确定性，那么它们什么也不知道，这在西方思维中经常发生。
- en: '![](images/00079.jpg) ChatGPT works by predicting which words will follow your
    prompt. It knows nothing. It calculates probabilities and issues an output with
    the highest probability of being correct, which can turn out to be 100 percent
    wrong. Do not take this to mean that ChatGPT is a toy or performs a simple calculation.
    ChatGPT is an astonishing feat of engineering. But it is also flawed.'
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00079.jpg) ChatGPT的工作原理是预测哪些单词会跟随你的提示。它一无所知。它计算概率并输出具有最高正确概率的结果，但这个结果可能完全错误。不要认为这意味着ChatGPT是一个玩具或执行简单计算。ChatGPT是一项惊人的工程壮举。但它也有缺陷。'
- en: Does that mean you should consider a flawed ChatGPT or other generative AI model
    worthless? Absolutely not. Even though its output will have to be consistently
    and rigorously fact-checked, it can still significantly increase the speed of
    production. And you can bet your competition is using it or something like it
    too.
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 那是否意味着你应该认为有缺陷的ChatGPT或其他生成式AI模型毫无价值？绝对不是。尽管其输出必须经过持续严格的事实核查，但它仍然可以显著提高生产速度。而且你可以打赌你的竞争对手也在使用它或类似的东西。
- en: '![](images/00084.jpg) Think of ChatGPT as a junior assistant that you may need
    to correct, instruct, and mentor. Despite its shortcomings, this assistant is
    incredibly fast at bringing you most of what you need to do your own job more
    easily and quickly.'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](images/00084.jpg) 将ChatGPT视为一个你可能需要纠正、指导和辅导的初级助手。尽管它有缺点，但这个助手在为你带来大部分工作所需的东西时非常快速，让你的工作更轻松、更快速。'
- en: Humanizing the machine
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使机器具有人性化
- en: One of the most remarkable achievements in OpenAI’s work in developing ChatGPT
    and the various models that power it is that this AI model appears human. This
    development is quite the modern marvel.
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在OpenAI开发ChatGPT和支持它的各种模型的工作中，最显著的成就之一是这个AI模型看起来像人类。这一发展是相当现代的奇迹。
- en: Alan Turing, a man of much education and many skills, dubbed his famous Turing
    Test for AI “an imitation game” wherein a machine could so closely mimic human
    intelligence and conversation that a human couldn’t tell it was a machine. He
    developed that test in the 1950s and, for much of that time forward, machines
    fell short. Now several appear to pass the test at least for a while, but they
    usually get outed eventually.
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 阿兰·图灵，一个受过良好教育且多才多艺的人，将他著名的AI图灵测试称为“模仿游戏”，在这个游戏中，一台机器可以如此逼真地模仿人类智能和对话，以至于人类无法分辨它是机器。他在1950年代开发了这个测试，而在那段时间的大部分时间里，机器表现不佳。现在有几个似乎至少暂时通过了测试，但它们通常最终会被揭穿。
- en: People generally know that ChatGPT is AI, but users can easily forget that fact
    as they continue to converse with it. Since the entire interaction from prompt
    to output is in natural language and flowing at the speed of human conversation,
    the experience can feel the same as chatting with another human online.
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人们通常知道ChatGPT是AI，但用户在继续与它交谈时很容易忘记这一事实。由于从提示到输出的整个交互都是用自然语言进行，并且以人类对话的速度进行，因此这种体验可能与在网上与另一个人聊天相同。
- en: Eventually, ChatGPT makes a misstep that reminds users that this is AI and the
    jig is up. Even ChatGPT admits that happens in the conversation I had with it
    on the subject, as captured in [Figure 5-3](#filepos219766).
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最终，ChatGPT会犯一个错误，提醒用户这只是人工智能，一切都暴露了。甚至ChatGPT在我与它关于这个话题的对话中也承认了这一点，如[图5-3](#filepos219766)所示。
- en: Even so, that initial false sense of familiarity breeds trust. And trust is
    the last thing anyone should place in AI.
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 即便如此，最初的虚假熟悉感也会培养信任。而信任是任何人都不应该放在人工智能身上的最后一件事。
- en: Several studies revealed that the human flaw towards humanizing and trusting
    a machine is persistent. For example, a report titled “Computers in Human Behavior”
    by researchers hailing from Carnegie Mellon and the University of California Berkeley
    found that misattribution of blame leads humans to rely on poorly performing AI.
    In other words, people tend to blame themselves rather than AI for errors. Further,
    humans continue to wrongly accept the blame, which causes them to “enter a vicious
    cycle of relying on a poorly performing AI.”
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 几项研究揭示了人类对机器人的人性化和信任的缺陷是持久的。例如，一份来自卡内基梅隆大学和加州大学伯克利分校的研究人员撰写的名为“人类行为中的计算机”报告发现，错误归因导致人们依赖表现不佳的人工智能。换句话说，人们倾向于责怪自己而不是人工智能的错误。此外，人类继续错误地接受责任，这导致他们“进入依赖表现不佳的人工智能的恶性循环”。
- en: '![](images/00004.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00004.jpg)'
- en: '[FIGURE 5-3:](#filepos218862) ChatGPT Plus (premium version built on GPT-4
    model) response when asked if people mistake it as human.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-3：](#filepos218862) ChatGPT Plus（基于GPT-4模型构建的高级版本）在被问及是否被误认为是人类时的回应。'
- en: Additionally, the researchers found that the user’s level of self-confidence,
    and not their level of confidence in AI, is the deciding factor in whether they
    accept or reject an AI’s suggestions. Their findings point to a need to “effectively
    calibrate human self-confidence for successful AI-assisted decision-making.” In
    short, humans need to be trained on when to trust themselves and when to trust
    AI, as opposed to defaulting and demurring to AI.
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 此外，研究人员发现用户的自信水平，而不是他们对人工智能的信心水平，是决定他们接受还是拒绝人工智能建议的关键因素。他们的研究结果指出了需要“有效校准人类自信心以进行成功的人工智能辅助决策”的需求。简而言之，人类需要接受培训，学会何时信任自己，何时信任人工智能，而不是默认和推诿给人工智能。
- en: Human experiences can also color acceptance of the presumed infallibility of
    AI — especially one that sounds human and benevolent like ChatGPT. People who
    are cynical and dubious of other people’s intent tend to be more skeptical of
    AI as well. Likewise, people who are more trusting of other people tend to trust
    AI. But members of both groups have been known to change their minds in response
    to their personal experiences with AI.
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人类的经验也会影响对假定不可错误的人工智能的接受程度，尤其是像ChatGPT这样听起来像人类和仁慈的人工智能。那些对他人意图愤世嫉俗和怀疑的人往往对人工智能持更多怀疑态度。同样，那些对他人更加信任的人往往也会信任人工智能。但这两组人中的成员已知会根据他们与人工智能的个人经验而改变主意。
- en: In any case, be aware of human and machine shortcomings and proceed accordingly.
    Resist your own urge to be friendly and trusting with ChatGPT and its ilk.
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 无论如何，要意识到人类和机器的缺点，并相应地进行。抵制自己与ChatGPT及其同类友好和信任的冲动。
- en: As Google’s People + AI Research (PAIR) initiative writer David Weinberger put
    it, uncertainty is seen as a weakness in humans but a strength in AI. Think about
    that for a minute. Are you making decisions based on misplaced trust in ChatGPT’s
    confidence — or are you going to fact-check it every time?
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 正如谷歌的People + AI Research (PAIR)计划撰稿人大卫·温伯格所说，不确定性在人类看来是一种弱点，但在人工智能看来是一种优势。想一想这一点。你是基于对ChatGPT的信心的错误信任做出决定吗，还是每次都会事实核查呢？
- en: Mitigating Risks and Liability
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解风险和责任
- en: OpenAI has gone to significant effort to improve the safety of ChatGPT by continuously
    improving its alignment with human values and goals. Among the measures they use
    to accomplish greater safety are feedback from human domain experts for adversarial
    testing and red-teaming (a group of humans who play an adversarial role in seeking
    out vulnerabilities), improved safety models (guardrails for the AI model), and
    a model-assisted safety pipeline that assists by automating machine-learning processes
    within safety parameters.
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI已经付出了大量努力来提高ChatGPT的安全性，不断改进其与人类价值观和目标的一致性。为了实现更大的安全性，他们采取的措施包括来自人类领域专家的反对测试和红队测试的反馈（一组扮演对抗角色寻找漏洞的人类），改进的安全模型（AI模型的防护栏），以及一个模型辅助的安全管道，通过在安全参数内自动化机器学习过程来提供帮助。
- en: Using human experts for adversarial testing and red-teaming, rather than just
    throwing two opposing AI models in a pit to continuously battle it out and refine
    each other in the process, is a crucially important move. Domain experts such
    as cybersecurity and international security professionals can find and eliminate
    or curb risks, such as terrorists using ChatGPT to get assembly instructions for
    a dirty bomb or a biohacking recipe for a human-engineered pandemic. I’m sure
    you can see why such intense precautions are necessary.
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用人类专家进行对抗测试和红队行动，而不仅仅是将两个对立的AI模型扔进一个坑中不断地互相较量和完善，这是一个至关重要的举措。诸如网络安全和国际安全专业人员之类的领域专家可以发现并消除或遏制风险，例如恐怖分子使用ChatGPT获取脏炸弹的组装说明或人为制造的生物黑客配方。我相信您能理解为什么这样强烈的预防措施是必要的。
- en: But other domain experts are also important in refining responses on niche topics,
    containing offensive remarks, curbing inherent biases, eliminating propaganda
    and misinformation, and preventing riots and civil unrest.
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但其他领域专家在细化有关小众话题的回应、包含冒犯性言论、遏制固有偏见、消除宣传和错误信息以及防止骚乱和社会动荡方面也很重要。
- en: AI models such as ChatGPT can do lots of good, but when it’s allowed to be bad,
    it can be very, very bad for all of us. Using human experts to deal with the issues
    and help install the needed guardrails is an absolute necessity.
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 诸如ChatGPT之类的AI模型可以做很多好事，但如果允许其做坏事，对我们所有人来说可能会非常糟糕。使用人类专家处理问题并帮助安装所需的防护措施是绝对必要的。
- en: OpenAI also uses reinforcement learning with human feedback (RLHF) to better
    match responses to user intent. This approach helps improve the quality of responses.
    And it helps weed out unsafe and bad behaviors on the part of AI, even if the
    human user is up to no good, but can also result in the machine becoming overly
    cautious and not replying even though it's safe to do so.
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI还使用强化学习与人类反馈（RLHF）来更好地匹配用户意图的回应。这种方法有助于提高回应的质量。它有助于消除AI的不安全和不良行为，即使人类用户有不良意图，但也可能导致机器过于谨慎，即使安全也不回复。
- en: OpenAI’s rule-based reward models (RBRMs) provide additional rewards for the
    AI model to avoid inappropriate responses and undue caution. The rewards methods,
    such as when a user clicks thumbs up and thumbs down icons, are indicators that
    further reinforce which answers are appropriate and desirable and which are not.
    There are only digital rewards with no donuts or free vacations for ChatGPT in
    the offering!
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI的基于规则的奖励模型（RBRMs）为AI模型提供额外奖励，以避免不当回应和过度谨慎。奖励方法，例如用户点击赞和踩图标时，是进一步强化哪些答案是适当和可取的，哪些不是的指标。ChatGPT只提供数字奖励，没有甜甜圈或免费度假！
- en: As an additional step, OpenAI works with external researchers to improve model
    performance and safety and to improve their own understanding of potential effects.
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为额外步骤，OpenAI与外部研究人员合作，以提高模型的性能和安全性，并提高他们对潜在影响的理解。
- en: But even after all this, some risks remain and the user is well advised to take
    serious precautions. For example, don’t assume that any conversation with ChatGPT
    or its competitors is or will remain private. See [Figure 5-4](#filepos225281)
    for an example of one of the many vulnerabilities AI models like these can have.
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但即使经过所有这些，仍然存在一些风险，用户最好采取严格的预防措施。例如，不要假设与ChatGPT或其竞争对手的任何对话是私密的或将保持私密。请参见[图5-4](#filepos225281)以了解这类AI模型可能存在的许多漏洞的示例。
- en: '![](images/00013.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00013.jpg)'
- en: '[FIGURE 5-4:](#filepos225087) A tweet by Sam Altman, CEO of OpenAI about a
    ChatGPT data leak.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-4：](#filepos225087)OpenAI首席执行官Sam Altman关于ChatGPT数据泄露的推文。'
- en: Potential liability also exists for users who publish unedited ChatGPT content
    because ChatGPT and its ilk are known to plagiarize. Copyright and intellectual
    property rights are not dismissed because a machine infringed upon them instead
    of a human. Be sure to double-check its work for plagiarism and other issues such
    as slander before you publish the content.
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于发布未经编辑的ChatGPT内容的用户也存在潜在责任，因为ChatGPT及其类似产品已知会抄袭。版权和知识产权并没有因为机器侵犯而被忽视。在发布内容之前，请务必仔细检查其是否存在抄袭和其他问题，如诽谤。
- en: As to the greater risks to communities, nations, and humanity, a collaborative
    effort of organizations and government agencies is urgently needed. Otherwise,
    these rising AI models will quickly get out of hand and undoubtedly create great
    harm.
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 至于对社区、国家和人类的更大风险，迫切需要组织和政府机构的协作努力。否则，这些不断崛起的AI模型将迅速失控，无疑会造成巨大伤害。
- en: 'Following are steps to take to help mitigate risks and liabilities associated
    with ChatGPT use:'
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 以下是采取的步骤，以帮助减轻与ChatGPT使用相关的风险和责任：
- en: Always fact-check the content it generates.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 始终要对其生成的内容进行事实核查。
- en: Conduct a human review to ensure that the content is accurate and current.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行人工审查，确保内容准确和及时。
- en: Disclose that you’re using AI so readers and reviewers don't feel duped.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 披露你正在使用人工智能，这样读者和评论者就不会感到被愚弄。
- en: Check that AI-generated content is compliant with all laws, regulations, and
    guidelines.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查人工智能生成的内容是否符合所有法律、法规和指导方针。
- en: Monitor audience feedback and respond quickly if the AI content has created
    issues.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控受众反馈，并在人工智能内容引发问题时迅速做出回应。
- en: Avoid dependency on AI from yourself or others you work with. You’re in charge;
    AI is just a tool.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免依赖自己或与你合作的他人的人工智能。你是负责任的；人工智能只是一个工具。
- en: Use AI responsibly. Never use it to do something morally, ethically, or legally
    wrong.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负责任地使用人工智能。永远不要用它做出道德、伦理或法律上错误的事情。
- en: These precautions should put you on the right path for mitigating risks and
    avoiding liability. But in high-risk applications, go beyond even these measures.
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些预防措施应该让你走上减轻风险和避免责任的正确道路。但在高风险应用中，甚至要超越这些措施。
