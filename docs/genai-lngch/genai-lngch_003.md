# 2 介绍 LangChain

## 在 Discord 上加入我们的书籍社区

[`packt.link/EarlyAccessCommunity`](https://packt.link/EarlyAccessCommunity)

![二维码描述自动生成](img/file8.png)

在本章中，我们讨论了 LLMs 的限制，以及如何将 LLMs 与工具结合起来以克服这些挑战，从而构建创新的基于语言的应用程序。有一些强大的框架为开发人员提供了强大的工具，用于快速工程、链接、数据检索等。无论您是开发人员、数据科学家还是对自然语言处理（NLP）或生成式人工智能的技术进步感兴趣，您都应该了解这些框架中最强大和流行的 LangChain。LangChain 解决了与使用 LLMs 相关的痛点，并提供了一个直观的框架来创建定制的 NLP 解决方案。在 LangChain 中，像 LLMs、互联网搜索和数据库查找这样的组件可以链接在一起，这意味着根据数据或任务的要求按顺序执行不同的任务。通过利用其功能，开发人员可以构建动态和数据感知的应用程序，利用我们在第一章讨论的最新技术突破。我们将列举一些用例，以说明该框架如何帮助不同领域的企业和组织。LangChain 对代理和内存的支持使得可以构建比仅通过 API 调用语言模型更强大和灵活的各种应用程序。我们将讨论与框架相关的重要概念，如代理、链、行动计划生成和内存。理解这些概念对于了解 LangChain 的工作原理至关重要。主要部分包括：

+   LLMs 的限制是什么？

+   什么是 LLM 应用程序？

+   什么是 LangChain？

+   LangChain 如何工作？

我们将从介绍 LLMs 的限制开始本章。

## LLMs 的限制是什么？

**大型语言模型**（**LLMs**）因其生成类似人类文本和理解自然语言的能力而受到广泛关注和流行，这使它们在围绕内容生成、文本分类和摘要的场景中非常有用。虽然**LLMs**提供了令人印象深刻的功能，但它们存在一些限制，可能会影响其在某些场景中的有效性。了解这些限制在开发应用程序时至关重要。与大型语言模型相关的一些痛点包括：

1.  **过时的知识**：**LLMs**无法提供实时或最新数据，因为它们完全依赖于提供给它们的训练数据。

1.  **无法执行操作**：**LLMs**无法执行操作或与外部系统交互，限制了其功能。例如，它们无法启动网络搜索、实时查询数据库或使用计算器进行数字乘法。

1.  **缺乏上下文和额外信息**：**LLMs**可能难以理解和整合来自先前提示或对话的上下文。它们可能不记得先前提到的细节或未能提供除给定提示之外的额外相关信息。

1.  **复杂性和学习曲线**：使用大型语言模型开发应用程序通常需要对人工智能概念、复杂算法和 API 有深入的理解。这可能对那些在这些领域没有专业知识的开发人员构成挑战。

1.  **幻觉**：**LLMs**在它们的权重中隐含了对世界的许多常识。然而，它们可能对某些主题了解不足，并生成不准确或不连贯的回应。例如，它们可能产生不存在的信息或提供不准确的细节。

1.  **偏见和歧视**：根据它们训练的数据，大型语言模型可能表现出宗教、意识形态、政治等方面的偏见。

LLMs 没有关于当前事件的信息，因为它们与外部世界没有连接，也不会知道它们没有接受过训练的任何事情，比如截止日期之后的任何事情，即训练数据生成的时间。更重要的是，它们在超出训练数据限制的上下文理解方面遇到困难。例如，由于模型无法执行操作或直接与外部系统交互，它们不会知道天气，也无法访问您的文档。这个截止日期问题在 OpenAI ChatGPT 聊天界面中询问**LangChain**时得到了说明：

![图 1.1：ChatGPT - 缺乏最新信息。](img/file9.png)

图 1.1：ChatGPT - 缺乏最新信息。

在这种情况下，模型能够正确地捕捉问题并给出正确的反馈。然而，如果我们在**GPT-3**游乐场问同样的问题，我们会得到这样的回答：

![图 1.2：带有 GPT 3.5 的 OpenAI 游乐场 - 幻觉。](img/file10.png)

图 1.2：带有 GPT 3.5 的 OpenAI 游乐场 - 幻觉。

在这种情况下，我们可以看到模型虚构了这个术语，并发明了一个名为去中心化平台。这是一种幻觉。需要注意这些问题。这个问题可以通过访问外部数据来解决，比如天气 API、用户偏好或来自网络的相关信息，这对于创建个性化和准确的语言驱动应用程序至关重要。**LLMs**擅长生成文本，但缺乏真正的理解和推理能力。然而，它们可能在逻辑推理方面遇到困难。例如，即使是高级的**LLMs**在高中水平的数学方面表现不佳，无法执行它们之前没有见过的简单数学运算。我们可以通过一个简单的演示来说明这一点：

![图 1.3：ChatGPT 数学求解。](img/file11.png)

图 1.3：ChatGPT 数学求解。

因此，该模型对第一个问题提出了正确的回答，但在第二个问题上失败了。以防你想知道真正的结果是什么 - 如果我们使用计算器，我们会得到这个结果：

![图 1.4：使用计算器进行乘法（BC）。](img/file12.png)

图 1.4：使用计算器进行乘法（BC）。

LLM 没有存储计算结果或者在训练数据中遇到足够多次以便可靠地记住它作为其权重中的编码。因此，它未能正确提出解决方案。在这种情况下，基于 Transformer 的 LLM 不是合适的工具。在部署应用程序之前，**LLMs**的输出可能需要监控和校正以确保准确性和偏见以及不当语言。在领域如客户服务、教育和营销中部署应用程序之前，需要监控和校正**LLMs**的输出以确保准确性和偏见。在 Chatbot 中找到偏见的例子并不难 - 只需回想一下 Tay Chatbot，因为其中包含种族歧视和其他仇外言论而成为微软的公关灾难。为了解决所有这些问题，**LLMs**需要与外部数据源、内存和能力集成，以便根据提供的数据与其环境动态交互并做出适当的响应。然而，将大型语言模型与不同的数据源和计算连接起来可能会很棘手，需要开发和仔细测试特定的定制工具。因此，使用生成式 AI 构建数据响应型应用程序可能会很复杂，可能需要大量编码和数据处理。最后，直接使用**LLM**模型可能具有挑战性且耗时。这从提示工程开始，但延伸得更远。困难在于导航这些复杂的模型，提供有效的提示，并解析它们的输出。

## 什么是 LLM 应用？

为了解决上述挑战和限制，**LLMs**可以与其他程序或服务的调用结合使用。主要思想是通过连接工具来增强 LLMs 的能力。将**LLMs**与其他工具结合到使用专门工具的应用程序中，**LLM**驱动的应用程序有潜力改变我们的数字世界。通常通过一条或多条提示调用**LLMs**的链来完成这一点，但也可以利用其他外部服务（如 API 或数据源）来完成特定任务。

> 一个**LLM 应用**是一种使用大型语言模型（LLMs）如 ChatGPT 来辅助各种任务的应用程序。它通过向语言模型发送提示来生成响应，并且还可以与其他外部服务（如 API 或数据源）集成，以实现特定目标。

为了说明一个**LLM**应用程序可能是什么样子，这里有一个非常简单的**LLM**应用程序，包括一个提示和一个**LLM**（来源：[`github.com/srush/MiniChain`](https://github.com/srush/MiniChain)）:

![图 1.5：一个简单的 LLM 应用，将提示与 LLM 结合在一起。](img/file13.png)

图 1.5：一个简单的 LLM 应用，将提示与 LLM 结合在一起。

**LLM**应用对人类有着重要潜力，因为它们增强了我们的能力，简化了流程，并在各个领域提供了有价值的帮助。以下是**LLM**应用重要的几个原因：

+   **效率和生产力**：**LLM**应用自动化任务，实现重复或复杂操作更快、更准确地完成。它们可以处理数据处理、分析、模式识别和决策，速度和准确性超过人类能力。这提高了数据分析、客户服务、内容生成等领域的效率和生产力。

+   **任务简化**：**LLM**应用通过将复杂任务分解为可管理的步骤或为用户提供直观界面来简化复杂任务。这些工具可以自动化复杂工作流程，使其对更广泛范围的用户可访问，而无需专业知识。

+   **增强决策能力**：**LLM**应用提供先进的分析能力，实现数据驱动的决策。它们可以快速分析大量信息，识别人类无法察觉的趋势或模式，并为战略规划或问题解决提供有价值的见解。

+   **个性化**：基于个人偏好和行为模式，AI 驱动的推荐系统个性化用户体验。这些应用考虑用户数据，提供定制建议、推荐和个性化内容，涵盖电子商务、娱乐和在线平台等各个领域。

公司数据，尤其是客户数据，与**LLMs**的使用是增长的一个特定领域。然而，我们必须谨慎考虑隐私和数据保护的影响。我们绝不能将**个人可识别**（**PII**）数据输入公共 API 端点。对于这些用例，部署模型在内部基础设施或私有云中至关重要，细化甚至训练专门模型提供重要改进。这就是我们将在第九章*LLM 应用在生产中*中讨论的内容。让我们比较一些可以帮助构建**LLM**应用的框架。

### 框架比较

**LLM**应用框架已经发展出来，提供专门的工具，可以有效利用**LLMs**的力量来解决复杂问题。一些库已经出现，满足有效结合生成式 AI 模型和其他工具构建**LLM**应用的要求。有几个开源框架可用于**构建**动态**LLM**应用。它们在开发尖端 LLM 应用方面提供价值。这张图显示它们随时间的流行度（数据来源：github 星标历史；[`star-history.com/`](https://star-history.com/)）：

![图 1.6：Python 中不同框架受欢迎程度的比较。我们可以看到每个项目随时间在 github 上的星星数量。](img/file14.png)

图 1.6：Python 中不同框架受欢迎程度的比较。我们可以看到每个项目随时间在 github 上的星星数量。

我们可以从图表中看到，Haystack 是比较的框架中最古老的，始于 2020 年初（根据 github 提交记录）。在 github 上，它也是最不受欢迎的。Langchain，**LlamaIndex**（之前称为 GPTIndex），以及**SuperAGI**在 2022 年末或 2023 年初开始，它们都在很短的时间内迅速走红，其中**LangChain**增长最为显著。在本书中，我们将看到为什么它的受欢迎程度正在迅速增长。**LlamaIndex**专注于高级检索，而不是**LLM**应用的更广泛方面。同样，Haystack 专注于创建大规模搜索系统，其组件专门设计用于可扩展信息检索，使用检索器、阅读器和其他数据处理程序结合通过预训练模型进行语义索引。**LangChain**擅长使用代理将**LLMs**链接在一起，用于将动作委托给模型。其用例强调及时优化和上下文感知信息检索/生成，但是由于其 Python 式高度模块化界面和庞大的工具集，它是实现复杂业务逻辑的头号工具。**SuperAGI**具有与**LangChain**类似的功能。它甚至配备了一个市场，一个工具和代理的存储库。然而，它不像**LangChain**那样广泛和得到良好支持。我没有包括**AutoGPT**（以及类似的工具如**AutoLlama**），这是一个递归应用，用于分解任务，因为它的推理能力，基于人类和 LLM 反馈，与**LangChain**相比非常有限。因此，它经常陷入逻辑循环，并经常重复步骤。我还省略了一些专注于提示工程的库，例如 Promptify。还有其他语言中的 LLM 应用框架，如 Rust、Javascript、Ruby 和 Java。例如，用 Rust 编写的 Dust 专注于 LLM 应用的设计和部署。让我们更深入地了解一下**LangChain**。

## 什么是 LangChain？

LangChain 是一个基于语言模型的应用程序开发框架，使用户能够更有效地使用**LLMs**构建应用程序。它为连接语言模型到其他数据源提供了标准接口，同时也为构建可以与环境交互的代理提供了支持。LangChain 被设计为模块化和可扩展的，使得构建适用于各种领域的复杂应用程序变得容易。LangChain 是开源的，使用 Python 编写，尽管还存在使用 JavaScript 或者更准确地说是 Typescript（LangChain.js）实现的伴随项目，以及为 Ruby 提供了 Ruby 解释器用于代码执行的新兴项目 Langchain.rb。在本书中，我们专注于该框架的 Python 版本。

> **LangChain** 是一个开源框架，允许 AI 开发人员将像 ChatGPT 这样的 LLMs 与其他计算和信息源结合在一起。

LangChain 由 Harrison Chase 于 2022 年 10 月作为一个开源项目在 github 上启动，采用 MIT 许可证，这是一种常见的许可证，允许商业使用、修改、分发和私人使用，但限制了责任和保证。LangChain 目前仍然很新，但已经拥有数百个集成和工具。在 discord 聊天服务器上有活跃的讨论，有博客，并且定期在旧金山和伦敦举行聚会。甚至有一个名为 ChatLangChain 的聊天机器人，可以回答关于 LangChain 文档的问题，该机器人是使用 LangChain 和 FastAPI 构建的，并且可以通过文档网站在线访问！该项目已经吸引了 Sequoia Capital 和 Benchmark 等公司的数百万美元的风险投资，这些公司曾为苹果、思科、谷歌、WeWork、Dropbox 等许多成功公司提供资金。LangChain 配备了许多扩展和正在围绕它发展的更大生态系统。正如前面提到的，它已经拥有大量的集成，每周还会有许多新的集成。这个截图展示了一些集成（来源：`integrations.langchain.com/trending`）：

![图 1.7：LangChain 集成。](img/file15.png)

图 1.7：LangChain 集成。

例如，LangChainHub 是一个存储库，其中包含对**LangChain**有用的工件，如提示、链和代理，它们结合在一起形成复杂的 LLM 应用程序。受 HuggingFace Hub 的启发，这是一个模型集合，旨在成为一个中央资源，用于共享和发现高质量的**LangChain**基元和应用程序。目前，该存储库仅包含一系列提示，但 - 希望 - 随着社区不断增加到这个集合，您可能很快就能找到链和代理。此外，**LlamaHub**库通过为**Google Docs**、**SQL 数据库**、**PowerPoints**、**Notion**、**Slack**和**Obsidian**等提供更多数据加载器和阅读器，扩展了 LangChain 和 LlamaIndex。**LangFlow**是一个 UI，允许通过将侧边栏组件拖放到画布上并将它们连接在一起来创建您的流水线的可执行流程图。这是一个快速尝试和原型设计流水线的方法。下面是一个基本聊天流水线的屏幕截图，其中包含一个提示模板和一个对话缓冲区作为记忆：

![图 1.8：带有基本聊天的 LangFlow UI。](img/file16.png)

图 1.8：带有基本聊天的 LangFlow UI。

在浏览器界面的侧边栏（此处未显示），您可以看到所有不同的**LangChain**组件，如零-shot 提示、数据加载器和语言模型包装器。这些流程可以直接在**LangChain**中导出和加载，也可以通过 API 调用本地服务器来调用。**LangChain**和**LangFlow**可以在本地部署，例如使用 Chainlit 库，也可以在包括 Google Cloud 在内的不同平台上部署。langchain-serve 库有助于通过单个命令将**LangChain**和**LangFlow**部署在**Jina AI 云**上作为 LLM 应用程序服务。**LangChain**提供了一个直观的框架，使开发人员、数据科学家，甚至对 NLP 技术新手来说更容易使用大型语言模型创建应用程序。值得注意的是**LangChain**既不是模型也不是提供者，而是一个促进与不同模型无缝交互的框架。使用**LangChain**，您不需要成为 AI 或复杂算法的专家 —— 它简化了流程并减少了学习曲线。

> 请注意，尽管 LangChain 的主要重点是 LLMs，这在本书中将是我们主要讨论的内容，但也有用于图像生成的集成。

通过具有数据意识和代理性，**LangChain**可以轻松集成各种数据源，包括**Google Drive**、**Notion**、**Wikipedia**、**Apify Actors**等。这种数据意识使应用程序能够根据用户偏好或来自外部来源的实时信息生成个性化和上下文相关的响应。让我们探讨一下**LangChain**为什么重要，然后它被用来做什么。

### 为什么 LangChain 很重要？

**LangChain**填补了我们在开始时概述的许多需求，包括**LLMs**的限制和**LLM**应用程序的出现。简而言之，它简化和优化了使用**LLMs**构建应用程序的开发过程。它提供了一种构建比通过 API 简单调用语言模型构建的应用程序更强大和灵活的方式。特别是，**LangChain**对代理和内存的支持允许开发人员以更复杂的方式与其环境进行交互，并且可以随时间存储和重复使用信息。**LangChain**可用于改善各种领域的应用程序的性能和可靠性。在医疗保健领域，它可以用于构建能够回答患者问题并提供医疗建议的聊天机器人。在这种情况下，我们必须非常注意信息可靠性和保密性方面的监管和道德约束。在金融领域，该框架可用于构建可以分析财务数据并进行预测的工具。在这里，我们必须考虑这些模型的可解释性。在教育领域，**LangChain**可以用于构建可以帮助学生学习新概念的工具。这可能是最令人兴奋的领域之一，LLMs 可以将完整的教学大纲分解并以定制的互动会话形式传递，个性化地适应个体学习者。**LangChain**的多功能性使其能够以几种动态方式使用，如构建能够回忆先前互动的虚拟个人助手；提取分析结构化数据集；创建提供与提供实时更新的 API 互动的问答应用程序；执行代码理解，从 GitHub 提取交互源代码，从而丰富开发人员体验并增强编码性能。使用**LangChain**有许多好处，包括：

+   **增强的灵活性**：它提供了广泛的工具和功能，用于构建强大的应用程序。此外，其模块化设计使得构建复杂应用程序变得容易，可以适应各种领域。

+   **提高性能**：支持行动计划生成可以帮助提高应用程序的性能。

+   **增强可靠性**：LangChain 对内存的支持可以通过存储和重复使用信息，以及通过访问外部信息来减少幻觉，从而提高应用程序的可靠性。

+   **开源**：开放的商业友好许可证以及庞大的开发者和用户社区意味着您可以根据自己的需求定制它，并依赖广泛的支持。

总之：有许多理由使用**LangChain**。但是，我应该警告说，由于**LangChain**仍然相当新，可能存在一些尚未解决的错误或问题。文档已经相对全面且庞大，但在某些地方还在建设中。

### 我可以用 LangChain 构建什么？

**LangChain**赋予各种 NLP 用例权力，例如虚拟助手、用于摘要或翻译的内容生成模型、问答系统等。它已被用于解决各种现实世界问题。例如，**LangChain**已被用于构建聊天机器人、问答系统和数据分析工具。它还被用于许多不同领域，包括医疗保健、金融和教育。您可以使用**LangChain**构建各种应用程序，包括：

+   **聊天机器人**：可用于构建可以以自然方式与用户交互的聊天机器人。

+   **问答**：**LangChain**可用于构建能够回答各种主题问题的问答系统。

+   **数据分析**：您可以将其用于自动化数据分析和可视化以提取见解。

+   **代码生成**：您可以设置软件对编程助手，帮助解决业务问题。

+   还有更多！

## LangChain 如何工作？

使用**LangChain**，您可以构建利用最新自然语言处理技术突破的动态应用程序。通过连接多个模块的组件（链接），您可以创建围绕大型语言模型定制的独特应用程序。从情感分析到聊天机器人，可能性是巨大的。LangChain 框架的主要价值主张包括以下部分：

+   **组件**：

    +   **模型 I/O**：此组件提供 LLM 包装器，作为连接到语言模型的标准化接口。

    +   **提示模板**：这使您可以管理和优化提示。

    +   **记忆**：索引用于在链/代理的调用之间存储和重复使用信息。

+   **代理**：代理允许 LLMs 与其环境进行交互。它们决定要采取的行动并执行该行动。

+   **链**：这些组件将组件组合在一起以解决任务。它们可以由对语言模型和其他实用程序的调用序列组成。

这里是这些部分的可视化表示：

![图 1.9：LangChain 组件。](img/file17.png)

图 1.9：LangChain 组件。

关于这些部分有很多内容需要解释。让我们稍微详细讨论一下！虽然**LangChain**本身不提供模型，但通过与各种不同语言模型提供者的**LLM**包装器进行集成，支持与聊天模型以及文本嵌入模型提供者进行交互。支持的提供者包括**OpenAI**、HuggingFace、Azure 和 Anthropic。提供标准化接口意味着可以轻松地更换模型以节省金钱和能源，或获得更好的性能。**LangChain**的核心构建块之一是提示类，允许用户通过提供简明的说明或示例与**LLMs**进行交互。提示工程有助于优化提示以获得最佳模型性能。模板在输入和可用提示集合方面提供了灵活性，在各种应用程序中经过了实战测试。当处理大型文档时，向量存储器会发挥作用，其中文档需要被分块以传递给**LLM**。文档的这些部分将被存储为嵌入，这意味着它们是信息的向量表示。所有这些工具增强了**LLMs**的知识，并提高了它们在问答和摘要等应用中的性能。有许多用于向量存储的集成。这些包括阿里巴巴云 OpenSearch、AnalyticDB for PostgreSQL、Meta AI 的 Annoy 库用于**近似最近邻**（**ANN**）**搜索**、**Cassandra**、**Chroma**、**ElasticSearch**、**Facebook** **AI 相似性搜索**（**Faiss**）、**MongoDB** **Atlas** **向量** **搜索**、**PGVector**作为**Postgres**的向量相似性搜索、**Pinecone**、**Scikit-Learn**（用于 k 最近邻搜索的`SKLearnVectorStore`），以及许多其他。还有一些其他模块包括：

+   **数据连接器和加载器**：这些组件提供了连接到外部数据源的接口。

+   **回调**：回调用于记录和流式传输任何链的中间步骤。

数据连接器包括用于存储数据和与外部系统交互的实用程序模块，如网络搜索或数据库，最重要的是数据检索。示例包括 Microsoft Doc（docx）、超文本标记语言（HTML）以及其他常见格式，如 PDF、文本文件、JSON 和 CSV。其他工具将向潜在客户发送电子邮件，向您的关注者发送有趣的双关语，或向您的同事发送 Slack 消息。让我们更详细地看看，代理可以做什么以及它们如何做出决策。

### 什么是代理？

代理在**LangChain**中用于控制应用程序的执行流程，与用户、环境和其他代理进行交互。代理可用于决定采取哪些行动，与外部数据源交互，以及随时间存储和重复使用信息。代理可以转账、预订航班，或与您的客户交谈。

> 一个**代理**是一个软件实体，可以在世界中执行动作和任务，并与其环境进行交互。在**LangChain**中，代理获取工具和链，并将它们组合以执行任务并决定使用哪个。

代理可以与外部世界建立连接。例如，可以利用搜索引擎或向量数据库来查找最新和相关的信息。然后可以将这些信息提供给模型。这被称为**检索增强**。通过整合外部信息源，**LLMs**可以从当前信息和扩展知识中汲取。这是代理如何克服**LLMs**固有弱点并通过将工具与模型结合来增强它们的一个例子。在关于**LLMs**限制的部分，我们已经看到，对于计算，一个简单的计算器胜过由数十亿参数组成的模型。在这种情况下，代理可以决定将计算传递给计算器或 Python 解释器。我们可以在这里看到一个简单的应用程序，将 OpenAI 语言模型输出连接到 Python 函数：

![chapter2/langflow_python_function.png](img/file18.png) 图 1.10：在 LangFlow 中可视化的带有 Python 函数的简单 LLM 应用程序。

我们将在*第三章*，*开始使用 LangChain*中实际看到这一点。**LangChain**中的代理可用于执行各种任务，例如：

+   搜索信息

+   调用 APIs

+   访问数据库

+   代码执行

每个代理都可以决定何时使用哪个工具。由于这对于理解**LangChain**的工作方式至关重要，让我们稍微详细地看一下这一点。

#### 动作执行

每个代理都配备了这些子组件：

+   工具，这些是功能组件，

+   工具包（这些是工具的集合），以及

+   代理执行器。

**代理执行器**是允许在工具之间进行选择的执行机制。 代理执行器可以被视为代理和执行环境之间的中介。 它接收来自代理的请求或命令，并将其翻译成可以由底层系统或软件执行的操作。 它管理这些操作的执行并向代理提供反馈或结果。 我们将看到不同类型的执行或决策模式。 **ReAct 模式**（由普林斯顿大学和 Google DeepMind 的研究人员于 2023 年 5 月发表的“ReACT：在语言模型中协同推理和行动”），简称为 Reason and Act，其中代理主动将任务分配给适当的工具，为其定制输入，并解析其输出以解决任务。 在论文中，使用了文档存储库，其中将搜索答案 - 这被实现为**ReAct 文档存储模式**。 在**LangChain**中，默认情况下，代理遵循**Zero-shot ReAct 模式**（`ZERO_SHOT_REACT_DESCRIPTION`），其中决策仅基于工具的描述。 可以通过记忆来扩展此机制，以考虑完整的对话历史。 使用**ReAct**，而不是要求**LLM**在您的文本上自动完成，您可以提示它以思考/行动/观察循环回应。 **LLM**的提示是逐步回应并将这些步骤与行动相关联。 这些步骤的结果，例如搜索结果，然后传递回**LLM**以进行下一次思考，因为它朝着目标迭代。 对于 ZeroShot 模式，提示非常重要，它是由连接前缀，描述工具及其用途的字符串，格式说明和后缀组成的：

```
PREFIX = """Answer the following questions as best you can. You have access to the following tools:"""
FORMAT_INSTRUCTIONS = """Use the following format:
Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question"""
SUFFIX = """Begin!
Question: {input}
Thought:{agent_scratchpad}"""
```

要看到这一实践，例如，我们可以询问**LangChain**代理执行器和**LangChain**执行计划之间的区别。以下是**LangChain**中的日志 - 首先问题传递给语言模型：

```
I'm not familiar with these terms, so I should search for information about them.
Action: Search
Action Input: "difference between langchain agent executor and langchain execution plan"
Observation: The Concept of Agents in LangChain Action Agents decide an action to take and execute that action one step at a time. They are more conventional and suitable for small tasks. On the other hand, Plan-and-Execute Agents first decide a plan of actions to take, and then execute those actions one at a time.
Thought:Based on the observation, a langchain agent executor is an agent that decides and executes actions one step at a time, while a langchain execution plan is an agent that first decides a plan of actions and then executes them one at a time.
Final Answer: A langchain agent executor executes actions one step at a time, while a langchain execution plan first decides a plan of actions and then executes them.
```

还有一些实施的机制。 华盛顿大学的研究人员，**MosaicAI**，Meta AI 研究和艾伦研究所（2022 年 10 月的论文“测量和缩小语言模型中的组合性差距”中）发现**LLMs**可能经常无法给出需要组合推理的问题的正确和完整答案，其中必须将多个信息片段放在一起。 **自问自答搜索**模式将问题分解为组成部分，并调用搜索引擎方法以检索必要的信息以回答问题。 用户 nkov 在 LangChain 的 github 上讨论了这种强大的机制的示例。 问题是谁活得更久，穆罕默德·阿里还是艾伦·图灵，对话发展如下：

```
Question: Who lived longer, Muhammad Ali or Alan Turing?
Are follow up questions needed here: Yes.
Follow up: How old was Muhammad Ali when he died?
Intermediate answer: Muhammad Ali was 74 years old when he died.
Follow up: How old was Alan Turing when he died?
Intermediate answer: Alan Turing was 41 years old when he died.
```

```
So the final answer is: Muhammad Ali
```

在每一步中，**LLM**决定是否需要后续搜索，并将此信息反馈给**LLM**。最近，OpenAI 模型（gpt-3.5-turbo-0613，gpt-4-0613）已经被微调以检测何时应执行**函数调用**以及应将哪些输入馈送到函数中。为了使其正常工作，函数也可以在 API 调用中描述给这些语言模型。这也在**LangChain**中实现了。在**LangChain**中，还有一些尚未（尚未）实施为执行机制的策略：

+   **递归批评和改进**其输出（**RCI**）方法（“语言模型可以解决计算机任务”；Kim 等人，2023 年 6 月）使用**LLM**作为规划者来构建一个代理，前者在执行动作之前使用**LLM**生成思路，而后者则提示 LLM 为改进后续情节思考出教训。

+   **思维树**（**ToT**）算法（由普林斯顿大学和谷歌 DeepMind 的研究人员于 2023 年 5 月发表的“思维树：使用大型语言模型进行深思熟虑的问题解决”）通过遍历搜索树推进模型推理。基本策略可以是深度优先或广度优先树遍历，然而许多其他策略也可以并且已经被测试，如最佳优先、蒙特卡洛和 A*。这些策略已被发现显著提高了问题解决的成功率。

这些决策可以提前计划或在每一步中进行。创建代理可以采取的一系列行动序列以实现目标的过程称为**行动计划生成**。根据任务所需的动态性，可以选择两种不同类型的代理通过行动计划生成：

+   **行动代理**根据所有先前行动的输出，在每次迭代中决定下一步行动。

+   **计划执行代理**在开始时决定所有行动的完整计划。然后他们执行所有这些行动而不更新顺序。这种在**LangChain**中的实现受到**BabyAGI**的启发。

一般来说，行动代理更加灵活，而计划执行代理更擅长保持长期目标。如果我们希望尽可能灵活，我们可以为我们的代理指定一个零-shot **ReAct**机制，以便在每个转弯时做出决策。现在让我们来看看链条吧！

### 什么是链条？

**LangChain**中的核心思想是**LLMs**和其他组件的组合性共同工作。例如，用户和开发人员可以将多个**LLM**调用和其他组件放在一个序列中，以创建类似聊天机器人的社交互动、数据提取和数据分析等复杂应用。

> 在最通用的术语中，**链**是一系列对组件的调用，其中可以包括其他链。

例如，提示链接是一种可以用来提高 LangChain 应用程序性能的技术。提示链接涉及将多个提示链接在一起以自动完成更复杂的响应。简而言之，链和代理都是组件的包装器。它们都可以通过使它们能够与外部系统交互并收集最新信息来扩展 LLMs 的功能。将应用程序模块化为链和代理等构建块可以使调试和维护变得更容易。链的最无害的例子可能是`PromptTemplate`，它将格式化的响应传递给语言模型。链的更有趣的例子包括用于数学查询的`LLMMath`和用于查询数据库的`SQLDatabaseChain`。这些被称为**实用链**，因为它们将语言模型与特定工具结合在一起。一些链可以做出自主决策。类似于代理，路由链可以根据其描述决定使用哪个工具。`RouterChain`可以动态选择要使用的检索系统，例如提示或索引。**LangChain** 实现链以确保输出内容不会有毒或违反 OpenAI 的管理规则（`OpenAIModerationChain`），或符合道德、法律或自定义原则（`ConstitutionalChain`）。LLMCheckerChain 可以通过验证提供的陈述和问题的基础假设来防止幻觉并减少不准确的响应。在 2023 年 5 月的一篇由卡内基梅隆大学、艾伦研究所、华盛顿大学、英伟达、加州大学圣地亚哥分校和谷歌研究人员撰写的论文（"SELF-REFINE: Iterative Refinement with Self-Feedback"）中，发现这种策略可以使任务性能平均提高约 20%。让我们来看看记忆策略！

### 什么是记忆？

**LLMs** 和工具在某种意义上是无状态的，它们不保留任何关于先前响应和对话的信息。记忆是 LangChain 中的一个关键概念，可以通过存储先前调用语言模型、用户、代理操作环境状态以及代理目标的结果来改善 LangChain 应用程序的性能。这可以帮助减少语言模型需要被调用的次数，并确保即使环境发生变化，代理也能继续运行。

> **记忆** 是一种数据结构，用于在一段时间内存储和重复使用信息。

记忆有助于为应用程序提供上下文，并使 LLM 的输出更连贯和与上下文相关。例如，我们可以存储所有对话（`ConversationBufferMemory`）或使用缓冲区保留对话中最后的消息，使用`ConversationBufferWindowMemory`。记录的消息在每次调用时都包含在模型的历史参数中。然而，我们应该注意，这将增加令牌使用量（因此增加 API 费用）和响应的延迟。这也可能影响模型的令牌限制。还有一种对话摘要记忆策略，其中 LLM 用于总结对话历史 - 这可能会导致额外的 API 调用费用。关于这些记忆选项有一些有趣的细微差别。例如，一个有趣的特性是，与 LLM 的对话可以被编码为知识图（`ConversationKGMemory`），这可以被集成回提示或用于预测响应，而无需访问 LLM。

> **知识图**是使用图结构数据模型表示数据的一种形式，通常以三元组的形式集成数据，主语、谓语和宾语，例如主语=Sam，谓语=loves，宾语=apples。这个图存储了关于实体（如人、地点或事件）及其之间关系的信息。

总之，**LangChain**中的记忆可以用于存储各种信息，包括：

+   先前对语言模型的调用结果

+   代理操作的环境状态

+   代理正在努力实现的目标。

现在，我们将看看我们可以使用的不同工具。

### 有哪些种类的工具？

工具是**LangChain**中的组件，可以与模型结合以扩展其功能。**LangChain**提供了诸如文档加载器、索引和向量存储等工具，这些工具有助于检索和存储数据，以增强**LLMs**中的数据检索。有许多可用的工具，以下只是一些示例，您可以使用工具做什么：

+   **机器翻译器**：语言模型可以使用机器翻译器更好地理解和处理多种语言的文本。这个工具使非翻译专用的语言模型能够理解并回答不同语言的问题。

+   **计算器**：语言模型可以利用简单的计算器工具解决数学问题。计算器支持基本算术运算，使模型能够准确解决专门设计用于数学问题解决的数据集中的数学查询。

+   **地图**：通过连接必应地图 API 或类似服务，语言模型可以检索位置信息，协助路线规划，提供驾驶距离计算，并提供附近景点的详细信息。

+   **天气**：天气 API 为语言模型提供全球城市的实时天气信息。模型可以回答关于当前天气状况或预测特定位置在不同时间范围内的天气的查询。

+   **股票**：连接股票市场 API（如 Alpha Vantage）使语言模型能够查询特定股票市场信息，如开盘价、收盘价、最高价、最低价等。

+   **幻灯片**：配备幻灯片制作工具的语言模型可以利用诸如 python-pptx 库提供的高级语义或根据给定主题从互联网检索图像来创建幻灯片。这些工具有助于在各种专业领域中需要的幻灯片制作任务。

+   **表格处理**：使用 pandas DataFrame 构建的 API 使语言模型能够在表格上执行数据分析和可视化任务。通过连接这些工具，模型可以为用户提供更流畅和自然的处理表格数据体验。

+   **知识图谱**：语言模型可以使用模拟人类查询过程的 API 查询知识图谱，例如查找候选实体或关系、发送 SPARQL 查询并检索结果。这些工具有助于基于知识图谱中存储的事实知识回答问题。

+   **搜索引擎**：通过利用 Bing Search 等搜索引擎 API，语言模型可以与搜索引擎互动，提取信息并回答实时查询。这些工具增强了模型从网络中收集信息并提供准确响应的能力。

+   **维基百科**：配备维基百科搜索工具的语言模型可以在维基百科页面上搜索特定实体，查找页面内的关键词，或消除具有相似名称的实体。这些工具有助于使用从维基百科检索的内容进行问答任务。

+   **在线购物**：将语言模型与在线购物工具连接起来，使其能够执行搜索商品、加载有关产品的详细信息、选择商品特性、浏览购物页面，并根据特定用户指令做出购买决策等操作。

其他工具包括 AI 绘画，允许语言模型使用 AI 图像生成模型生成图像；3D 模型构建，使语言模型能够使用先进的 3D 渲染引擎创建三维（3D）模型；化学性质，利用像 PubChem 这样的 API 解决关于化学性质的科学问题；数据库工具促进对数据库数据的自然语言访问，以执行 SQL 查询并检索结果。这些各种工具为语言模型提供了额外的功能和能力，以执行超出文本处理范围的任务。通过通过 API 连接这些工具，语言模型可以增强其在翻译、数学问题解决、基于位置的查询、天气预测、股市分析、幻灯片制作、表格处理和分析、图像生成、文本转语音转换以及许多其他专业任务领域的能力。所有这些工具都可以为我们提供先进的 AI 功能，工具几乎没有限制。我们可以轻松构建自定义工具来扩展 LLMs 的能力，正如我们将在下一章节 3 中看到的那样。使用不同的工具扩展了语言模型的应用范围，并使其能够更有效地处理各种现实世界任务。让我们总结一下！

## 总结

在当今世界，准确理解和处理语言对于开发智能应用程序以及创建个性化和有效的用户体验至关重要。因此，**大型语言模型**（**LLMs**）理想地适用于为应用程序提供这种能力。然而，正如我们在本章中讨论的那样，独立的**LLMs**存在其局限性。如果我们用工具补充**LLMs**，我们可以克服其中一些限制，并大大增强它们的性能，创建**LLM**应用程序。这就是 LangChain 的作用所在，这是一个旨在为 AI 开发人员建立代理应用程序的框架 - 这些代理由计算实体组成，如 LLMs 和其他可以自主执行某些任务的工具。我们已经讨论了它的重要概念，首先是代理和链条的概念。总之，LangChain 是一个有价值的开源框架，旨在简化使用来自 OpenAI 和 Hugging Face 等提供商和平台的**大型语言模型**（**LLMs**）开发应用程序。这个框架在释放生成式 AI 的力量方面提供了巨大价值。在接下来的章节中，我们将通过构建**LLM**应用程序来进一步发展**LangChain**的核心原则。通过利用**LangChain**的能力，开发人员可以释放**LLMs**的全部潜力。在*第三章*，*开始使用 LangChain*中，我们将使用**Langchain**实现我们的第一个应用程序！让我们看看你是否记得本章的一些关键要点！

## 问题

请看看是否能回答这些问题。如果你对任何问题不确定，我建议你回到本章的相应部分查看：

1.  LLMs 的局限性是什么？

1.  什么是 LLM 应用？

1.  什么是 LangChain，为什么你应该使用它？

1.  LangChain 的主要特点是什么？

1.  LangChain 中的代理是什么？

1.  什么是行动计划生成？

1.  什么是链？

1.  为什么 LangChain 应用需要记忆？

1.  有哪些可用的工具？

1.  LangChain 是如何工作的？
