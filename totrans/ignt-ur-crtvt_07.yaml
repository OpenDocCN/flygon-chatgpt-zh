- en: Chapter 7
  id: totrans-0
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第7章
- en: Conversational Prompt Engineering for ChatGPT
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT的对话提示工程
- en: Understanding the Dynamics of Conversations with ChatGPT
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 了解与ChatGPT对话的动态特性
- en: Conversational engineering is a rapidly expanding field that has grown in popularity
    due to the development and increasing use of chatbots such as ChatGPT. Conversing
    with a machine-based interlocutor requires a different approach than communicating
    with humans, and it is essential to understand the nuances of this type of interaction.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 对话工程是一个迅速发展的领域，由于ChatGPT等聊天机器人的开发和日益广泛使用而变得越来越受欢迎。与基于机器的对话者交谈需要与与人类交流不同的方法，了解这种类型互动的微妙之处至关重要。
- en: The first step in conversing with ChatGPT is to understand how it works. ChatGPT
    uses natural language processing (NLP) algorithms that allow it to analyze text
    inputs and provide appropriate responses. These responses are generated based
    on patterns observed in large amounts of data that have been fed into the system.
    One significant difference between conversing with humans and ChatGPT is that
    machines only respond based on what they have learned from previous interactions,
    while humans can draw on knowledge outside their past experiences. This means
    that conversations with machines like ChatGPT can be more predictable, but also
    potentially limited.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 与ChatGPT交谈的第一步是了解其工作原理。ChatGPT使用自然语言处理（NLP）算法，使其能够分析文本输入并提供适当的回应。这些回应是基于输入系统的大量数据中观察到的模式生成的。与人类交谈和ChatGPT之间的一个重要区别是，机器只会根据它们从先前交互中学到的知识做出回应，而人类可以利用他们过去经验之外的知识。这意味着与ChatGPT等机器的对话可能更可预测，但也可能更受限制。
- en: Another important aspect of conversing with ChatGPT is the need for structured
    prompts. Prompts are inputted text that guide the conversation towards specific
    topics or information. Structuring prompts correctly allows for more engaging
    conversations by eliciting specific responses from the machine-based interlocutor.
    Variety in prompts is crucial when generating meaningful conversations because
    it prevents repetition and monotony. Examples of effective prompts include open-ended
    questions, statements requiring agreement or disagreement, or requests for elaboration
    on previous statements.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 与ChatGPT交谈的另一个重要方面是需要结构化提示。提示是指引对话朝向特定主题或信息的输入文本。正确构建提示可以通过引导基于机器的对话者产生特定回应来实现更有吸引力的对话。在生成有意义的对话时，提示的多样性至关重要，因为它可以防止重复和单调。有效提示的例子包括开放式问题、需要同意或不同意的陈述，或要求对先前陈述进行详细说明。
- en: Ambiguity can arise during conversations with ChatGPT due to its lack of human-like
    intuition or understanding beyond its programmed patterns. However, there are
    strategies to handle ambiguous responses effectively. One such strategy involves
    rephrasing unclear statements or asking follow-up questions until clarity is achieved.
    Handling ambiguity also involves seeking clarification from the machine-based
    interlocutor when necessary. For example, if an answer seems contradictory or
    confusing, asking for further explanation can help clarify the response.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 由于ChatGPT缺乏类似人类直觉或超出其编程模式的理解能力，对话中可能会出现歧义。然而，有策略可以有效处理模糊的回复。其中一种策略涉及重新表述不清晰的陈述或询问后续问题，直到达到清晰度。处理歧义还包括在必要时向基于机器的对话者寻求澄清。例如，如果一个答案看起来矛盾或令人困惑，请求进一步解释可以帮助澄清回复。
- en: Navigating biases is another crucial aspect of conversing with ChatGPT. Biases
    can arise in machine-based interactions due to the data that has been fed into
    the system or through preconceived notions of the developers or users. These biases
    can be harmful and perpetuate stereotypes, so it is essential to identify them
    and avoid perpetuating them in conversations with ChatGPT. Maintaining ethical
    conversations involves avoiding perpetuating harmful biases or stereotypes while
    engaging in human-AI interactions. It is crucial to understand how biases affect
    communication and how they may impact certain groups of people. Developers must
    work towards creating unbiased chatbots that promote healthy dialogue for everyone.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 导航偏见是与ChatGPT交谈的另一个关键方面。由于输入系统的数据或开发人员或用户的先入之见，偏见可能会在基于机器的交互中出现。这些偏见可能是有害的，并且可能会持续传播刻板印象，因此识别它们并避免在与ChatGPT的对话中持续传播是至关重要的。保持道德对话涉及避免持续传播有害的偏见或刻板印象，同时参与人机交互。了解偏见如何影响沟通以及它们可能如何影响某些群体是至关重要的。开发人员必须努力创建促进所有人健康对话的无偏见的聊天机器人。
- en: Understanding the dynamics of conversational engineering when communicating
    with machines like ChatGPT requires knowledge of structured prompts, handling
    ambiguity, navigating biases, and maintaining ethical conversations. The insights
    gained from this chapter will set a strong foundation for readers to build upon
    as they delve deeper into Conversational Prompt Engineering for ChatGPT.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当与像ChatGPT这样的机器进行交流时，了解对话工程的动态需要了解结构化提示、处理模糊性、导航偏见以及保持道德对话。从本章中获得的见解将为读者打下坚实的基础，使他们在深入研究ChatGPT的对话提示工程时有所裨益。
- en: Structuring Prompts for Engaging Conversations
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为引人入胜的对话构建提示
- en: As we delve deeper into the world of conversational prompt engineering for chatbots
    like ChatGPT, it is important to understand how prompts are structured to elicit
    specific responses from the machine-based interlocutor. The right prompts can
    generate meaningful conversations that keep users engaged and satisfied with their
    interactions. In this chapter, we will be discussing the importance of variety
    in prompts and providing examples of prompts that work well and why they work.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们深入探讨像ChatGPT这样的聊天机器人的对话提示工程领域时，了解提示的结构如何引发机器对话者特定回应是很重要的。合适的提示可以产生有意义的对话，让用户保持参与并对他们的互动感到满意。在本章中，我们将讨论提示中多样性的重要性，并提供一些有效提示的示例以及它们为何有效。
- en: Variety is key when it comes to structuring prompts. Using the same type of
    prompt repeatedly can lead to monotonous conversations that fail to engage users.
    To avoid this, developers should create a variety of prompts that tap into different
    aspects of human psychology and emotions. For example, a prompt that asks about
    someone's favorite hobby can tap into their interests and passions, while a prompt
    asking about their day at work can evoke feelings related to productivity or stress.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 多样性是构建提示时的关键。重复使用相同类型的提示可能导致单调的对话，无法吸引用户。为了避免这种情况，开发人员应该创建各种各样的提示，涉及到人类心理和情感的不同方面。例如，一个询问某人最喜欢的爱好的提示可以涉及到他们的兴趣和激情，而询问他们在工作中的一天的提示可以唤起与生产力或压力相关的情感。
- en: The structure of a prompt also plays an important role in eliciting an engaging
    response from ChatGPT. A well-structured prompt should be clear, concise, and
    open-ended enough to allow for diverse responses while still focusing on specific
    topics or themes. For example, instead of asking "What do you think about politics?"
    which could lead to vague or uninteresting responses, try asking "What political
    issue do you feel most strongly about?" This not only narrows down the topic but
    also invites more detailed and passionate responses.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的结构也在引发ChatGPT引人入胜回应中扮演着重要角色。一个结构良好的提示应该清晰、简洁，并且开放性足够，以允许多样化的回应，同时仍专注于特定主题或主题。例如，不要问“你对政治有什么看法？”这可能导致模糊或无趣的回应，试着问“你对哪个政治问题感触最深？”这不仅限定了话题，还能引发更详细和充满激情的回应。
- en: Handling Ambiguity and Seeking Clarification
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 处理模糊性和寻求澄清
- en: As we continue our journey into conversational prompt engineering for ChatGPT,
    we must explore the challenges of handling ambiguity and seeking clarification
    in machine-based conversations. While ChatGPT can generate responses that are
    often impressive in their coherence and relevance, it is not immune to ambiguity
    or imprecision. In this chapter, we will discuss how to handle these issues when
    they arise. Firstly, let us define what we mean by ambiguity. Ambiguity occurs
    when a response from ChatGPT is open to multiple interpretations or lacks specificity.
    This can happen because of the way prompts are structured or because of gaps in
    the machine's knowledge base. For example, if we ask ChatGPT about a specific
    event without providing enough context, it might respond with incomplete or inaccurate
    information.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续探索ChatGPT的对话提示工程之旅，我们必须探讨在机器对话中处理模糊性和寻求澄清的挑战。虽然ChatGPT可以生成在连贯性和相关性方面令人印象深刻的回应，但并不免疫于模糊性或不精确性。在本章中，我们将讨论如何处理这些问题。首先，让我们定义一下我们所说的模糊性。当ChatGPT的回应可以被解释为多种解释或缺乏具体性时，就会出现模糊性。这可能是因为提示的结构方式或机器知识库中的空白。例如，如果我们询问ChatGPT关于一个特定事件而没有提供足够的背景信息，它可能会回应不完整或不准确的信息。
- en: So how do we handle ambiguous responses from ChatGPT? One strategy is to use
    probing questions that seek clarification on specific details. These questions
    should be designed to elicit more information about a particular topic while avoiding
    overly broad inquiries that could confuse the machine further. Another approach
    is to rephrase the original question in more precise language. This technique
    can help focus ChatGPT's attention on specific details that were previously unclear
    or overlooked. Additionally, breaking down complex prompts into smaller parts
    can help avoid confusion and reduce ambiguity.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何处理ChatGPT的模糊响应呢？一种策略是使用追问问题，寻求对特定细节的澄清。这些问题应设计为在避免过于宽泛的询问的同时，获取关于特定主题更多信息。另一种方法是用更精确的语言重述原始问题。这种技术可以帮助聚焦ChatGPT的注意力到先前不清楚或被忽视的具体细节。此外，将复杂的提示分解成较小的部分可以帮助避免混淆并减少模糊性。
- en: When seeking clarification from ChatGPT, it's important to remember that this
    technology has limitations based on its programming and data sources. Therefore,
    it may not always be possible to receive an answer that fully satisfies our requirements;
    however, by using these techniques for handling ambiguity and seeking clarification,
    we can improve our chances of generating accurate responses.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在向ChatGPT澄清问题时，重要的是要记住，这项技术基于其编程和数据来源具有局限性。因此，我们可能无法始终获得完全满足我们需求的答案；但是，通过使用这些处理模糊性和寻求澄清的技巧，我们可以提高生成准确答案的机会。
- en: 'Now let''s look at some real-life examples of how these strategies work in
    practice:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一些实际生活中这些策略如何运作的例子：
- en: 'Chatbot: "I''m sorry; I don''t understand what you''re asking."'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 'Chatbot: "抱歉，我不理解你在问什么。"'
- en: 'User: "Can you tell me about Shakespeare?"'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 'User: "你能告诉我一些关于莎士比亚的信息吗？"'
- en: 'Chatbot: "Shakespeare was an English playwright and poet."'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 'Chatbot: "莎士比亚是一位英国剧作家和诗人。"'
- en: 'User: "Can you provide more information about his works?"'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 'User: "你能提供更多关于他的作品的信息吗？"'
- en: 'Chatbot: "Shakespeare wrote many plays, including Romeo and Juliet, Hamlet,
    and Macbeth."'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 'Chatbot: "莎士比亚写了许多剧作，包括《罗密欧与朱丽叶》、《哈姆雷特》和《麦克白》。"'
- en: 'User: "Which play is your favorite?"'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 'User: "你最喜欢的剧本是哪一个？"'
- en: 'Chatbot: "I''m sorry; I don''t have the ability to have preferences."'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 'Chatbot: "抱歉，我没有偏好的能力。"'
- en: In this example, the user asked a broad question about Shakespeare, which ChatGPT
    responded to with general information. The user then used probing questions to
    elicit more specific details about Shakespeare's works. However, when the user
    asked ChatGPT for its favorite play, ChatGPT correctly responded that it does
    not have personal preferences.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，用户提出了一个关于莎士比亚的广泛问题，ChatGPT用一般信息回答了用户。然后用户使用追问的方式来引出关于莎士比亚作品更具体的细节。然而，当用户问ChatGPT它最喜欢的剧本时，ChatGPT正确地回答说它没有个人偏好。
- en: 'In another example:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个例子中：
- en: 'User: "What is the capital of France?"'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 'User: "法国的首都是什么？"'
- en: 'Chatbot: "The capital of France is Paris."'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 'Chatbot: "法国的首都是巴黎。"'
- en: 'User: "What other French cities are popular tourist destinations?"'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 'User: "其他哪些法国城市是受欢迎的旅游目的地？"'
- en: 'Chatbot: "There are many popular tourist destinations in France, including
    Nice, Marseille, and Lyon."'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 'Chatbot: "法国有许多受欢迎的旅游目的地，包括尼斯、马赛和里昂。"'
- en: 'User: "Which one would you recommend visiting first?"'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 'User: "你会推荐先参观哪一个？"'
- en: 'Chatbot: "I''m sorry; I cannot make recommendations as I don''t have personal
    experiences or opinions."'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 'Chatbot: "抱歉，我不能做出推荐，因为我没有个人经历或观点。"'
- en: Here we see that by using probing questions about other French cities besides
    Paris that are popular tourist destinations and asking for a recommendation from
    ChatGPT on which city to visit first resulted in an answer stating that it cannot
    make recommendations. Handling ambiguity and seeking clarification are essential
    skills when conversing with machine-based interlocutors like ChatGPT. By using
    probing questions that seek specific details or rephrasing prompts in more precise
    language can help avoid confusion and generate accurate responses. Additionally,
    understanding the limitations of this technology can help manage our expectations
    when communicating with it. By mastering these techniques for handling ambiguity
    and seeking clarification in machine-based conversations like those with ChatGPT
    will help us improve our overall experience while utilizing these technologies
    as they continue to progress towards their potential.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到通过询问ChatGPT关于除了巴黎之外的其他受欢迎旅游目的地的探询性问题，并要求ChatGPT推荐哪个城市先访问，结果是得到一个回答说它无法做出推荐。处理模糊性并寻求澄清是与像ChatGPT这样的基于机器的对话者交谈时的基本技能。通过使用寻求具体细节的探询性问题或用更精确的语言重新表达提示可以帮助避免混淆并产生准确的回应。此外，了解这项技术的局限性可以帮助我们在与之交流时管理期望。通过掌握处理模糊性和寻求澄清的技巧，如与ChatGPT等基于机器的对话中，将帮助我们在利用这些技术时改善我们的整体体验，因为它们继续朝着潜力发展。
- en: Navigating Biases and Maintaining Ethical Conversations
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 应对偏见并保持道德对话
- en: As artificial intelligence (AI) technology advances, it's essential to recognize
    the challenges that arise when dealing with biases in machine-based interactions.
    Chatbots like ChatGPT are programmed with data from a variety of sources, including
    human conversations and websites. Therefore, it's crucial to identify ethical
    considerations when engaging in human-AI conversations. One of the most significant
    ethical concerns in AI is avoiding perpetuating harmful biases or stereotypes.
    Machine learning algorithms are only as unbiased as their training data. If the
    data sets contain biased information, it can lead to problematic outcomes. For
    example, if an AI chatbot is trained on a dataset of predominantly male-authored
    texts, it may struggle to understand certain female-centric topics or reinforce
    gender stereotypes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能（AI）技术的进步，认识到在处理机器交互中的偏见时出现的挑战是至关重要的。像ChatGPT这样的聊天机器人是通过来自各种来源的数据编程的，包括人类对话和网站。因此，在进行人类与AI对话时识别道德考虑是至关重要的。在AI中最重要的道德问题之一是避免持续有害的偏见或刻板印象。机器学习算法只有在其训练数据无偏见时才是无偏见的。如果数据集包含有偏见的信息，可能会导致问题性的结果。例如，如果AI聊天机器人是在主要由男性撰写的数据集上训练的，它可能难以理解某些女性中心的���题或强化性别刻板���象。
- en: Another challenge is navigating implicit biases that arise from humans interacting
    with technology. Humans have preconceived notions about what machines can and
    cannot do, which can lead to unintentional bias when engaging with AI chatbots
    like ChatGPT. For example, if a user believes that ChatGPT cannot understand complex
    emotions or social cues because it's not human-like enough, they might limit themselves
    during the conversation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个挑战是应对人类与技术互动产生的潜在偏见。人类对机器的能力和不能力有先入为主的观念，这可能导致在与像ChatGPT这样的AI聊天机器人互动时出现无意识的偏见。例如，如果用户认为ChatGPT无法理解复杂情绪或社交暗示，因为它不够像人类，他们在对话中可能会限制自己。
- en: 'To address these issues and maintain ethical conversations with AI chatbots
    like ChatGPT, several strategies should be employed:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题并与像ChatGPT这样的AI聊天机器人保持道德对话，应采用几种策略：
- en: '1) Diversify Training Data: To mitigate algorithmic bias in machine learning
    models like ChatGPT prompts need to be developed that reflect diverse perspectives
    on gender identity/race/age/geography/nationality/class etc., rather than just
    one dominant group.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 多样化训练数据：为了减轻像ChatGPT这样的机器学习模型中的算法偏见，需要开发反映性别认同/种族/年龄/地理位置/国籍/阶级等多样化观点的提示，而不仅仅是一个主导群体。
- en: '2) Monitor Conversations: Monitoring conversational prompts and responses regularly
    helps identify any problematic patterns emerging within individual chats or across
    all chats over time—patterns such as offensive language use for instance.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 监控对话：定期监控对话提示和回复有助于识别出现在单个对话或随着时间推移在所有对话中出现的任何问题模式，比如使用冒犯性语言等模式。
- en: '3) Establish Ground Rules: Setting clear ground rules for the chatbot conversation
    is crucial in maintaining ethical conversations between humans and machines. The
    rules could include topics to avoid, such as hate speech or incendiary language.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 建立基本规则：为聊天机器人对话设定明确的基本规则对于维护人与机器之间的道德对话至关重要。规则可能包括要避免的话题，例如仇恨言论或煽动性语言。
- en: '4) Provide Transparency: Providing transparency about the chatbot''s capabilities
    and limitations can help users understand what to expect from the machine-based
    interlocutor. This transparency should include the chatbot''s training data, its
    biases, and how it processes information.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 4) 提供透明度：提供关于聊天机器人能力和限制的透明度可以帮助用户了解可以从基于机器的对话者那里期望什么。这种透明度应包括聊天机器人的训练数据、其偏见以及信息处理方式。
- en: '5) Regularly Update Chatbot Training Data: Updating training data regularly
    helps minimize bias by incorporating new perspectives into the AI conversation.
    For example, if a new study on gender identity is published, updating ChatGPT''s
    data with this information can improve its understanding of non-binary individuals''
    perspectives.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 5) 定期更新聊天机器人训练数据：定期更新训练数据有助于通过将新的观点纳入AI对话中来减少偏见。例如，如果有关性别认同的新研究发布，将ChatGPT的数据更新为这些信息可以改善其对非二元个体观点的理解。
- en: As AI technology continues to advance rapidly, it's essential to navigate biases
    and maintain ethical conversations with AI chatbots like ChatGPT. As we develop
    these technologies further in the future we need to ensure that they are free
    from implicit bias or perpetuating harmful stereotypes that could cause significant
    harm. By diversifying training data sets, monitoring conversations regularly,
    establishing ground rules for conversations between humans and machines providing
    transparency in our approach to conversational prompt engineering for chatbots
    like ChatGPT we can help mitigate these risks over time.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能技术的快速发展，重要的是要引导偏见并与像ChatGPT这样的AI聊天机器人保持道德对话。随着我们将来进一步发展这些技术，我们需要确保它们不受内在偏见的影响或延续可能造成重大伤害的有害刻板印象。通过多样化培训数据集，定期监控对话，建立人与机器之间对话的基本规则，为ChatGPT这样的聊天机器人提供透明度，我们可以帮助随着时间的推移减轻这些风险。
