- en: 10 The Future of Generative Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 生成模型的未来
- en: Join our book community on Discord
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的书籍社区Discord
- en: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
- en: '![Qr code Description automatically generated](../media/file65.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![二维码描述自动生成](../media/file65.png)'
- en: 'In this book, so far, we’ve discussed generative models for building applications.
    We’ve explored LLMs and image models for content creation, tool use, agent strategies,
    semantic search with retrieval augmented generation, and conditioning of models
    with prompts and fine-tuning. Further, we’ve implemented a few simple applications,
    for example, for developers and data scientists. In this chapter, we’ll discuss
    where this leaves us and where the future leads us.The pace of progress in AI
    has accelerated dramatically in the past year, with breakthroughs like DALL-E,
    Midjourney, and ChatGPT producing astounding results. These generative AI models
    can create photorealistic images, write essays and code, and have conversational
    abilities surpassing most humans. Venture funding for generative AI startups skyrocketed
    in 2022, almost matched the total investments from the previous five years combined.
    Recently, major players like Salesforce and Accenture have made big commitments
    to generative AI with multibillion dollar investments. Unique customization of
    foundation models for specific use cases is seen as the real value creation opportunity.
    But it remains uncertain which entities - big tech firms, startups, or foundation
    model developers - will capture most upside.On a technical level, generative models
    like ChatGPT often function as black boxes, with limited transparency into their
    decision-making processes. A lack of model interpretability makes it difficult
    to fully understand model behavior or to control outputs. There are also concerns
    around potential biases that could emerge from imperfect training data. On a practical
    level, generative models require extensive computational resources for training
    and deployment. For many organizations, acquiring the infrastructure to effectively
    utilize these AI systems remains a barrier.On the positive side, AI can democratize
    skills, allowing amateurs to produce professional quality output in design, writing,
    etc. Businesses can benefit from faster, cheaper, on-demand work. However, there
    are major concerns around job losses, especially for specialized middle-class
    roles like graphic designers, lawyers and doctors. Their work is being automated
    while low skilled workers learn to leverage AI as a superpower. More ominously,
    AI could be weaponized by militaries, terrorists, criminals and governments for
    propaganda and influence. Deepfakes produced in real-time will proliferate scams
    and erode trust. The path forward balances enthusiasm with practicality, prioritizing
    human dignity. By acknowledging risks, fostering open discussion, and enacting
    thoughtful policies, we can build an equitable future enabled by AI’s enlivening
    possibilities.The main sections of this chapter are:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，到目前为止，我们已经讨论了用于构建应用程序的生成模型。我们探讨了LLMs和图像模型用于内容创作，工具使用，代理策略，检索增强生成的语义搜索，以及使用提示和微调来调节模型。此外，我们实现了一些简单的应用程序，例如为开发人员和数据科学家。在本章中，我们将讨论这给我们留下了什么，未来将引领我们走向何方。人工智能领域的进展速度在过去一年中急剧加快，像DALL-E，Midjourney和ChatGPT这样的突破性成果产生了惊人的结果。这些生成式人工智能模型可以创建逼真的图像，撰写文章和代码，并具有超越大多数人类的对话能力。2022年，生成式人工智能初创公司的风险投资激增，几乎与前五年的总投资额相匹配。最近，像Salesforce和Accenture这样的主要参与者已经做出了数十亿美元的投资承诺。为特定用例定制基础模型被视为真正的价值创造机会。但目前尚不清楚哪些实体
    - 大型科技公司，初创公司或基础模型开发者 - 将获得最大的上行空间。在技术层面上，像ChatGPT这样的生成模型通常作为黑匣子运作，对其决策过程的透明度有限。模型可解释性的缺乏使得完全理解模型行为或控制输出变得困难。还存在潜在偏见可能由于不完善的训练数据而出现的担忧。在实际层面上，生成模型需要大量的计算资源进行训练和部署。对于许多组织来说，获取基础设施以有效利用这些人工智能系统仍然是一道障碍。在积极的一面，人工智能可以使技能民主化，使业余爱好者能够在设计，写作等方面产生专业质量的输出。企业可以从更快，更便宜，按需的工作中受益。然而，人们对工作岗位流失存在重大担忧，特别是对于像平面设计师，律师和医生这样的专业中产阶级角色。他们的工作正在被自动化，而低技能工人则学会利用人工智能作为超能力。更令人不安的是，人工智能可能被军事，恐怖分子，犯罪分子和政府用于宣传和影响。实时生成的Deepfakes将促使欺诈活动泛滥，并侵蚀信任。前进的道路在热情和实用性之间取得平衡，优先考虑人类尊严。通过承认风险，促进开放讨论，并实施周到的政策，我们可以建立一个由人工智能激发的公平未来。本章的主要部分包括：
- en: Current State of Generative AI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前生成式人工智能的状态
- en: Possible Future Capabilities
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能的未来能力
- en: Societal Implications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会影响
- en: Practical Implementation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际实施
- en: The Road Ahead
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未来之路
- en: Let’s start from the current state of models and their capabilities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从当前模型的状态和它们的能力开始。
- en: Current State of Generative AI
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当前生成式人工智能的状态
- en: 'As discussed in this book, in recent years, generative AI models have attained
    new milestones in producing human-like content across modalities including text,
    images, audio and video. Leading models like OpenAI’s GPT-4 and DALL-E 2, Google’s
    Imagen and Parti, and Anthropic’s Claude display impressive fluency in language
    generation along with creative visual artistry.Between 2022 and 2023, models have
    progressed in strides. If generative models were previously capable to produce
    barely coherent text or grainy images, now we see high-quality 3D models, videos,
    and generate coherent and contextually relevant prose and dialogue, rivaling or
    even surpassing the fluency levels of humans. These AI models leverage gargantuan
    datasets and computational scale, enabling them to capture intricate linguistic
    patterns, display a nuanced understanding of knowledge about the world, translate
    texts, summarize content, answer natural language questions, create appealing
    visual art, and acquire the capability to describe images. Seemingly by magic,
    the AI generated outputs mimic human ingenuity — painting original art, writing
    poetry, producing human-level prose, and even engaging in sophisticated aggregation
    and synthesis of information from diverse sources. But let’s be a bit more nuanced.
    Generative Models come with weaknesses as well as strengths. Deficiencies still
    persist compared to human cognition, including the frequent generation of plausible
    yet incorrect or nonsensical statements. Hallucinations show a lack of grounding
    in reality, given that they are based on patterns in data rather than an understanding
    of the real world. Further, models exhibit difficulties performing mathematical,
    logical, or causal reasoning. They are easily confused by complex inferential
    questions, which could limit their applicability in certain fields of work. The
    black box problem of lack of explainability for predictions as well as the models
    themselves hampers troubleshooting efforts, and controlling model behaviors within
    desired parameters remains challenging. AI models may exhibit harmful unintended
    biases that pose significant ethical concerns—a problem greatly due to the biases
    present in the training data itself. This issue of bias not only skews output
    but can propagate and amplify societal disparities.Here is a table visualizing
    the key strengths and deficiencies of current LLMs compared to human cognition:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本书所讨论的，在最近几年，生成式人工智能模型在跨越文本、图像、音频和视频等多种形式的人类内容生成方面取得了新的里程碑。领先的模型如OpenAI的GPT-4和DALL-E
    2，Google的Imagen和Parti，以及Anthropic的Claude在语言生成方面展现出令人印象深刻的流畅性和创造性视觉艺术。在2022年至2023年之间，模型取得了长足的进步。如果生成模型以前只能生成难以理解的文本或模糊的图像，现在我们看到高质量的3D模型、视频，并生成连贯和上下文相关的散文和对话，与人类的流畅水平相媲美甚至超越。这些人工智能模型利用庞大的数据集和计算规模，使它们能够捕捉复杂的语言模式，展现对世界知识的细致理解，翻译文本，总结内容，回答自然语言问题，创作吸引人的视觉艺术，并获得描述图像的能力。看似像魔术一样，人工智能生成的输出模仿了人类的创造力
    - 绘制原创艺术，写诗，生成人类水平的散文，甚至从不同来源进行复杂的信息聚合和综合。但让我们更加细致一些。生成模型也有弱点，不仅有优势。与人类认知相比，仍然存在缺陷，包括频繁生成似是而非或荒谬的陈述。幻觉显示缺乏现实基础，因为它们基于数据中的模式而不是对真实世界的理解。此外，模型在执行数学、逻辑或因果推理方面存在困难。它们很容易被复杂的推理问题搞混，这可能限制它们在某些工作领域的适用性。预测的不可解释性黑匣子问题以及模型本身阻碍了故障排除工作，控制模型行为在期望参数内仍然具有挑战性。人工智能模型可能表现出有害的意外偏见，引发重大的伦理关切
    - 这个问题很大程度上是由训练数据中存在的偏见所致。这种偏见不仅扭曲输出，还可能传播和放大社会差距。下面是一个表格，将当前LLMs的关键优势和缺陷与人类认知进行了对比：
- en: '| **Strengths of LLMs** | **Deficiencies of LLMs** |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **LLMs的优势** | **LLMs的缺陷** |'
- en: '| --- | --- |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Language Fluency - Ability to generate grammatically coherent, contextual
    prose and dialogue. GPT-4 produces human-level prose. | Factual Accuracy - LLMs
    frequently generate plausible but incorrect or nonsensical statements. Lack of
    grounding in reality. |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 语言流畅性 - 能够生成语法连贯、上下文相关的散文和对话。GPT-4能够生成人类水平的散文。 | 事实准确性 - 语言模型经常生成似是而非或荒谬的陈述。缺乏现实基础。
    |'
- en: '| Knowledge Synthesis - Sophisticated aggregation and presentation of information
    from diverse sources. | Logical Reasoning - Inability to perform mathematical,
    logical or causal reasoning. Easily confused by complex inferential questions.
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 知识综合 - 从多样化来源聚合和呈现信息的复杂过程。 | 逻辑推理 - 无法进行数学、逻辑或因果推理。容易被复杂的推理问题所困扰。 |'
- en: '| Creative Output - Imaginative and original text, art, music reflecting human
    ingenuity. Claude writes poetry, DALL-E 2 paints original art. | Controllability
    - Difficulty constraining model behaviors within desired parameters. Can exhibit
    harmful unintended biases. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 创造性输出 - 反映人类创造力的想象力和原创文本、艺术、音乐。克劳德写诗，DALL-E 2绘制原创艺术。 | 可控性 - 难以约束模型在期望参数内的行为。可能展示有害的意外偏见。
    |'
- en: '|  | Bias - Potential to propagate and amplify societal biases present in training
    data. Raises ethical concerns. |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '|  | 偏见 - 有可能传播和放大训练数据中存在的社会偏见。引发道德关切。 |'
- en: '|  | Transparency - Lack of explainability for model predictions. The "black
    box" problem limits troubleshooting. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '|  | 透明度 - 模型预测缺乏可解释性。"黑匣子"问题限制了故障排除。 |'
- en: 'Figure 10.1: Strengths and Deficiencies of LLMs.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：LLM的优势和不足。
- en: While generative AI capabilities have come a long way, their problematic areas
    need addressing for these technologies to effectively function in the future.
    Nonetheless, their profound potential indicates an exciting future if developed
    and regulated responsibly.The weaknesses of generative models define some of the
    technical challenges, as we’ll see now.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成式人工智能的能力已经取得了长足进步，但它们的问题领域需要解决，以便这些技术在未来有效地发挥作用。尽管如此，它们的深远潜力表明，如果负责任地开发和监管，将会有一个令人兴奋的未来。生成模型的弱点定义了一些技术挑战，我们现在将看到。
- en: Technical Challenges
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 技术挑战
- en: 'While rapid progress has been made, significant technical obstacles remain
    to realize the full potential of generative AI safely and responsibly. As mentioned,
    generative AI models, despite their considerable advances, are grappling with
    significant technical challenges that need to be overcome to allow their full
    potential to be harnessed safely and responsibly. We’ve discussed some of these
    issues and potential solutions in previous chapters.This table shows a summary
    for a few of these challenges together with the technical approaches to tackle
    them:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了快速进展，但要安全、负责地实现生成式人工智能的全部潜力仍然存在重大技术障碍。正如前面提到的，生成式人工智能模型尽管取得了可观的进步，但仍在应对需要克服的重大技术挑战，以允许其安全、负责地发挥全部潜力。我们已经在前几章讨论了一些这些问题和潜在解决方案。这个表格总结了其中一些挑战以及解决它们的技术方法：
- en: '| **Challenge** | **Description** | **Potential Solutions** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| **挑战** | **描述** | **潜在解决方案** |'
- en: '| --- | --- | --- |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Realistic and Diverse Content Generation | Existing models struggle with
    logical consistency and factual plausibility. Generates repetitive, bland samples
    lacking human nuance. | Reinforcement learning from human feedback Data augmentation
    and synthesis techniquesModular domain knowledge |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 生成真实和多样化内容 | 现有模型在逻辑一致性和事实合理性方面存在困难。生成的样本重复、乏味，缺乏人类细微差别。 | 从人类反馈中强化学习数据增强和合成技术模块化领域知识
    |'
- en: '| Output Quality Control | Lack of mechanisms to reliably constrain properties
    of generated content. Models sporadically produce harmful, biased or nonsensical
    results. | Constrained optimization objectivesModeration systemsInterruption and
    correction techniques |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 输出质量控制 | 缺乏可靠约束生成内容属性的机制。模型偶尔会产生有害、偏见或荒谬的结果。 | 有限的优化目标调节系统中断和纠正技术 |'
- en: '| Avoiding Bias | Models inadvertently amplify societal biases present in training
    data. Developing techniques to curtail prejudice remains difficult. | Balanced
    and representative training dataBias mitigation algorithmsOngoing testing and
    audits |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 避免偏见 | 模型无意中放大了训练数据中存在的社会偏见。开发技术来遏制偏见仍然困难。 | 平衡和代表性的训练数据偏见缓解算法持续测试和审计 |'
- en: '| Factual Accuracy | Inability to reason about objective truths limits reliability
    for real-world applications. Grounding models in common sense and physics is an
    open problem. | Incorporating knowledge basesHybrid neuro-symbolic architecturesRetrieval
    augmented generation |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 事实准确性 | 无法推理客观真理限制了在现实世界应用中的可靠性。将模型基于常识和物理知识是一个未解之谜。 | 结合知识库混合神经符号结构检索增强生成
    |'
- en: '| Explainability | The opaque behavior of large neural networks poses hurdles
    for troubleshooting failures or bias, necessitating explainable AI techniques.
    | Model introspection techniquesConcept attribution methodsSimplified model architectures
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 可解释性 | 大型神经网络的不透明行为对故障排除或偏见提出了障碍，需要可解释的人工智能技术。 | 模型内省技术概念归因方法简化模型架构 |'
- en: '| Data Privacy | Collecting and processing massive datasets raises challenges
    around consent, anonymization, access control and misuse of data. | Differential
    privacy and secure multi-party computationSynthetic data generationFederated learning
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 数据隐私 | 收集和处理大规模数据集带来了关于同意、匿名化、访问控制和数据滥用的挑战。 | 差分隐私和安全多方计算合成数据生成联邦学习 |'
- en: '| Latency and Compute | Deploying huge models requires substantial computing
    resources, delaying real-time interactivity needed for many applications. | Model
    distillation into smaller form factorsOptimized inference enginesDedicated AI
    hardware accelerators |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 延迟和计算 | 部署庞大模型需要大量计算资源，延迟了许多应用程序所需的实时交互性。 | 模型压缩为更小的形式优化推理引擎专用人工智能硬件加速器 |'
- en: '| Data Licenses | Organizations may need to obtain a commercial license to
    use existing datasets or to build bespoke datasets to train generative models.
    This can be a complex and time-consuming process. | Open-source and synthetic
    data |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 数据许可 | 组织可能需要获得商业许可来使用现有数据集或构建定制数据集以训练生成模型。这可能是一个复杂和耗时的过程。 | 开源和合成数据 |'
- en: 'Figure 10.2: Technical Challenges and Potential Solutions.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：技术挑战和潜在解决方案。
- en: 'Primarily, the content generated by these models is often hindered by a lack
    of realism and diversity. While they have displayed impressive abilities to mimic
    human-like language and creativity, they still falter when it comes to producing
    content that is logically consistent and factually plausible. Their outputs often
    lack human nuance turning out to be quite repetitive and bland. Potential solutions
    include reinforcement learning from human feedback to improve coherence and nuance,
    controlled data augmentation and synthesis techniques, and architectures incorporating
    modular domain knowledge.Another critical hurdle is the control of output quality.
    Despite rigorous training and development, existing AI mechanisms fall short in
    reliably constraining properties of the generated content. This results in sporadic
    production of content that can be harmful, biased or outright nonsensical, posing
    a risk to their wider acceptance and application. Promising approaches involve
    constrained optimization objectives, human-in-the-loop moderation systems, and
    techniques to interrupt and correct model output during generation.Bias is indeed
    a major issue with these AI models as they frequently and inadvertently amplify
    societal prejudices present in their training data. Developing corrective techniques
    to curtail such biases remains a complicated issue. Strategies like balanced and
    representative training data, bias mitigation algorithms, and ongoing testing
    and audits for fairness seek to address this problem.The inability of these AI
    models to reason about objective truths noticeably limits their reliability for
    real-world applications. Grounding these models in common sense and physics represents
    an open problem that the AI community is still grappling with. Hybrid neuro-symbolic
    architectures, incorporation of knowledge bases, and retrieval augmented generation
    offer promising directions.The black box nature of AI presents another complex
    challenge: explainability. The opaque behavior of large neural networks poses
    hurdles for troubleshooting failures or bias, which emphasizes the need for more
    transparent AI techniques. Model introspection, concept attribution methods, and
    simplified model architectures could provide solutions.Furthermore, the issue
    of data privacy rises to prominence due to the collection and processing of extensive
    datasets. This aspect introduces challenges around consent, anonymization, access
    control and misuse of data. Techniques like differential privacy, secure multi-party
    computation, synthetic data generation, and federated learning may help address
    privacy risks.Last but not least, deploying these enormous models demands substantial
    computing resources, leading to significant latency and compute issues. This could
    delay the real-time interactivity required for many applications, indicating that
    efficiency improvements are key. Solutions involve model distillation into smaller
    form factors, optimized inference engines, and dedicated AI hardware accelerators.Looking
    ahead, generative AI systems are poised to become more powerful and multifaceted.
    Let’s see how!'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 主要问题在于，这些模型生成的内容往往缺乏现实感和多样性。虽然它们展示了模仿人类语言和创造力的令人印象深刻的能力，但在产生逻辑一致和事实可信的内容方面仍然表现不佳。它们的输出往往缺乏人类的细微差别，变得相当重复和乏味。潜在的解决方案包括通过人类反馈进行强化学习以提高连贯性和细微差别，控制数据增强和合成技术，以及融合模块化领域知识的架构。另一个关键障碍是控制输出质量。尽管经过严格的训练和开发，现有的人工智能机制在可靠地约束生成内容的属性方面仍然存在不足。这导致内容的零星生产可能是有害的、带有偏见的或完全荒谬的，对其更广泛的接受和应用构成风险。有希望的方法包括受限制的优化目标、人机协同的调节系统以及在生成过程中中断和纠正模型输出的技术。这些人工智能模型存在偏见的问题确实是一个重要问题，因为它们经常无意中放大其训练数据中存在的社会偏见。开发纠正偏见的技术仍然是一个复杂的问题。诸如平衡和代表性训练数据、偏见缓解算法以及为公平性进行持续测试和审计的策略旨在解决这一问题。这些人工智能模型无法推理客观真理的能力明显限制了它们在现实世界应用中的可靠性。将这些模型基于常识和物理学进行基础化代表着人工智能社区仍在努力解决的一个悬而未决的问题。混合神经符号架构、知识库的整合以及检索增强生成提供了有希望的方向。人工智能的黑匣子性质带来了另一个复杂的挑战：可解释性。大型神经网络的不透明行为给故障排除或偏见带来了障碍，这强调了更透明的人工智能技术的需求。模型内省、概念归因方法以及简化的模型架构可能提供解决方案。此外，由于收集和处理大量数据集，数据隐私问题变得突出。这一方面引入了关于同意、匿名化、访问控制和数据滥用的挑战。差分隐私、安全多方计算、合成数据生成和联邦学习等技术可能有助于解决隐私风险。最后但并非最不重要的是，部署这些庞大模型需要大量的计算资源，导致显著的延迟和计算问题。这可能会延迟许多应用所需的实时互动性，表明效率改进至关重要。解决方案涉及将模型精简为更小的形式因子、优化推理引擎以及专用人工智能硬件加速器。展望未来，生成式人工智能系统有望变得更加强大和多样化。让我们拭目以待！
- en: Possible Future Capabilities
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可能的未来能力
- en: 'The current doubling time in training compute of very large models is about
    8 months, outstripping scaling laws such as Moore’s Law (transistor density at
    cost increases at a rate of currently about 18 months) or Rock’s Law (costs of
    hardware like GPUs and TPUs halve every 4 years).This graph illustrates this trend
    in training compute of large models (Source: Epoch, *Parameter, Compute and Data
    Trends in Machine Learning*. Published online at epochai.org. Retrieved from:
    https://epochai.org/mlinputs/visualization):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 目前非常大型模型的训练计算翻倍时间约为 8 个月，超过了摩尔定律（晶体管密度成本每约 18 个月增加一倍）或洛克定律（像 GPU 和 TPU 这样的硬件成本每
    4 年减半）等缩放定律。这张图表展示了大型模型训练计算的这一趋势（来源：Epoch，《机器学习中的参数、计算和数据趋势》。在线发表于 epochai.org。检索自：https://epochai.org/mlinputs/visualization）：
- en: '![Figure 10.3: Training FLOPs of notable AI systems.](../media/file66.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3：知名人工智能系统的训练 FLOPs。](../media/file66.png)'
- en: 'Figure 10.3: Training FLOPs of notable AI systems.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3：知名人工智能系统的训练 FLOPs。
- en: As discussed in chapter 1, parameter sizes for large systems have been increasing
    at a similar rate as the training compute, which means that we could be seeing
    much larger and more expensive systems if this growth continues. Empirically derived
    scaling laws predict the performance of LLMs based on the training budget, dataset
    size, and the number of parameters. This could mean that highly powerful systems
    would be concentrated in the hands of Big Tech.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正如第 1 章讨论的那样，大型系统的参数大小增长速度与训练计算相似，这意味着如果这种增长持续下去，我们可能会看到更大更昂贵的系统。经验推导的缩放定律根据训练预算、数据集大小和参数数量预测了
    LLMs 的性能。这可能意味着高度强大的系统将集中在大科技公司手中。
- en: The **KM scaling** law, proposed by Kaplan and colleagues, derived through empirical
    analysis and fitting of model performance with varied data sizes, model sizes,
    and training compute, presents power-law relationships, indicate a strong dependence,
    between model performance and factors such as model size, dataset size, and training
    compute.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**KM 缩放**定律，由卡普兰和同事提出，通过对模型性能与不同数据大小、模型大小和训练计算进行经验分析和拟合得出，呈现出幂律关系，表明模型性能与模型大小、数据集大小和训练计算等因素之间存在强烈依赖关系。'
- en: ''
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The **Chinchilla scaling law**, developed by the Google DeepMind team, involved
    experiments with a wider range of model sizes and data sizes, and suggests an
    optimal allocation of compute budget to model size and data size, which can be
    determined by optimizing a specific loss function under a constraint.
  id: totrans-43
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Chinchilla 缩放定律**，由谷歌 DeepMind 团队开发，涉及对更广泛范围的模型大小和数据大小进行实验，并建议将计算预算最优分配给模型大小和数据大小，这可以通过在约束条件下优化特定损失函数来确定。'
- en: 'However, future progress may depend more on data efficiency and model quality
    than sheer size. Though massive models grab headlines, computing power and energy
    constraints put a limit on unrestrained model growth. The future will see co-existence
    of massive, general models with smaller and accessible specialized niche models
    that provide faster and cheaper training, maintenance, and inference. It has already
    been shown that smaller specialized models can prove highly performant. We’ve
    recently seen models such as phi-1 (*Textbooks Are All You Need*, 2023, Gunasekar
    and colleagues), on the order of 1 billion parameters, that – despite its smaller
    scale – achieve high accuracy on evaluation benchmarks. The authors suggest that
    improving data quality can dramatically change the shape of scaling laws.More
    work has shown that models can be substantially smaller with only a modest drop
    in accuracy (*One Wide Feedforward is All You Need*, Pessoa Pires and others,
    2023), which supports the argument for a democratization of model training and
    access. Further, techniques such as transfer learning, distillation and prompting
    techniques can enable smaller models to leverage capabilities of large foundations
    without replicating their costs. In order to compensate for limitations, tools
    like search engines and calculators have been incorporated into agents and multi-step
    reasoning strategies, plugins, and extensions may be increasingly used to expand
    capabilities.AI training costs are dropping because of different factors – according
    to ARK Investment Management LLC, about 70% per year. A recently released AI training
    tools by Mosaic ML can train language models to GPT-3 level performance for roughly
    one-tenth the estimated $4.6 million just two years ago. This will enable experimentation,
    but advances will increasingly emerge from training regimes, data quality, and
    novel architectures rather than model size alone. After an arms race dominated
    by resource-rich big tech firms, responsible, economical innovation may become
    the priority.In a timeframe of 3-5 years (2025-2027), constraints around computing
    and talent availability could ease considerably, eroding the centralized moat.
    Specifically, if cloud computing costs decline as projected, and AI skills become
    more widespread through education and automated tools, self-training customized
    LLMs may become feasible for many companies. This could better serve needs for
    personalization and data privacy.Some abilities, however, such as in-context learning,
    are not predictable according to the scaling laws and only emerge in large models.
    It has been further speculated that enormous models trained on even more data
    may exhibit more behaviors and skills, where extreme scaling could eventually
    produce **artificial general intelligence** (**AGI**) – reasoning on par or beyond
    human intellect. However, from a neuroscience perspective, the threat of AGI taking
    over the world seems highly exaggerated at our present stage of technology (compare
    Jaan Aru and others, *The feasibility of artificial consciousness through the
    lens of neuroscience*; 2023):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，未来的进展可能更多地取决于数据效率和模型质量，而不是纯粹的规模大小。尽管庞大的模型抓住了头条，但计算能力和能源限制限制了模型无限增长的可能性。未来将会看到庞大的通用模型与更小、可访问的专业化细分模型共存，这些模型提供更快、更便宜的训练、维护和推理。已经有证据表明，更小的专业化模型可以表现出很高的性能。我们最近看到了像phi-1（*只需教科书*，2023年，Gunasekar和同事）这样的模型，拥有约10亿个参数，尽管规模较小，但在评估基准上取得了高准确度。作者建议，改善数据质量可以显著改变规模定律的形状。更多的工作表明，模型可以大幅缩小，只有轻微的准确度下降（*只需一个宽度前馈*，Pessoa
    Pires等人，2023年），这支持了模型训练和访问的民主化的论点。此外，转移学习、蒸馏和提示技术等技术可以使更小的模型利用大型基础的能力，而不会复制它们的成本。为了弥补限制，搜索引擎和计算器等工具已经被整合到代理人和多步推理策略、插件和扩展中，这些工具可能越来越多地用于扩展功能。由于不同因素的影响，AI训练成本正在下降
    - 根据ARK Investment Management LLC的数据，每年约下降70%。最近发布的Mosaic ML的AI训练工具可以将语言模型训练到GPT-3级别的性能，成本大约是两年前估计的460万美元的十分之一。这将促进实验，但进步将越来越多地来自训练制度、数据质量和新颖的架构，而不仅仅是模型大小。在由资源丰富的大型科技公司主导的军备竞赛之后，负责任、经济的创新可能成为优先考虑的事项。在3-5年的时间范围内（2025-2027年），围绕计算和人才可用性的限制可能会大大缓解，侵蚀中心化的壕沟。具体来说，如果云计算成本如预期般下降，而通过教育和自动化工具使AI技能更加普及，自我训练定制的LLM可能对许多公司变得可行。这可以更好地满足个性化和数据隐私的需求。然而，一些能力，如上下文学习，根据规模定律是不可预测的，只会在大型模型中出现。进一步推测，即使在更多数据上训练的巨大模型可能会展现出更多的行为和技能，极端扩展最终可能会产生**人工通用智能**（**AGI**）-
    推理能力与甚至超越人类智慧。然而，从神经科学的角度来看，AGI接管世界的威胁在我们目前的技术阶段似乎被高度夸大（参见Jaan Aru等人，*通过神经科学的视角探讨人工意识的可行性*；2023年）。
- en: '**Lack of embodied, embedded information**: LLMs today are trained purely on
    textual data rather than the rich multimodal inputs that allow humans to develop
    common sense reasoning about the physical world. This absence of grounded learning
    poses a major obstacle to developing human-level intelligence.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏具体化、嵌入式信息**：今天的LLM仅仅是在文本数据上进行训练，而不是像人类那样通过丰富的多模态输入来发展对物理世界的常识推理。这种缺乏基础学习对于发展人类水平的智能构成了重大障碍。'
- en: '**Different architecture from biological brains**: The relatively simple stacked
    transformer architecture used in models like GPT-4 lacks the complex recurrent
    and hierarchical structures of the thalamocortical system thought to enable consciousness
    and general reasoning in humans.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与生物大脑不同的架构**：像GPT-4这样的模型使用的相对简单的堆叠变压器架构缺乏被认为能够使人类具有意识和一般推理能力的复杂的循环和分层结构。'
- en: '**Narrow capabilities**: Existing models remain specialized for particular
    domains like text and fall short in flexibility, causal reasoning, planning, social
    skills, and general problem-solving intelligence. This could change either with
    increasing tool use or with fundamental changes to the models.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**狭窄的能力**：现有模型仍然专门针对特定领域（如文本）而设计，在灵活性、因果推理、规划、社交技能和一般问题解决智能方面存在不足。这可能会随着工具使用的增加或模型的根本性变化而改变。'
- en: '**Minimal social abilities or intent**: Current AI systems have no innate motivations,
    social intelligence, or intent beyond their training objectives. Fears of malicious
    goals or desire for domination seem unfounded.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社交能力或意图的最小化**：当前的人工智能系统没有固有的动机、社交智能或超出其训练目标的意图。对恶意目标或对统治欲望的担忧似乎是没有根据的。'
- en: '**Limited real-world knowledge**: Despite ingesting huge datasets, the factual
    knowledge and common sense of large models remains very restricted compared to
    humans. This impedes applicability in the physical world.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的现实世界知识**：尽管摄入了大量数据集，大型模型的事实知识和常识与人类相比仍然非常有限。这阻碍了在现实世界中的适用性。'
- en: '**Data-driven limitations**: Reliance on pattern recognition from training
    data rather than structured knowledge makes reliable generalization to novel situations
    difficult.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据驱动的局限性**：依赖于训练数据中的模式识别，而不是结构化知识，使得可靠地推广到新情况变得困难。'
- en: Given these arguments, the risk of today’s AI precipitously evolving into malicious
    superintelligence seems highly improbable. That said, thoughtfully addressing
    longer-term safety research and ethics remains prudent as capabilities continue
    advancing. But fears of imminent world takeover are not substantiated by evidence
    from neuroscience or current model capabilities. Therefore, claims of inevitable,
    imminent AGI lack rigorous support.However, the sheer pace of advancement creates
    unease surrounding human obsolescence and job displacement, which could further
    divide economic classes. Unlike physical automation of the past, generative AI
    threatens cognitive job categories previously considered safe from automation.
    Managing this workforce transition ethically and equitably will require foresight
    and planning. There are also philosophical debates around whether AI should be
    creating art, literature or music that has historically reflected the human condition.
    Let’s think a bit more broadly about the societal impact!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些论点，今天的人工智能迅速演变为恶意超级智能的风险似乎是极不可能的。尽管如此，随着能力的不断提升，深思熟虑地处理长期安全研究和伦理问题仍然是明智的。但是，根据神经科学或当前模型能力的证据，对即将到来的世界占领的恐惧并没有实质性的支持。因此，对必然、即将到来的人工通用智能的断言缺乏严格的支持。然而，快速的进步速度引发了对人类过时和工作岗位流失的担忧，这可能进一步分化经济阶层。与过去的物理自动化不同，生成式人工智能威胁到以前被认为不会被自动化取代的认知工作类别。以道德和公平的方式管理这种工作力量的过渡将需要远见和规划。关于人工智能是否应该创作反映人类状况的艺术、文学或音乐也存在哲学上的争论。让我们更广泛地思考社会影响吧！
- en: Societal Implications
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社会影响
- en: The advent of highly capable generative AI will likely transform many aspects
    of society in coming years. As generative models continue to develop and add value
    to businesses and creative projects, generative AI will shape the future of technology
    and human interaction across domains. While their widespread adoption brings forth
    numerous benefits and opportunities for businesses and individuals, it is crucial
    to address the ethical and societal concerns that arise from increasing reliance
    on AI models in various fields.Generative AI offers immense potential benefits
    across personal, societal, and industrial realms if deployed thoughtfully. At
    a personal level, these models can enhance creativity and productivity, and increase
    accessibility to services like healthcare, education and finance. Democratizing
    access to knowledge resources, they can help students learn or aid professionals
    make decisions by synthesizing expertise. As virtual assistants, they provide
    instant, customized information to facilitate routine tasks. By automating rote
    tasks, they may free up human time for higher-value work, boosting economic output.
    Economically, the gains in productivity will most likely result in massive disruptions
    of certain job categories. New industries and jobs may emerge to support AI systems.
    Thoughtfully considering and addressing these changes is crucial. As models become
    better and running them becomes cheaper, this could trigger a massive expansion
    of generative AI and LLM applications to new areas. On top of the reduction in
    hardware costs, with every cumulative doubling of AI systems produced, costs may
    fall by 10-30% according to Wright’s Law. This cost curve reflects efficiencies
    like reuse of code, tools and techniques. A virtuous cycle arises as lower costs
    expand adoption, which drives further cost reductions. This will lead to a feedback
    cycle of more efficiency driving more use driving more efficiency.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 高度能力的生成式人工智能的出现可能会在未来几年改变社会的许多方面。随着生成模型的不断发展并为企业和创意项目增加价值，生成式人工智能将塑造技术和人类互动在各个领域的未来。尽管它们的广泛采用为企业和个人带来了许多好处和机会，但关键是要解决由于在各个领域对AI模型的依赖增加而引起的伦理和社会问题。如果慎重部署，生成式人工智能在个人、社会和工业领域都具有巨大的潜在好处。在个人层面，这些模型可以增强创造力和生产力，并增加对医疗保健、教育和金融等服务的可访问性。通过民主化获取知识资源，它们可以帮助学生学习或帮助专业人士通过综合专业知识做出决策。作为虚拟助手，它们提供即时、定制的信息以便于完成日常任务。通过自动化机械性任务，它们可能释放出人类时间用于更有价值的工作，从而提高经济产出。在经济上，生产率的增长很可能会导致某些工作类别的巨大变革。新的行业和工作可能会出现以支持AI系统。慎重考虑和解决这些变化是至关重要的。随着模型变得更好，运行它们变得更便宜，这可能会引发生成式人工智能和LLM应用到新领域的大规模扩展。除了硬件成本的降低外，根据赖特定律，随着每累积生产的AI系统翻倍，成本可能会降低10-30%。这种成本曲线反映了代码、工具和技术的重复使用等效率。随着成本的降低扩大采用，进一步降低成本的循环将产生良性循环。这将导致更多效率驱动更多使用，进而驱动更多效率的反馈循环。
- en: '**Wright’s Law**, also known as the **experience curve effect**, is an observation
    in economics and business that states that for many products, costs decline by
    a fixed percentage each time cumulative production doubles. Specifically, it states
    that costs tend to decrease by a fixed percentage (typically ranging from 10-30%)
    for each cumulative doubling of production.'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**赖特定律**，也被称为**经验曲线效应**，是经济学和商业领域的一个观察，它指出对于许多产品，每当累积生产翻倍时，成本都会按固定百分比下降。具体来说，它指出每当生产累积翻倍时，成本往往会按固定百分比（通常在10-30%之间）下降。'
- en: ''
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The law is named after Theodore Paul Wright, an American aircraft engineer who
    first observed this phenomenon in 1936 when analyzing trends in aircraft production
    costs. Wright noticed that every time the cumulative production of airframes doubled,
    the labor required to produce them decreased by 10-15%.
  id: totrans-56
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该定律以西奥多·保罗·赖特（Theodore Paul Wright）的名字命名，他是一位美国飞机工程师，1936年首次观察到这一现象，当时他分析了飞机生产成本的趋势。赖特注意到，每当飞机机身的累积生产翻倍时，生产所需的劳动力就会减少10-15%。
- en: ''
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This relationship can be expressed mathematically as:'
  id: totrans-58
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这种关系可以用数学方式表达为：
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../media/file67.png)'
  id: totrans-60
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_IMG
  zh: '![](../media/file67.png)'
- en: ''
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Where *C*[1] represents the cost to produce the first unit, *C*[*x*] the cost
    to produce the xth unit, and b is the progress ratio, which has been estimated
    across numerous industries between 0.75 to 0.9.
  id: totrans-62
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其中*C*[1]代表生产第一单位的成本，*C*[*x*]代表生产第x单位的成本，b是进步比率，据估计在许多行业中介于0.75至0.9之间。
- en: ''
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The logic behind Wright’s Law is that as production increases, workers become
    more efficient in manufacturing a product through practice, standardized workflows,
    and developing better tools and processes. Companies also identify ways to optimize
    supply chains, logistics and resource utilization to reduce costs.
  id: totrans-64
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Wright定律背后的逻辑是随着生产量的增加，工人通过实践、标准化工作流程以及开发更好的工具和流程，在制造产品方面变得更加高效。公司还会找到优化供应链、物流和资源利用的方法，以降低成本。
- en: Industrially, the models bring extensive opportunities to augment human capabilities
    and remake workflows. In content production, generative AI can draft initial versions
    for marketing campaigns or journalistic pieces faster than humans, enabling greater
    creativity and customization. For developers, autogenerated code and rapid iterations
    accelerate software building. Researchers can quickly synthesize discoveries from
    papers to advance science.Generative AI also facilitates new levels of personalization
    at scale for consumers. Recommendations can be tailored down to the individual.
    Marketing across segments and geographies can be customized. Overall, these models
    can enhance productivity across sectors from industrial design to supply chains.As
    for the spread of the technology, two primary scenarios exist. In the first scenario,
    each company or individual trains their own tailored model using their proprietary
    data. However, this requires considerable AI/ML expertise to properly develop,
    train and deploy such systems - talent that remains scarce and expensive currently.
    The computational costs are also extremely high, with specialized hardware like
    clusters of GPUs costing substantial sums only feasible for large entities. There
    are further risks around data privacy compliance when models are trained on sensitive
    information. If these barriers around expertise, computing requirements and data
    privacy can be overcome, personalized LLMs fine-tuned to an organization’s particular
    goals and data could significantly enhance their productivity and efficiency by
    automating routine tasks and offering insights customized to the specific business.
    However, a downside is that models trained on small, private datasets may lack
    the generalization capability of those trained on much larger diverse public corpuses.Both
    centralized and self-service models can co-exist serving different use cases.
    In the near term, large tech firms have strengths in providing industry-specific
    fine-tuning services given their resources. But over time, more in-house training
    may emerge driven by customization and privacy needs.The pace of progress on reducing
    costs, spreading expertise, and addressing robustness challenges will determine
    how long any centralized advantage persists. Rapid innovations in these areas
    favor erosion of the moat, but platform effects around dominant frameworks, datasets
    and models could enable continued concentration among current leaders.If robust
    tools emerge to simplify and automate AI development, custom generative models
    may even be viable for local governments, community groups, and individuals to
    address hyper-local challenges. While centralized Big Tech firms benefit currently
    from economies of scale, distributed innovation from smaller entities could unlock
    generative AI’s full potential across all sectors of society.Finally, the emergence
    of generative AI intersects with broader shifts in how we produce and consume
    creative works. The internet has already fostered a remix culture where derivative
    works and collaborative content creation are commonplace. As AI models generate
    new artifacts by recombining existing materials, they align with remix culture
    principles of iterative, collective production.However, the scale at which generative
    models can synthesize and repurpose copyrighted content raises challenging legal
    questions. With models trained on vast datasets of books, articles, images and
    more, attributing rights and royalties could become incredibly complex. Current
    detection mechanisms are unable to find content authored by generative AI at above
    chance level. This speaks to wider debates surrounding authorship and copyright
    law.Let’s look at the different aspects, where generative models will have profound
    near-term impacts, starting with creative endeavors.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在工业领域，这些模型为增强人类能力和重塑工作流程带来了广泛的机会。在内容生产方面，生成式人工智能可以比人类更快地起草营销活动或新闻报道的初始版本，从而实现更大的创造力和定制化。对于开发人员，自动生成的代码和快速迭代加速了软件构建。研究人员可以快速从论文中综合发现以推动科学进步。生成式人工智能还为消费者提供了规模化的新个性化水平。推荐可以量身定制到个人。跨领域和地理区域的营销可以定制。总的来说，这些模型可以提高从工业设计到供应链等各个领域的生产率。至于技术的传播，存在两种主要情景。在第一种情景中，每家公司或个人使用其专有数据训练自己定制的模型。然而，这需要相当多的人工智能/机器学习专业知识来正确开发、训练和部署这些系统
    - 目前这种人才仍然稀缺且昂贵。计算成本也非常高，专门的硬件如GPU集群的成本巨大，只有大型实体才能承担。当模型基于敏感信息进行训练时，还存在数据隐私合规方面的风险。如果能够克服围绕专业知识、计算需求和数据隐私的障碍，针对组织特定目标和数据进行微调的个性化LLMs可以通过自动化例行任务和提供定制的见解显著提高其生产力和效率。然而，一个缺点是基于小型私有数据集训练的模型可能缺乏那些基于更大、更多样化的公共语料库训练的模型的泛化能力。集中化和自助式模型可以共存，为不同的用例提供服务。在短期内，大型科技公司在提供行业特定的微调服务方面具有优势。但随着时间的推移，更多的内部培训可能会出现，受定制化和隐私需求驱动。在降低成本、传播专业知识和解决稳健性挑战方面的进展速度将决定任何集中化优势持续存在的时间。在这些领域的快速创新有利于消除壕沟，但围绕主导框架、数据集和模型的平台效应可能使当前领导者继续集中。如果出现简化和自动化人工智能开发的强大工具，定制的生成模型甚至可能适用于地方政府、社区团体和个人解决超局部挑战。尽管目前大型科技公司受益于规模经济，但来自较小实体的分布式创新可能会释放生成式人工智能在社会各个领域的全部潜力。最后，生成式人工智能的出现与我们如何生产和消费创意作品的更广泛转变相交汇。互联网已经培育了一个混搭文化，其中衍生作品和协作内容创作司空见惯。当人工智能���型通过重新组合现有材料生成新的作品时，它们符合混搭文化的迭代、集体生产原则。然而，生成模型可以合成和重新利用受版权保护内容的规模引发了复杂的法律问题。随着模型在大量书籍、文章、图片等数据集上进行训练，归因权和版税可能变得极其复杂。目前的检测机制无法以高于偶然水平的准确率找到由生成式人工智能创作的内容。这反映了围绕作者身份和版权法的更广泛辩论。让我们看看生成模型将在哪些方面产生深远的近期影响，从创意努力开始。
- en: Creative industries and advertising
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创意产业和广告
- en: The gaming and entertainment industries are leveraging generative AI to craft
    uniquely immersive user experiences. Major efficiency gains from automating creative
    tasks could increase leisure time spent online. Generative AI can enable machines
    to generate new and original content, such as art, music, and literature, by learning
    from patterns and examples. This has implications for creative industries, as
    it can enhance the creative process and potentially create new revenue streams.
    It also unlocks new scales of personalized, dynamic content creation for media,
    film, and advertising. However, generative content requires extensive quality
    control around accuracy and eliminating biases before full deployment.For media,
    film, and advertising, AI unlocks new scales of personalized, dynamic content
    creation. In journalism, automated article generation using massive datasets can
    free up reporters to focus on more complex investigative stories. **AI-generated
    content** (**AIGC**) is playing a growing role in transforming media production
    and delivery by enhancing efficiency and diversity. In journalism, text generation
    tools automate writing tasks traditionally done by human reporters, significantly
    boosting productivity while maintaining timeliness. Media outlets like Associated
    Press generate thousands of stories per year using AIGC. Robot reporters like
    Los Angeles Times’ Quakebot can swiftly produce articles on breaking news. Other
    applications include Bloomberg News’ Butletin service where chatbots create personalized
    one-sentence news summaries. AIGC also enables AI news anchors that co-present
    broadcasts with real anchors by mimicking human appearance and speech from text
    input. Chinese news agency Xinhua’s virtual presenter Xin Xiaowei is an example,
    presenting broadcasts from different angles for an immersive effect.AIGC is transforming
    movie creation from screenwriting to post-production. AI screenwriting tools analyze
    data to generate optimized scripts. Visual effects teams blend AI-enhanced digital
    environments and de-aging with live footage for immersive visuals. Deep fake technology
    recreates or revives characters convincingly.AI also powers automated subtitle
    generation, even predicting dialogue in silent films by training models on extensive
    audio samples. This expands accessibility via subtitles and recreates voiceovers
    synchronized to scenes. In post-production, AI color grading and editing tools
    like Colourlab.Ai and Descript simplify processes like color correction using
    algorithms.In advertising, AIGC unlocks new potential for efficient, customized
    advertising creativity and personalization. AI-generated content allows advertisers
    to create personalized, engaging ads tailored to individual consumers at scale.
    Platforms like Creative Advertising System (CAS) and Personalized Advertising
    Copy Intelligent Generation System (SGS-PAC) leverage data to automatically generate
    ads with messaging targeted to specific user needs and interests.AI also assists
    in advertising creativity and design – Tools like Vinci produce customized attractive
    posters from product images and slogans, while companies like Brandmark.io generate
    logo variations based on user preferences. GAN technologies automate product listing
    generation with keywords for effective peer-to-peer marketing. Synthetic ad production
    is also on the rise, enabling highly personalized, scalable campaigns that save
    time.In music, tools like Google’s Magenta, IBM’s Watson Beat, or Sony CSL’s Flow
    Machine can generate original melodies and compositions. AIVA similarly creates
    unique compositions from parameters tuned by users. LANDR’s AI mastering uses
    machine learning to process and improve digital audio quality for musicians.In
    visual arts, MidJourney uses neural networks to generate inspirational images
    that can kickstart painting projects. Artists have used its outputs to create
    prize-winning works. DeepDream’s algorithm imposes patterns on images, creating
    psychedelic art. GANs can generate abstract paintings converging on a desired
    style. AI painting conservation analyzes artwork to digitally repair damage and
    restore pieces.Animation tools like Adobe’s Character Animator or Anthropic’s
    Claude can help with the generation of customized characters, scenes and motion
    sequences opening animation potential for non-professionals. ControlNet adds constraints
    to steer diffusion models, increasing output variability. For all these applications,
    advanced AI expands creative possibilities through both generative content and
    data-driven insights. It is important to note however that generative content
    requires extensive quality control around accuracy and eliminating biases before
    full deployment. For advertising, ethical use of consumer data and human oversight
    remain important. In all cases, properly attributing contributions of human artists,
    developers and training data remains an ongoing challenge as adoption spreads.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏和娱乐行业正在利用生成式人工智能来打造独特沉浸式的用户体验。通过自动化创意任务，可以实现主要效率提升，增加在线休闲时间。生成式人工智能可以使机器通过学习模式和示例生成新的原创内容，如艺术、音乐和文学。这对创意产业有着重要影响，因为它可以增强创意过程，潜在地创造新的收入来源。它还为媒体、电影和广告开启了新的个性化、动态内容创作规模。然而，在完全部署之前，生成内容需要围绕准确性和消除偏见进行广泛的质量控制。对于媒体、电影和广告，人工智能开启了新的个性化、动态内容创作规模。在新闻业中，利用大规模数据集自动生成文章可以释放记者，让他们专注于更复杂的调查报道。**AI生成内容**（**AIGC**）在转变媒体制作和传递方面发挥着越来越重要的作用，提高了效率和多样性。在新闻业中，文本生成工具自动化了传统由人类记者完成的写作任务，显著提高了生产率，同时保持及时性。像美联社这样的媒体机构每年利用AIGC生成数千篇报道。像洛杉矶时报的Quakebot这样的机器记者可以迅速撰写有关突发新闻的文章。其他应用包括彭博新闻的Butletin服务，其中聊天机器人创建个性化的一句新闻摘要。AIGC还可以实现AI新闻主播，通过模仿人类外观和从文本输入中产生的语音与真实主播一起共同主持广播。中国新闻机构新华社的虚拟主持人辛小薇就是一个例子，以不同角度呈现广播，产生沉浸式效果。AIGC正在从剧本创作到后期制作改变电影创作。AI剧本创作工具分析数据以生成优化的剧本。视觉效果团队将AI增强的数字环境和去老化技术与实景影像融合，产生沉浸式视觉效果。深度伪造技术可以逼真地重现或复活角色。AI还可以实现自动生成字幕，甚至通过在广泛音频样本上训练模型来预测无声电影中的对话。这通过字幕扩大了可访问性，并重新创建与场景同步的配音。在后期制作中，AI调色和编辑工具如Colourlab.Ai和Descript使用算法简化了诸如颜色校正之类的流程。在广告领域，AIGC开启了有效、定制广告创意和个性化的新潜力。AI生成内容使广告商能够以规模化的方式创建个性化、引人入胜的广告，针对个别消费者。像创意广告系统（CAS）和个性化广告文案智能生成系统（SGS-PAC）这样的平台利用数据自动生成针对特定用户需求和兴趣的广告信息。AI还协助广���创意和设计——像Vinci这样的工具可以根据产品图像和口号生成定制的吸引人海报，而像Brandmark.io这样的公司则根据用户偏好生成标志变体。GAN技术自动化产品清单生成，为有效的点对点营销提供关键词。合成广告制作也在兴起，实现高度个性化、可扩展的广告活动，节省时间。在音乐领域，像谷歌的Magenta、IBM的Watson
    Beat或索尼CSL的Flow Machine可以生成原创旋律和作曲。AIVA同样可以根据用户调整的参数创建独特的作品。LANDR的AI母带使用机器学习处理和改善音频质量，为音乐人提供帮助。在视觉艺术领域，MidJourney使用神经网络生成启发性图像，可以启动绘画项目。艺术家们已经利用其输出创作了获奖作品。DeepDream的算法在图像上施加模式，创造出迷幻艺术。GAN可以生成符合所需风格的抽象画作。AI绘画修复分析艺术品以数字修复损坏并恢复作品。动画工具如Adobe的Character
    Animator或Anthropic的Claude可以帮助生成定制角色、场景和动作序列，为非专业人士打开动画潜力。ControlNet添加约束以引导扩散模型，增加输出的变化性。对于所有这些应用，先进的人工智能通过生成内容和数据驱动的见解扩展了创意可能性。然而，值得注意的是，生成内容在完全部署之前需要围绕准确性和消除偏见进行广泛的质量控制。对于广告业，消费者数据的道德使用和人类监督仍然很重要。在所有情况下，正确归因于人类艺术家、开发人员和训练数据的贡献仍然是一个持续的挑战，因为采用范围不断扩大。
- en: Economic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 经济
- en: 'The deployment of generative AI and other technologies could help accelerate
    productivity growth, partially compensating for declining employment growth and
    enabling overall economic growth. Assuming energy and computing can scale sustainably,
    the huge productivity gains from integrating generative AI into business processes
    seem likely to usher automation of many tasks over the next decade. However, this
    transition may disrupt labor markets, requiring adjustments. Research by McKinsey
    and Company estimates 30-50% of current work activities could be automated by
    2030-2060\. Generative AI could boost global productivity by $6-8 trillion annually
    by 2030, adding 15-40% onto previous estimates for AI’s economic impact. According
    to Tyna Eloundou and colleagues (*GPTs are GPTs: An Early Look at the Labor Market
    Impact Potential of Large Language Models*, 2023) around 80% of US workers have
    at least 10% of work tasks affected by LLMs, while 19% may have over 50% of tasks
    impacted. Effects span all wage levels, with higher-wage jobs facing more exposure.
    Just 15% of all US worker tasks could be done significantly faster with LLMs alone.
    But with LLM-powered software, this increases to 47-56% of all tasks, showing
    the big impact of complementary technologies.From a geographic perspective, external
    private investment in generative AI, mostly from tech giants and venture capital
    firms, is largely concentrated in North America, reflecting the continent’s current
    domination of the overall AI investment landscape. Generative AI–related companies
    based in the United States raised about $8 billion from 2020 to 2022, accounting
    for 75 percent of total investments in such companies during that period.Automation
    adoption is likely to be faster in developed economies, where higher wages will
    make it economically feasible sooner. The scale of work automation does not directly
    equate to job losses. Like other technologies, generative AI typically enables
    individual activities within occupations to be automated, not entire occupations.
    However, organizations may decide to realize the benefits of increased productivity
    by reducing employment in some job categories.Productivity growth, the main engine
    of GDP growth over the past 30 years, slowed down in the past decade. The deployment
    of generative AI and other technologies could help accelerate productivity growth,
    partially compensating for declining employment growth and enabling overall economic
    growth. Based on estimates by analysts at McKinsey and Company, the automation
    of individual work activities could provide the global economy with an annual
    productivity boost of 0.2 to 3.3 percent from 2023 to 2040 depending on the rate
    of automation adoption, however, only if individuals affected by the technology
    were to shift to other work activities that at least match their 2022 productivity
    levels.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '部署生成式人工智能和其他技术可以帮助加快生产力增长，部分弥补就业增长下降并促进整体经济增长。假设能源和计算能够可持续扩展，将生成式人工智能整合到业务流程中所带来的巨大生产力增益似乎可能在未来十年内推动许多任务的自动化。然而，这种转变可能会扰乱劳动力市场，需要进行调整。麦肯锡公司的研究估计，到2030-2060年，当前工作活动的30-50%可能会被自动化。生成式人工智能到2030年每年可能会为全球生产力增长6-8万亿美元，为人工智能经济影响的先前估计增加15-40%。根据Tyna
    Eloundou及其同事的研究（*GPTs are GPTs: An Early Look at the Labor Market Impact Potential
    of Large Language Models*, 2023），大约80%的美国工人的工作任务至少有10%受到大型语言模型的影响，而19%可能有超过50%的任务受到影响。影响涵盖所有工资水平，高薪工作面临更多风险。仅有15%的美国工人任务可以通过大型语言模型显著加快完成。但是，通过大型语言模型驱动的软件，这一比例增加到所有任务的47-56%，显示了辅助技术的巨大影响。从地理角度来看，生成式人工智能的外部私人投资主要来自科技巨头和风险投资公司，主要集中在北美，反映了该大陆目前在整体人工智能投资领域的主导地位。总部位于美国的生成式人工智能相关公司在2020年至2022年期间筹集了约80亿美元，占该期间此类公司总投资的75%。自动化采用在发达经济体中可能会更快，因为较高的工资将使其更早地在经济上可行。工作自动化的规模并不直接等同于失业。与其他技术一样，生成式人工智能通常使职业中的个别活动自动化，而不是整个职业。然而，组织可能会决定通过减少某些工作类别的就业来实现增加生产力的好处。在过去30年中，生产力增长一直是GDP增长的主要引擎，但在过去十年中放缓。部署生成式人工智能和其他技术可以帮助加快生产力增长，部分弥补就业增长下降并促进整体经济增长。根据麦肯锡公司分析师的估计，从2023年到2040年，个别工作活动的自动化可能会为全球经济每年提供0.2至3.3%的生产力提升，取决于自动化采用率，然而，前提是受到技术影响的个人能够转移到其他工作活动，至少与他们2022年的生产力水平相匹配。'
- en: Education
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 教育
- en: One potential near-future scenario is that the rise of personalized AI tutors
    and mentors could democratize access to education for high-demand skills aligned
    with an AI-driven economy. In the education sector, generative AI is already transforming
    how we teach and learn. Tools like ChatGPT can be used to automatically generate
    personalized lessons and customized content for individual students. This reduces
    instructor workloads substantially by automating repetitive teaching tasks. AI
    tutors provide real-time feedback on student writing assignments, freeing up teachers
    to focus on more complex skills. Virtual simulations powered by generative AI
    can also create engaging, tailored learning experiences adapted to different learners’
    needs and interests.However, risks around perpetuating biases and spreading misinformation
    need to be studied further as these technologies evolve. The accelerating pace
    of knowledge and the obsolescence of scientific findings means that training children’s
    curiosity-driven learning should focus on developing the cognitive mechanisms
    involved in initiating and sustaining curiosity, such as awareness of knowledge
    gaps and the use of appropriate strategies to resolve them.While AI tutors tailored
    to each student could enhance outcomes and engagement, poorer schools may be left
    behind, worsening inequality. Governments should promote equal access to prevent
    generative AI from becoming a privilege of the affluent. Democratizing opportunity
    for all students remains vital.If implemented thoughtfully, personalized AI-powered
    education could make crucial skills acquisition accessible to anyone motivated
    to learn. Interactive AI assistants that adapt courses to students’ strengths,
    needs and interests could make learning efficient, engaging and equitable. But
    challenges around access, biases, and socialization need addressing.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个潜在的近期未来场景是，个性化人工智能导师和导师的崛起可能使得对齐人工智能驱动经济的高需求技能的教育变得民主化。在教育领域，生成式人工智能已经在改变我们的教学和学习方式。像ChatGPT这样的工具可以用来自动生成个性化课程和定制内容给个别学生。这通过自动化重复的教学任务大大减轻了教师的工作量。人工智能导师可以对学生的写作作业提供实时反馈，让教师有更多时间专注于更复杂的技能。由生成式人工智能驱动的虚拟模拟也可以创造引人入胜、量身定制的学习体验，适应不同学习者的需求和兴趣。然而，随着这些技术的发展，需要进一步研究围绕着持续存在偏见和传播错误信息的风险。知识的加速增长和科学发现的过时意味着培养孩子们的好奇心驱动学习应该专注于发展启动和维持好奇心所涉及的认知机制，比如意识到知识空白和使用适当策略来解决它们。虽然为每个学生量身定制的人工智能导师可能会增强结果和参与度，但贫困学校可能会被落下，加剧不平等。政府应该促进平等获取，以防止生成式人工智能成为富裕阶层的特权。民主化机会对所有学生仍然至关重要。如果经过深思熟虑实施，个性化人工智能驱动的教育可以使任何有学习动力的人获得关键技能。交互式人工智能助手可以根据学生的优势、需求和兴趣调整课程，使学习高效、引人入胜和公平。但是，需要解决关于获取、偏见和社会化的挑战。
- en: Jobs
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作
- en: 'Assuming energy and computing can scale sustainably, the huge productivity
    gains from integrating generative AI into business processes seem likely to usher
    automation of many tasks over the next decade. This transition may disrupt labor
    markets, requiring adjustments.Automation enabled by AI will likely displace many
    administrative, customer service, writing, legal, and creative jobs in the near
    term, while professions in agriculture and construction might be virtually unaffected.
    However, past industrial revolutions ultimately led to new types of jobs and industries,
    albeit with difficult workforce transitions. The same dynamic is likely to play
    out with AI automation over the long run. This will impact almost all occupations
    to some degree, though some will be affected more heavily. Generative AI’s ability
    to analyze and generate natural language content could significantly increase
    the automation potential for activities like communicating, collaborating and
    reporting across many white-collar occupations. However, the extent to which entire
    jobs are eliminated remains uncertain. Past technological innovations ultimately
    created new types of work, even if the transitions were difficult.According to
    research at McKinsey and company, about 75 percent of the value that generative
    AI use cases could deliver falls across four areas: Customer operations, marketing
    and sales, software engineering, and R&D. Prominent examples include generative
    AI’s ability to support interactions with customers, generate creative content
    for marketing and sales, and draft computer code based on natural-language prompts,
    among many other tasks.Language models and Generative AI carry the potential to
    disrupt and automate tasks within various industries that were traditionally performed
    by humans. As for different roles, these predictions seem credible:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 假设能源和计算能够可持续扩展，将生成AI整合到业务流程中带来的巨大生产力增益似乎可能在未来十年内推动许多任务的自动化。这种转变可能会扰乱劳动力市场，需要进行调整。由AI实现的自动化可能会在短期内取代许多行政、客户服务、写作、法律和创意工作，而农业和建筑行业的专业可能几乎不受影响。然而，过去的工业革命最终导致了新类型的工作和产业，尽管劳动力转变困难。相同的动态可能会在长期内随着AI自动化发生变化。这将在某种程度上影响几乎所有职业，尽管有些受影响更严重。生成AI分析和生成自然语言内容的能力可能会显著增加像沟通、协作和报告等许多白领职业的自动化潜力。然而，整个工作被消除的程度仍然不确定。过去的技术创新最终创造了新类型的工作，即使转变困难。根据麦肯锡公司的研究，生成AI用例可能提供的价值约75%分布在四个领域：客户运营、市场营销和销售、软件工程和研发。突出的例子包括生成AI支持与客户互动、为市场营销生成创意内容以及根据自然语言提示起草计算机代码，以及许多其他任务。语言模型和生成AI具有颠覆和自动化传统由人类执行的各行业任务的潜力。至于不同的角色，这些预测似乎可信：
- en: Junior software engineers may be augmented or replaced by AI coding assistants.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初级软件工程师可能会被AI编码助手增强或取代。
- en: Analysts and advisors utilizing data insights from AI Customer service agents
    replaced by conversational AI.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析师和顾问利用AI数据洞察。客户服务代理被对话AI取代。
- en: Technical writers and journalists aided by AI content generation.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术撰稿人和记者受益于AI内容生成。
- en: Teachers leveraging AI for course prep and personalized tutoring.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教师利用AI进行课程准备和个性化辅导。
- en: Paralegals utilizing AI for summarization and document review.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法律助理利用AI进行摘要和文件审查。
- en: Graphic designers will be empowered by AI image generation, however, making
    image creation and manipulation available to many more people could also have
    an impact on wages.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图形设计师将受益于AI图像生成，然而，使图像创建和处理对更多人可用也可能对工资产生影响。
- en: However, demand will remain strong for senior software engineers to develop
    specialized AI solutions and systems.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，对于开发专门的AI解决方案和系统的高级软件工程师的需求将保持强劲。
- en: Data scientists may pivot from building predictive models to focusing more on
    validating, debugging and maximizing value from AI systems.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家可能会从构建预测模型转向更多地专注于验证、调试和从AI系统中最大化价值。
- en: Programmers will increasingly code tools to assist AI development.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序员将越来越多地编写工具来辅助AI开发。
- en: New roles like prompt engineering have started to emerge.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新角色如提示工程师已经开始出现。
- en: AI can perform certain tasks that extend to tasks involving natural language
    processing, content creation, and even intricate creative work, efficiently and
    with fewer errors than humans. Less skilled individuals may be able to perform
    more highly skilled work, while highly skilled individuals may be left with fewer
    job opportunities. For example, paralegals use boilerplate documents and fill
    in the necessary information to cater to clients’ needs. AI, equipped with vast
    knowledge of legal documents, legislation, university courses, journals, news
    articles, and court cases, can perform this task even better than paralegals.
    The result is a potential decrease in the need for junior lawyers for drafting
    purposes, with paralegals using AI-powered software to communicate clients’ specific
    requirements.Software developers and data scientists alike can benefit from the
    potential of LLMs but must carefully consider its capabilities and limitations
    for optimal use. For junior developers and data scientists, LLMs can automate
    routine tasks, provide basic solutions, and reduce errors, accelerating learning
    by freeing up time for more complex work. However, relying solely on AI risks
    hindering deeper technical growth, so LLMs should be seen as supportive tools
    while actively developing hands-on expertise.Senior developers and data scientists
    possess domain knowledge and problem-solving abilities beyond current AI capabilities.
    While automating standard solutions may save some time, their expertise is essential
    for guiding AI tools, ensuring reliable and scalable outcomes.The surge in AI
    productivity means that companies are in high demand for AI talent, and the competition
    for hiring and retaining this talent is fierce. There will also be a growing need
    for cybersecurity professionals who can protect AI systems from attack. Additionally,
    as AI systems become more prevalent, there may be more work in areas such as AI
    ethics, regulation, and public policy. Hence, investing in attracting and nurturing
    such talent is significant for companies to remain relevant in this rapidly evolving
    landscape.Creators in all sectors will be affected. In music, AI is aiding musicians
    across the creative process, from composing lyrics and melodies to digitally mastering
    and enhancing audio. Generative art tools allow visual artists to experiment with
    customized paintings catered to their unique styles.A Goldman Sachs study from
    March 2023 suggested that administrative and legal roles are most at risk. They
    estimated that about two thirds of current jobs will be exposed to automation
    by AI, and concluded that generative AI tools could impact 300 million full-time
    jobs worldwide, more than 20% of the current workforce. The pace of adoption is
    a critical unknown. McKinsey analysts estimated that automation could absorb between
    60 to 70 percent of employee hours so that between 2030 and 2060 about half of
    today’s work activities could be automated. According to PwC, by the mid-2030s,
    up to 30% of jobs could be automatable. But real-world adoption depends on many
    hard-to-predict factors like regulation, social acceptance and retraining policies.Knowledge
    work sectors such as software and app development are already seeing the effects
    of this transformation. Generative AI has been employed to streamline tasks ranging
    from initial code generation to image editing and design. It reduces repetitive
    manual work for developers and designers, enabling them to focus their efforts
    on higher-value innovation. However, meticulous monitoring and iterative correction
    of errors in auto-generated outputs remains critical.The large-scale automation
    of work activities could result in a major shift in labor demand, leading to substantial
    changes in occupation and necessitating employees to acquire new skills. Because
    their capabilities are fundamentally engineered to do cognitive tasks, Generative
    AI is likely to have the biggest impact on knowledge work, particularly activities
    involving decision making and collaboration, which previously had the lowest potential
    for automation. While previously, automation’s impact was highest in lower-middle-income
    quintiles, Further, Generative AI could have the biggest impact on activities
    in high-wage jobs. A significant number of workers will need to substantially
    change the work they do, either in their existing occupations or in new ones.
    They will also need support in making transitions to new activities.Managing this
    turnover will require policy foresight to minimize hardship for displaced workers
    through retraining programs, job creation incentives and portable benefits. If
    worker transitions and other risks can be managed, generative AI could contribute
    substantively to economic growth and support a more sustainable, inclusive world,
    where people are liberated from repetitive work.If the efficiency gains from AI
    automation are reinvested well, new industries and jobs could be created in the
    long run. But smooth workforce transitions will require policy foresight and employee
    training in the interim. In summary, while certain jobs may be displaced by AI
    in the near term, especially routine cognitive tasks, it may automate certain
    activities rather than eliminate entire occupations. Technical experts like data
    scientists and programmers will remain key to developing AI tools and realizing
    their full business potential.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能可以执行一些任务，涵盖自然语言处理、内容创作，甚至复杂的创意工作，效率高，错误少于人类。技能较低的人可能能够执行更高技能的工作，而技能较高的人可能会面临较少的工作机会。例如，法律助理使用模板文件并填写必要信息以满足客户需求。拥有广泛法律文件、法规、大学课程、期刊、新闻文章和法院案例知识的人工智能，可以比法律助理做得更好。结果可能是对初级律师起草工作需求的潜在减少，法律助理使用人工智能软件来传达客户特定需求。软件开发人员和数据科学家都可以从LLMs的潜力中受益，但必须仔细考虑其能力和限制以实现最佳利用。对于初级开发人员和数据科学家，LLMs可以自动化例行任务，提供基本解决方案，减少错误，通过释放更多时间进行更复杂的工作来加速学习。然而，仅依赖人工智能可能会阻碍更深入的技术增长，因此LLMs应被视为支持性工具，同时积极开发实践经验。高级开发人员和数据科学家拥有超出当前人工智能能力的领域知识和解决问题能力。虽然自动化标准解决方案可能节省一些时间，但他们的专业知识对于指导人工智能工具、确保可靠和可扩展的结果至关重要。人工智能生产力的激增意味着公司急需人工智能人才，对于招聘和留住这些人才的竞争激烈。还将需要更多能够保护人工智能系统免受攻击的网络安全专业人员。此外，随着人工智能系统变得更加普及，可能会在人工智能伦理、监管和公共政策等领域出现更多工作。因此，吸引和培养这类人才对于公司在这个快速发展的领域保持相关性至关重要。所有领域的创作者都将受到影响。在音乐领域，人工智能正在帮助音乐人完成整个创作过程，从创作歌词和旋律到数字化母带处理和增强音频。生成艺术工具允许视觉艺术家尝试定制绘画，以迎合其独特风格。2023年3月高盛的一项研究表明，行政和法律角色最容易受到影响。他们估计约三分之二的当前工作岗位将面临人工智能自动化，得出结论称生成人工智能工具可能会影响全球3亿全职工作岗位，占当前劳动力的20%以上。采用速度是一个关键未知因素。麦肯锡分析师估计，自动化可能吸收员工工作时间的60%至70%，因此在2030年至2060年间，大约有一半的今天的工作活动可能会被自动化。根据普华永道的数据，到2030年代中期，高达30%的工作可能是可自动化的。但现实世界的采用取决于许多难以预测的因素，如监管、社会接受和再培训政策。软件和应用开发等知识工作领域已经看到了这种转变的影响。生成人工智能已被用于简化从初始代码生成到图像编辑和设计的任务。它减少了开发人员和设计师的重复手动工作，使他们能够将精力集中在更有价值的创新上。然而，对自动生成输出中的错误进行细致监控和迭代更正仍然至关重要。大规模自动化工作活动可能导致劳动力需求的重大转变，从而导致职业发生重大变化，迫使员工获得新技能。由于它们的能力基本上是为了执行认知任务而设计的，生成人工智能可能会对知识工作产生最大影响，特别是涉及决策和协作的活动，这些活动以前的自动化潜力最低。以前，自动化的影响主要集中在中低收入五分位数，此外，生成人工智能可能会对高薪工作的活动产生最大影响。大量工人将需要在现有职业或新职业中进行实质性的工作变革。他们还需要支持来进行过渡到新活动。管理这种变革将需要政策远见，以最小化对被解雇工人的困难，通过再培训计划、创造就业激励措施和可转移的福利。如果能够很好地重新投资人工智能自动化带来的效率收益，长期内可能会创造新的产业和就业机会。但顺利的劳动力转变将需要政策远见和员工培训。总之，虽然在短期内可能会有一些工作被人工智能取代，特别是例行认知任务，但它可能会自动化某些活动，而不是消灭整个职业。数据科学家和程序员等技术专家将继续是开发人工智能工具和实现其完整商业潜力的关键。
- en: Law
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 法律
- en: Generative models like LLMs can automate routine legal tasks such as contract
    review, documentation generation, and brief preparation. They also enable faster,
    comprehensive legal research and analysis. Additional applications include explaining
    complex legal concepts in plain language and predicting litigation outcomes using
    case data. However, responsible and ethical use remains critical given considerations
    around transparency, fairness and accountability. Overall, properly implemented
    AI tools promise to boost legal productivity and access to justice, while requiring
    ongoing scrutiny regarding reliability and ethics.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型如LLMs可以自动化例行法律任务，如合同审查、文件生成和简要准备。它们还可以加快全面的法律研究和分析。其他应用包括用通俗语言解释复杂的法律概念，以及利用案例数据预测诉讼结果。然而，考虑到透明度、公平性和问责制等因素，负责任和道德的使用仍然至关重要。总体而言，正确实施的人工智能工具有望提高法律生产力和司法准入，同时需要持续审查可靠性和伦理问题。
- en: Manufacturing
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 制造业
- en: In the automotive sector, they are employed to generate 3D environments for
    simulations and aid in the development of cars. Additionally, generative AI is
    utilized for road testing autonomous vehicles using synthetic data. These models
    can also process object information to comprehend the surrounding environment,
    understand human intent through dialogues, generate natural language responses
    to human input, and create manipulation plans to assist humans in various tasks.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在汽车行业，它们被用于生成用于模拟的3D环境，并帮助汽车的开发。此外，生成式人工智能被用于使用合成数据对自动驾驶车辆进行道路测试。这些模型还可以处理物体信息以理解周围环境，通过对话了解人类意图，生成对人类输入的自然语言响应，并制定操纵计划以协助人类完成各种任务。
- en: Medicine
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 医学
- en: A model that can accurately predict physical properties from gene sequences
    would represent a major breakthrough in medicine and could have profound impacts
    on society. It could further accelerate drug discovery and precision medicine,
    enable earlier disease prediction and prevention, provide a deeper understanding
    of complex diseases, and improve gene therapies. However, it also raises major
    ethical concerns around genetic engineering and could exacerbate social inequalities.New
    techniques with neural networks are already employed to lower long-read DNA sequencing
    error rates (Baid and colleagues; *DeepConsensus improves the accuracy of sequences
    with a gap-aware sequence transformer*, September 2022), and according to a report
    by ARK Investment Management (2023), in the short-term, technology like this can
    make it already possible to deliver the first high-quality, whole long-read genome
    for less than $1,000\. This means that large-scale gene-to-expression models might
    not be far away either.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一个能够准确预测基因序列中的物理特性的模型将是医学上的重大突破，并可能对社会产生深远影响。它还可以进一步加速药物发现和精准医学，实现更早的疾病预测和预防，提供对复杂疾病的更深入理解，并改善基因治疗。然而，这也引发了围绕基因工程的重大伦理关切，并可能加剧社会不平等。神经网络已经被用于降低长读DNA测序错误率（Baid等人；*DeepConsensus改进了具有间隙感知序列变换器的序列的准确性*，2022年9月），根据ARK投资管理公司的报告（2023年），在短期内，这样的技术已经可以以不到1000美元的价格交付第一个高质量的完整长读基因组。这意味着大规模的基因到表达模型也可能不会太远。
- en: Military
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 军事
- en: Militaries worldwide are investing in research to develop lethal autonomous
    weapons systems (LAWS). Robots and drones can identify targets and deploy lethal
    force without any human supervision. Machines can process information and react
    faster than humans, removing emotion from lethal decisions. However, this raises
    significant moral questions. Allowing machines to determine if lives should be
    taken crosses a troubling threshold. Even with sophisticated AI, complex factors
    in war like proportionality and distinction between civilians and combatants require
    human judgment.If deployed, completely autonomous lethal weapons would represent
    an alarming step towards relinquishing control over life-and-death decisions.
    They could violate international humanitarian law or be used by despotic regimes
    to terrorize populations. Once unleashed fully independently, the actions of autonomous
    killer robots would be impossible to predict or restrain.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 全球各军事力量正在投资研究开发致命的自主武器系统（LAWS）。机器人和无人机可以在没有任何人类监督的情况下识别目标并部署致命力量。机器可以比人类更快地处理信息并做出反应，从致命决策中消除情感。然而，这引发了重大的道德问题。让机器决定是否应该夺取生命越过了一个令人不安的界限。即使使用了复杂的人工智能，战争中的比例和平民与战斗人员之间的区别等复杂因素仍需要人类判断。如果部署，完全自主的致命武器将代表放弃对生死决策的控制迈出令人震惊的一步。它们可能违反国际人道主义法，或被专制政权用来恐吓人口。一旦完全独立释放，自主杀手机器人的行动将无法预测或约束。
- en: Misinformation and cybersecurity
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 虚假信息和网络安全
- en: AI presents a dual-edged sword against disinformation. While it enables scalable
    detection, automation makes it easier to spread sophisticated, personalized propaganda.
    AI could help or harm security depending on whether it is used responsibly. It
    increases vulnerabilities to misinformation along with cyberattacks using generative
    hacking and social engineering. There are significant threats associated with
    AI techniques like micro-targeting and deepfakes. Powerful AI can profile users
    psychologically to deliver personalized disinformation that facilitates concealed
    manipulation, escaping broad examination Big data and AI could be leveraged to
    exploit psychological vulnerabilities and infiltrate online forums to attack and
    spread conspiracy theories. Disinformation has transformed into a multifaceted
    phenomenon, involving biased information, manipulation, propaganda, and intent
    to influence political behavior. For example, during the COVID-19 pandemic, the
    spread of misinformation and infodemics has been a major challenge. AI has a potential
    to influence public opinion on topics like elections, war, or foreign powers.It
    can also generate fake audio/video content to damage reputations and sow confusion.
    State and non-state actors are weaponizing these capabilities for propaganda,
    to damage reputations and sow confusion. AI can be used by political parties,
    governments, criminal groups, and even the legal system, launch lawsuits, and
    extract money. This likely will have far-reaching consequences in various domains.
    A significant portion of internet users may be obtaining the information they
    need without accessing external websites. There is a danger of large corporations
    being the gatekeepers of information and controlling public opinion, effectively
    being able to restrict certain actions or viewpoints.Careful governance and digital
    literacy are essential to build resilience. Though no single fix exists, collective
    efforts promoting responsible AI development can help democratic societies address
    emerging threats.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能对抗虚假信息具有双刃剑的作用。虽然它能够实现可扩展的检测，但自动化使得传播复杂、个性化的宣传更加容易。人工智能的使用可能有助于或有害于安全，取决于是否负责任地使用。它增加了对使用生成式黑客和社会工程技术进行网络攻击的虚假信息的脆弱性。与微目标定位和深度伪造等人工智能技术相关的重大威胁。强大的人工智能可以在心理上对用户进行个性化分析，传递便于隐蔽操纵、避免广泛审查的虚假信息。大数据和人工智能可以被利用来利用心理漏洞，渗透在线论坛，攻击和传播阴谋论。虚假信息已经转变为一个多方面的现象，涉及偏见信息、操纵、宣传以及意图影响政治行为。例如，在COVID-19大流行期间，虚假信息和信息疫情的传播一直是一个重大挑战。人工智能有潜力影响公众对选举、战争或外国势力等主题的观点。它还可以生成虚假的音频/视频内容来损害声誉并制造混乱。国家和非国家行为者正在武器化这些能力进行宣传，损害声誉并制造混乱。政党、政府、犯罪团伙甚至法律系统都可以利用人工智能发起诉讼并获取金钱。这可能会在各个领域产生深远的影响。大部分互联网用户可能正在获取所需信息而无需访问外部网站。大型企业成为信息的守门人并控制公众舆论的危险，实际上能够限制某些行动或观点。谨慎的治理和数字素养对于建立抵抗力至关重要。虽然没有单一的解决方案，但促进负责任的人工智能发展的集体努力可以帮助民主社会应对新兴威胁。
- en: Practical Implementation Challenges
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施挑战
- en: 'Realizing the potential of generative AI in a responsible manner involves addressing
    a number of practical legal, ethical and regulatory issues:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 负责任地实现生成式人工智能的潜力涉及解决许多实际的法律、伦理和监管问题：
- en: '**Legal**: Copyright laws remain ambiguous regarding AI-generated content.
    Who owns the output - the model creator, training data contributors, or end users?
    Replicating copyrighted data in training also raises fair use debates that need
    clarification.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**法律**：关于人工智能生成内容，版权法仍存在模糊不清的问题。谁拥有产出物 - 模型创建者、训练数据贡献者还是最终用户？在训练中复制受版权保护的数据也引发了需要澄清的公平使用争议。'
- en: '**Data Protection**: Collecting, processing and storing the massive datasets
    required to train advanced models creates data privacy and security risks. Governance
    models ensuring consent, anonymity and safe access are vital.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据保护**：收集、处理和存储训练高级模型所需的大规模数据集会带来数据隐私和安全风险。确保同意、匿名性和安全访问的治理模型至关重要。'
- en: '**Oversight and Regulations**: Calls are mounting for oversight to ensure non-discrimination,
    accuracy and accountability from advanced AI systems. But flexible policies balancing
    innovation and risk are needed rather than burdensome bureaucracy.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督和法规**：呼吁加强监督，确保先进人工智能系统不歧视、准确和负责任。但是需要灵活的政策来平衡创新和风险，而不是繁琐的官僚主义。'
- en: '**Ethics**: Frameworks guiding development toward beneficial outcomes are indispensible.
    Integrating ethics through design practices focused on transparency, explicability
    and human oversight helps build trust.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理学**：引导发展朝着有益结果的框架是不可或缺的。通过专注于透明性、可解释性和人类监督的设计实践来整合伦理有助于建立信任。'
- en: Overall, proactive collaboration between policymakers, researchers and civil
    society is essential to settle unresolved issues around rights, ethics and governance.
    With pragmatic guardrails in place, generative models can fulfill their promise
    while mitigating harm. But public interest must remain the compass guiding AI
    progress.There is a growing demand for algorithmic transparency. This means that
    tech companies and developers should reveal the source code and inner workings
    of their systems. However, there is resistance from these companies and developers
    who argue that disclosing proprietary information would harm their competitive
    advantage. Open-source models will continue to thrive and local legislation in
    EU and other countries will push for transparent use of AI.The consequence of
    AI bias includes potential harm to individuals or groups due to biased decisions
    made by AI systems. Incorporating ethics training into computer science curricula
    can help reduce biases in AI codes. By teaching developers how to build applications
    that are ethical by design applications, the probability of biases being embedded
    into the codes can be minimized. To stay on the right path, organizations need
    to prioritize transparency, accountability, and guardrails to prevent bias in
    their AI systems. AI bias prevention is a long-term priority for many organizations,
    however, without legislation driving it, it can take time to be introduced. Local
    legislation in EU countries, for example, such as the European Commission’s proposal
    for harmonized rules on AI regulation, will drive more ethical use of language
    and imagery.A current German law on fake news, which imposes a 24-hour timeframe
    for platforms to remove fake news and hate speech, is impractical for both large
    and small platforms. Additionally, the limited resources of smaller platforms
    make it unrealistic for them to police all content. Further, online platforms
    should not have the sole authority to determine what is considered truth, as this
    could lead to excessive censorship. More nuanced policies are needed that balance
    free speech, accountability, and feasibility for a diversity of technology platforms
    to comply. Relying solely on private companies to regulate online content raises
    concerns around lack of oversight and due process. Broader collaboration between
    government, civil society, academics, and industry can develop more effective
    frameworks to counter misinformation while protecting rights.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，政策制定者、研究人员和公民社会之间的积极合作对于解决围绕权利、伦理和治理尚未解决的问题至关重要。在制定务实的监管措施的同时，生成模型可以实现其承诺，同时减少伤害。但公众利益必须始终是引导人工智能进步的指南。对算法透明性的需求日益增长。这意味着科技公司和开发者应该揭示其系统的源代码和内部运作方式。然而，这些公司和开发者认为披露专有信息会损害其竞争优势，因此存在抵制。开源模型将继续蓬勃发展，欧盟和其他国家的地方立法将推动人工智能的透明使用。人工智能偏见的后果包括由人工智能系统做出的偏见决策可能对个人或群体造成潜在伤害。将伦理培训纳入计算机科学课程可以帮助减少人工智能代码中的偏见。通过教导开发者如何构建以伦理为设计基础的应用程序，可以最大程度地减少将偏见嵌入代码的可能性。为了走上正确的道路，组织需要优先考虑透明度、问责制和监管措施，以防止其人工智能系统中存在偏见。人工智能偏见预防是许多组织的长期优先事项，然而，如果没有立法推动，引入可能需要时间。例如，欧盟国家的地方立法，如欧洲委员会关于人工智能监管规则的提案，将推动更具伦理性的语言和形象使用。德国目前关于虚假新闻的法律规定，要求平台在24小时内删除虚假新闻和仇恨言论，对于大型和小型平台都是不切实际的。此外，较小平台有限的资源使得他们无法监管所有内容变得不切实际。此外，在线平台不应该拥有确定什么是真相的唯一权威，因为这可能导致过度审查。需要更加细致的政策来平衡言论自由、问责制和各种技术平台遵守的可行性。仅依靠私营公司来监管在线内容引发了对监督和正当程序不足的担忧。政府、公民社会、学术界和行业之间更广泛的合作可以制定更有效的框架来对抗错误信息，同时保护权利。
- en: The Road Ahead
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未来之路
- en: The forthcoming era of generative AI models offers a plethora of intriguing
    opportunities and unparalleled progression, yet it is interspersed with numerous
    uncertainties. As discussed in this book, many breakthroughs have been accomplished
    in the recent years but successive challenges continue to linger, mainly pertaining
    to precision, rationalizing ability, controllability and entrenched bias within
    these models. While grandiose claims of superintelligent AI on the horizon may
    seem hyperbolic, consistent trends predict sophisticated capabilities sprouting
    within a few decades. On an individual level, the proliferation of generative
    content raises valid concerns around misinformation, plagiarism in academia, and
    impersonation in online spaces. As these models become more adept at mimicking
    human expression, people may have difficulty discerning what is human-generated
    versus AI-generated, enabling new forms of deception. There are also fears about
    generative models exacerbating social media addiction due to their ability to
    produce endless customized content.From a societal perspective, the sheer pace
    of advancement creates unease surrounding human obsolescence and job displacement,
    which could further divide economic classes. Unlike physical automation of the
    past, generative AI threatens cognitive job categories previously considered safe
    from automation. Managing this workforce transition ethically and equitably will
    require foresight and planning. There are also philosophical debates around whether
    AI should be creating art, literature or music that has historically reflected
    the human condition.For corporations, effective governance frameworks have yet
    to be established around acceptable use cases. Generative models amplify risks
    of misuse, ranging from creating misinformation such as deepfakes to generating
    unsafe medical advice. Legal questions around content licensing and intellectual
    property arise. While these models can enhance business productivity, quality
    control and bias mitigation incur additional costs. While large tech firms currently
    dominate generative AI research and development, smaller entities may ultimately
    stand to gain the most from these technologies. As costs decline for computing,
    data storage, and AI talent, custom pre-training of specialized models could become
    feasible for small and mid-sized companies. Rather than relying on generic models
    from Big Tech, tailored generative AI fine-tuned on niche datasets could better
    serve unique needs. Startups and non-profits often excel at rapidly iterating
    to build cutting-edge solutions for specialized domains. Democratized access through
    cost reductions could enable such focused players to train performant models exceeding
    capabilities of generalized systems. Concerns have emerged about saturation as
    generative AI tools are relatively easy to build using foundation models. Customization
    of models and tools is will allow value creation, but it’s unclear who will capture
    most upsides. While current market hype is high, investors are tempering decisions
    given lower valuations and skepticism following the 2021 AI boom/bust cycle. The
    long-term market impact and winning generative AI business models have yet to
    unfold.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 未来的生成式人工智能模型时代提供了大量引人入胜的机遇和无与伦比的进展，然而其中夹杂着许多不确定性。正如本书所讨论的，近年来取得了许多突破，但连续的挑战仍然存在，主要涉及这些模型的精度、理性能力、可控性以及根深蒂固的偏见。虽然有人对即将到来的超智能人工智能的宏伟声明可能显得言过其实，但持续的趋势预示着在未来几十年内将出现复杂的能力。在个人层面上，生成内容的泛滥引发了关于误导、学术抄袭以及在线空间中的冒名顶替的合理担忧。随着这些模型在模仿人类表达方面变得更加娴熟，人们可能难以分辨是人类生成还是人工智能生成的内容，从而为新形式的欺骗创造了可能性。人们还担心生成模型加剧社交媒体成瘾，因为它们能够生成无穷无尽的定制内容。从社会角度来看，快速发展的速度引发了人类过时和工作岗位流失的不安，这可能进一步分化经济阶层。与过去的物理自动化不同，生成式人工智能威胁到以前被认为不会受到自动化影响的认知工作类别。以道德和公平的方式管理这种工作力量的转变将需要远见和规划。围绕AI是否应该创作反映人类状况的艺术、文学或音乐也存在着哲学上的争论。对于企业来说，尚未建立有效的治理框架来规范可接受的用例。生成模型放大了滥用的风险，从制造深度伪造等误导性信息到生成不安全的医疗建议。内容许可和知识产权方面出现了法律问题。虽然这些模型可以提高业务生产力，但质量控制和偏见缓解会增加额外成本。尽管大型科技公司目前主导着生成式人工智能的研究和开发，但较小的实体最终可能从这些技术中获益最多。随着计算、数据存储和人工智能人才成本的降低，为中小型公司进行定制预训练专业模型可能变得可行。与依赖大型科技公司的通用模型不同，针对特定数据集进行细化调整的生成式人工智能���能更好地满足独特需求。初创公司和非营利组织通常擅长快速迭代，为专业领域构建尖端解决方案。通过成本降低实现的民主化访问可能使这些专注的参与者能够训练性能模型，超越通用系统的能力。随着生成式人工智能工具相对容易地构建，关于模型和工具的定制化将促进价值创造，但尚不清楚谁将获得最大的好处。尽管当前市场炒作很高，但投资者在2021年人工智能繁荣/衰退周期之后对较低的估值和怀疑进行了调整。长期市场影响和获胜的生成式人工智能商业模式尚未揭晓。
- en: The **2021 AI boom/bust cycle** refers to a rapid acceleration in investment
    and growth in the AI startup space followed by a market cooldown and stabilization
    in 2022 as projections failed to materialize and valuations declined.
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2021年人工智能繁荣/衰退周期**指的是人工智能初创公司领域投资和增长的快速加速，随后在2022年市场降温和稳定，因为预期未能实现，估值下降。'
- en: ''
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here’s a quick summary:'
  id: totrans-106
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 以下是一个快速摘要：
- en: ''
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Boom Phase (2020-2021):'
  id: totrans-108
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 繁荣阶段（2020-2021年）：
- en: ''
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There was huge interest and skyrocketing investment in AI startups offering
    innovative capabilities like computer vision, natural language processing, robotics,
    and machine learning platforms. Total funding for AI startups hit record levels
    in 2021, with over $73 billion invested globally according to Pitchbook. Hundreds
    of AI startups were founded and funded during this period.
  id: totrans-110
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于提供创新能力的人工智能初创公司，如计算机视觉、自然语言处理、机器人技术和机器学习平台，市场出现了巨大的兴趣和投资热潮。根据Pitchbook的数据，2021年全球人工智能初创公司的总融资额达到创纪录的730亿美元以上。在这一时期，数百家人工智能初创公司应运而生并获得了资金支持。
- en: ''
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Bust Phase (2022):'
  id: totrans-112
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 破灭阶段（2022年）：
- en: ''
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In 2022, the market underwent a correction, with valuations of AI startups falling
    significantly from their 2021 highs. Several high-profile AI startups like Anthropic
    and Cohere faced valuation markdowns. Many investors became more cautious and
    selective with funding AI startups. Market corrections in the broader tech sector
    also contributed to the bust.
  id: totrans-114
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在2022年，市场经历了一次修正，人工智能初创公司的估值从2021年的高点大幅下跌。一些知名的人工智能初创公司，如Anthropic和Cohere，面临了估值下调。许多投资者对资助人工智能初创公司变得更加谨慎和选择性。更广泛的科技行业市场调整也促成了这一繁荣的结束。
- en: ''
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Key Factors:'
  id: totrans-116
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 关键因素：
- en: ''
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Excessive hype, unrealistic growth projections, historically high valuations
    in 2021, and broader economic conditions all contributed to the boom-bust cycle.
    The cycle followed a classic pattern seen previously in sectors like dot-com and
    blockchain.
  id: totrans-118
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 过度炒作、不切实际的增长预期、2021年历史上高企的估值以及更广泛的经济状况都导致了这一繁荣-衰退周期。这一周期遵循了先前在互联网泡沫和区块链等领域中看到的经典模式。
- en: 'Looking decades ahead, perhaps the deepest challenges are ethical. As AI is
    entrusted with more consequential decisions, alignment with human values becomes
    critical. While accuracy, reasoning ability, controllability, and mitigating bias
    remain technical priorities, other priorities should include fortifying model
    robustness, promoting transparency and ensuring alignment with human values. In
    order to maximize benefits, companies need to ensure human oversight, diversity,
    and transparency in development. Policy makers may need to implement guardrails
    preventing misuse while providing workers with support to transition as activities
    shift. With responsible implementation, generative AI could propel growth, creativity
    and accessibility in a more prosperous society. Addressing potential risks early
    on and ensuring a just distribution of benefits designed to serve public welfare
    will cultivate a sense of trust among stakeholders, such as:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 展望几十年后，也许最深远的挑战是伦理问题。随着人工智能被委托处理更为重要的决策，与人类价值观的一致性变得至关重要。虽然准确性、推理能力、可控性和减少偏见仍然是技术上的重点，但其他重点应包括加强模型的稳健性、促进透明度并确保与人类价值观的一致性。为了最大化利益，公司需要确保人类监督、多样性和开发过程的透明度。政策制定者可能需要实施防止滥用的限制措施，同时为工人提供支持以适应活动的转变。通过负责任的实施，生成式人工智能可以推动社会的增长、创造力和可访问性。及早解决潜在风险并确保公共利益设计的利益公平分配将培养利益相关者的信任，例如：
- en: '**The Dynamics of Progress**: Fine-tuning the pace of transformation is critical
    to avoid any undesired repercussions. Moreover, excessively slow developments
    could stifle innovation, suggesting that determining an ideal pace through encompassing
    public discourse is crucial.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进步的动态**：调整转型的速度对于避免任何不良后果至关重要。此外，过于缓慢的发展可能会扼杀创新，因此通过包容性的公共讨论确定理想的速度是至关重要的。'
- en: '**The Human-AI Symbiosis**: Rather than striving for outright automation, more
    advantageous systems would integrate and complement the creative prowess of humans
    with the productive efficiency of AI. Such a hybrid model will ensure optimal
    oversight.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工智能与人类的共生**：与其追求完全自动化，更有利的系统将整合和补充人类的创造力与人工智能的生产效率。这样的混合模式将确保最佳监督。'
- en: '**Promoting Access and Inclusion**: Equitable access to resources, relevant
    education and myriad opportunities concerning AI is key to negating the amplification
    of disparities. Representativeness and diversity should be prioritized.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**促进获取和包容性**：对人工智能资源、相关教育和各种机会的平等获取对抵消差距的扩大至关重要。代表性和多样性应该得到优先考虑。'
- en: '**Preventive Measures and Risk Management**: Constant evaluation of freshly
    emerging capabilities via interdisciplinary insights is necessary to evade future
    dangers. Excessive apprehensions, however, should not impede potential progress.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预防措施和风险管理**：通过跨学科的洞察力不断评估新兴能力是必要的，以避免未来的危险。然而，过度的担忧不应阻碍潜在的进步。'
- en: '**Upholding Democratic Norms**: Collaborative discussions, communal efforts
    and reaching compromise will inevitably prove more constructive in defining the
    future course of AI, as compared to unilateral decrees imposed by a solitary entity.
    Public interest must take precedence.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护民主规范**：合作讨论、共同努力和达成妥协必然比由一个孤立实体强加的单方面法令更有建设性地定义人工智能未来发展方向。公共利益必须优先考虑。'
- en: While future capabilities remain uncertain, proactive governance and democratization
    of access are essential to direct these technologies toward equitable, benevolent
    outcomes. Collaboration between researchers, policymakers and civil society around
    issues of transparency, accountability and ethics can help align emerging innovations
    with shared human values. The goal should be empowering human potential, not mere
    technological advancement.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然未来的能力仍然不确定，但积极的治理和获取的民主化对于引导这些技术走向公平、善意的结果至关重要。研究人员、政策制定者和公民社会围绕透明度、问责制和伦理问题展开合作，可以帮助将新兴创新与共同的人类价值观对齐。目标应该是赋予人类潜力，而不仅仅是技术进步。
