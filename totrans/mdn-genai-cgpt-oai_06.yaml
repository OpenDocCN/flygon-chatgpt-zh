- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding Prompt Design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we mentioned the term **prompt** several times while
    referring to user input in ChatGPT and OpenAI models in general.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter focuses in more depth on the importance of prompt design and engineering
    as a technique to improve the accuracy of the model. Prompts heavily impact the
    model’s generated output: a well-designed prompt can help guide the model toward
    generating relevant and accurate output, while a poorly designed prompt can lead
    to irrelevant or confusing output. Finally, it is also important to incorporate
    ethical considerations into the prompt to prevent the model from generating harmful
    content.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a prompt and why is it important?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-, one-, and few-shot learning – typical of transformers models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principles of well-defined prompts to obtain relevant and consistent results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding the risk of hidden bias and taking into account ethical considerations
    in ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to get high-quality results from
    your ChatGPT and OpenAI model interactions thanks to proper prompt design.
  prefs: []
  type: TYPE_NORMAL
- en: What is a prompt and why is it important?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the context of generative AI, a prompt refers to the input the user provides
    to the generative models. When we talk about ChatGPT and OpenAI models, prompts
    mainly refer to a piece of text in natural language or – as we saw for Codex models
    – in programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: Prompts are the only way users can control the output generated by those models.
    As such, there is no surprise in saying that the quality of the prompts used to
    engage the AI system in a conversation is key to determining its success.
  prefs: []
  type: TYPE_NORMAL
- en: Well-defined prompts are the recipe for a successful conversation that covers
    the topics of interest; poorly-defined prompts, on the other hand, not only prevent
    the conversation from being useful to the user but could also lead to potentially
    misleading content. As we saw in the previous chapter, ChatGPT still suffers from
    some limitations, such as the 2021 cut-off of its knowledge base, as well as another
    caveat typical of generative AI systems in general, such as the phenomenon of
    hallucination.
  prefs: []
  type: TYPE_NORMAL
- en: Namely, imagine that we want to learn about **Convolutional Neural Networks**
    (**CNNs**). We don’t have any knowledge about **Artificial Neural Networks** (**ANNs**),
    so we need to start with a gentle introduction. The idea is that, starting from
    the first output, we can deep dive into relevant elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s examine the result of a poorly-defined prompt in ChatGPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Example of a poorly-defined prompt](img/Figure_4.1_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Example of a poorly-defined prompt
  prefs: []
  type: TYPE_NORMAL
- en: The result is correct and accurate, but it’s going through many technical concepts
    we may have never seen before. What are fully connected layers? What is a pooling
    layer? This answer assumes we have previous knowledge of ANNs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to give more context to ChatGPT to get a result that is more useful
    to us:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Example of a well-defined prompt](img/Figure_4.2_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – Example of a well-defined prompt
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the wording in this response is much more likely than the one
    I was looking for. In the introduction, it doesn’t use words such as *multi-layer
    perceptron* or *fully connected layer*. It also provides, as requested, an example
    of the process of image recognition. Then, it goes into further details, making
    sure to explain each step with simple words.
  prefs: []
  type: TYPE_NORMAL
- en: I’m pretty satisfied with this response and, as a user, I could now start asking
    about the pooling layer in more detail, for example.
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, prompt design and engineering has been gaining more and more traction
    and it’s growing as a discipline itself.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s focus on how to improve ChatGPT’s responses by leveraging its few-shot
    learning capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Zero-, one-, and few-shot learning – typical of transformers models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we mentioned how OpenAI models, and hence also ChatGPT,
    come in a pre-trained format. They have been trained on a huge amount of data
    and have had their (billions of) parameters configured accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: However, this doesn’t mean that those models can’t learn anymore. In [*Chapter
    2*](B19904_02.xhtml#_idTextAnchor030), we saw that one way to customize an OpenAI
    model and make it more capable of addressing specific tasks is by **fine-tuning**.
  prefs: []
  type: TYPE_NORMAL
- en: Definition
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning is the process of adapting a pre-trained model to a new task. In
    fine-tuning, the parameters of the pre-trained model are altered, either by adjusting
    the existing parameters or by adding new parameters so that they fit the data
    for the new task. This is done by training the model on a smaller labeled dataset
    that is specific to the new task. The key idea behind fine-tuning is to leverage
    the knowledge learned from the pre-trained model and fine-tune it to the new task,
    rather than training a model from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning is a proper training process that requires a training dataset, compute
    power, and some training time (depending on the amount of data and compute instances).
  prefs: []
  type: TYPE_NORMAL
- en: 'That is why it is worth testing another method for our model to become more
    skilled in specific tasks: **shot learning**.'
  prefs: []
  type: TYPE_NORMAL
- en: The idea is to let the model learn from simple examples rather than the entire
    dataset. Those examples are samples of the way we would like the model to respond
    so that the model not only learns the content but also the format, style, and
    taxonomy to use in its response.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, shot learning occurs directly via the prompt (as we will see in
    the following scenarios), so the whole experience is less time-consuming and easier
    to perform.
  prefs: []
  type: TYPE_NORMAL
- en: The number of examples provided determines the level of shot learning we are
    referring to. In other words, we refer to zero-shot if no example is provided,
    one-shot if one example is provided, and few-shot if more than 2-3 examples are
    provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s focus on each of those scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Zero-shot learning**. In this type of learning, the model is asked to perform
    a task for which it has not seen any training examples. The model must rely on
    prior knowledge or general information about the task to complete the task. For
    example, a zero-shot learning approach could be that of asking the model to generate
    a description, as defined in my prompt:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Example of zero-shot learning](img/Figure_4.3_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Example of zero-shot learning
  prefs: []
  type: TYPE_NORMAL
- en: '**One-shot learning**: In this type of learning, the model is given a single
    example of each new task it is asked to perform. The model must use its prior
    knowledge to generalize from this single example to perform the task. If we consider
    the preceding example, I could provide my model with a prompt-completion example
    before asking it to generate a new one:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Example of one-shot learning](img/Figure_4.4_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 – Example of one-shot learning
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the way I provided an example was similar to the structure used for
    fine-tuning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Few-shot learning**: In this type of learning, the model is given a small
    number of examples (typically between 3 and 5) of each new task it is asked to
    perform. The model must use its prior knowledge to generalize from these examples
    to perform the task. Let’s continue with our example and provide the model with
    further examples:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Example of few-shot learning with three examples](img/Figure_4.5_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 – Example of few-shot learning with three examples
  prefs: []
  type: TYPE_NORMAL
- en: 'The nice thing about few-shot learning is that you can also control model output
    in terms of how it is presented. You can also provide your model with a template
    of the way you would like your output to look. For example, consider the following
    tweet classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Few-shot learning for a tweets classifier. This is a modified
    version of the original script from https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/completions](img/Figure_4.6_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 – Few-shot learning for a tweets classifier. This is a modified version
    of the original script from https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/completions
  prefs: []
  type: TYPE_NORMAL
- en: Let’s examine the preceding figure. First, I provided ChatGPT with some examples
    of labeled tweets. Then, I provided the same tweets but in a different data format
    (list format), as well as the labels in the same format. Finally, in list format,
    I provided unlabeled tweets so that the model returns a list of labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output format is not the only thing you can teach your model, though. You
    can also teach it to act and speak with a particular jargon and taxonomy, which
    could help you obtain the desired result with the desired wording:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Example of a conversation with ChatGPT acting as an interviewer](img/Figure_4.7_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 – Example of a conversation with ChatGPT acting as an interviewer
  prefs: []
  type: TYPE_NORMAL
- en: 'Or, imagine you want to generate a chatbot called Simpy that is very funny
    and sarcastic while responding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – Example of a chatbot that is funny and sarcastic, making fun
    of my request](img/Figure_4.8_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 – Example of a chatbot that is funny and sarcastic, making fun of
    my request
  prefs: []
  type: TYPE_NORMAL
- en: We have to say, with this last one, ChatGPT nailed it.
  prefs: []
  type: TYPE_NORMAL
- en: Shot-learning possibilities are limitless (and often more useful than Simpy)
    – it’s only a matter of testing and a little bit of patience in finding the proper
    prompt design.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, it is important to remember that these forms of learning
    are different from traditional supervised learning, as well as fine-tuning. In
    few-shot learning, the goal is to enable the model to learn from very few examples,
    and to generalize from those examples to new tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve learned how to let ChatGPT learn from examples, let’s focus on
    how to properly define our prompt to make the model’s response as accurate as
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: Principles of well-defined prompts to obtain relevant and consistent results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Previously, we saw how important prompt designing and engineering are when
    controlling models’ output. Here are some best practices you can use to improve
    your prompts, as well as some practices you should avoid:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Clarity**: Use simple sentences and instructions that can easily be understood
    by ChatGPT.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conciseness**: Favor short prompts and short sentences. This can be achieved
    by chunking your instructions into smaller sentences with clear intentions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Focus**: Keep the focus of the prompt on a well-defined topic so that you
    don’t risk your output being too generic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistency**: Maintain a consistent tone and language during the conversation
    so that you can ensure a coherent conversation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**“Acting as…”**: The hack of letting ChatGPT act as someone or something has
    proven to be extremely powerful. You can shorten the context you have to provide
    to the model by simply asking him to *act like* the person or system you want
    information from. We’ve already seen the interview-candidate example, where ChatGPT
    acted as an interviewer for a data scientist position. A very interesting prompt
    is that of asking ChatGPT to act as a console. Here is an example of it:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.9 – Example of ChatGPT acting as a Python console](img/Figure_4.9_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 – Example of ChatGPT acting as a Python console
  prefs: []
  type: TYPE_NORMAL
- en: Note that the console, as it would be if it were real, is also reporting the
    error I made in the `for` cycle, indicating that I was missing the brackets.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a continuously growing list of *Act as* prompts you can try in the
    following GitHub repository: https://github.com/f/awesome-chatgpt-prompts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering the few-shot learning capabilities elaborated on in the previous
    paragraph, there are some good tips for leveraging this feature in prompt designing.
    An ideal conversation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with a concise, clear, and focused prompt. This will help you have an
    overview of the topic you want to discuss, as well as provide food for thought
    and potential expansion of particular elements. Here’s an example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.10 – Example of a clear and focused prompt to initiate a conversation
    with ChatGPT](img/Figure_4.10_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 – Example of a clear and focused prompt to initiate a conversation
    with ChatGPT
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have identified the relevant elements in the discussion, you can ask
    ChatGPT to elaborate on them with much more focus:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.11 – Example of a deep-dive follow-up question in a conversation
    with ChatGPT](img/Figure_4.11_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 – Example of a deep-dive follow-up question in a conversation with
    ChatGPT
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, it might be useful to remember the model and the context in which
    you are inquiring, especially if the question might apply to various domains:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Example of a reminder about the context in a conversation with
    ChatGPT](img/Figure_4.12_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.12 – Example of a reminder about the context in a conversation with
    ChatGPT
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, always keep in mind the limitations we mentioned in previous chapters.
    ChatGPT may provide partial or incorrect information, so it is always a good practice
    to double-check. One nice tip you could try is asking the model to provide documentation
    about its responses so that you can easily find proof of them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.13 – Example of ChatGPT providing documentation supporting its previous
    responses](img/Figure_4.13_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.13 – Example of ChatGPT providing documentation supporting its previous
    responses
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, there are some things you should avoid while designing your
    prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Information overload**: Avoid providing too much information to ChatGPT,
    since it could reduce the accuracy of the response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open-ended questions**: Avoid asking ChatGPT vague, open-ended questions.
    Prompts such as *What can you tell me about the world?* or *Can you help me with
    my exam?* are far too generic and will result in ChatGPT generating vague, useless,
    and sometimes hallucinated responses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of constraints**: If you are expecting an output with a specific structure,
    don’t forget to specify that to ChatGPT! If you think about the earlier example
    of ChatGPT acting as an interviewer, you can see how strict I was in specifying
    not to generate questions all at once. It took several tries before getting to
    the result since ChatGPT is thought to generate a continuous flow of text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: As a general consideration, we still have to remember that the knowledge base
    of ChatGPT is limited to 2021, so we should avoid asking questions about facts
    that occurred after that date. You can still provide context; however, all the
    responses will be biased toward the knowledge base before 2021.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, it is worth mentioning that in the last few months, a lot of research
    and development has been dedicated to the study of prompt design for **large language
    models** (**LLMs**) (not just **generative pretrained transformer** (**GPT**)),
    because of the extensive use of some specific techniques such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Chain-of-Thought** (**CoT**): Google researchers Jason Wei et al. have introduced
    a new technique called **CoT prompting** to improve the reasoning abilities of
    LLMs. The method divides intricate problems into smaller, manageable steps, which
    enables language models to solve complex reasoning tasks that cannot be handled
    by conventional promoting approaches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, let’s say we want to train a language model to solve a complex
    math problem, such as calculating the value of an algebraic expression. We can
    use CoT prompting to break down the problem into smaller, manageable steps.
  prefs: []
  type: TYPE_NORMAL
- en: First, we can prompt the model to identify the variables and constants in the
    expression. Then, we can prompt the model to apply the order of operations to
    simplify the expression. Next, we can instruct the model to substitute the numerical
    values of the variables and constants. Finally, we can prompt the model to evaluate
    the expression to obtain the final result.
  prefs: []
  type: TYPE_NORMAL
- en: By using CoT prompting, the language model can learn to solve complex math problems
    that require multi-step reasoning and problem-solving abilities.
  prefs: []
  type: TYPE_NORMAL
- en: '**Active-Prompt**: Even if prompting with CoT reasoning has been proven effective,
    current CoT methods rely on a fixed set of human-annotated exemplars that may
    not be optimal for different tasks. In their paper, *Active Prompting with Chain-of-Thoughts
    for Large Language Models*, Shizhe Diao et al. propose a new method called **Active-Prompt**,
    which adapts LLMs to different tasks by selecting the most important and helpful
    questions to annotate from a pool of task-specific queries. The following approach
    involves querying the LLM with a few CoT examples and generating *k* possible
    answers for a set of training questions. An uncertainty metric is then calculated
    based on the disagreement among the *k* answers. The most uncertain questions
    are selected for annotation by humans, and the newly annotated exemplars are used
    to infer each question.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reason and Act** (**ReAct**): This approach is based on human intelligence’s
    ability to seamlessly combine task-oriented actions with verbal reasoning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, imagine a person trying to assemble a piece of furniture, such
    as a bookshelf. Between each specific action, the person may reason in language
    to track progress (“*Now that I’ve attached the sides, I need to connect the shelves*”),
    handle exceptions, or adjust the plan according to the situation (“*These screws
    don’t fit, so I need to find a different size*”), and to realize when external
    information is needed (“*I’m not sure which way this piece goes, let me look at
    the instructions*”). The person may also act by referring to the instructions,
    looking for the necessary tools, and positioning the pieces correctly to support
    the reasoning and to answer questions (“*Which screws go where?*”). This tight
    synergy between acting and reasoning enables the person to complete the task efficiently
    and effectively, even if they have never assembled a bookshelf before.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, the ReAct paradigm introduced by Shunyu Yao et al. does exactly the same:
    it prompts LLMs to produce verbal reasoning traces and actions that are relevant
    to the task at hand in a seamlessly interleaved manner. By doing so, the model
    can engage in dynamic reasoning to create, adjust, and maintain high-level plans
    for acting while simultaneously interacting with external sources of information
    (such as Wikipedia) to incorporate additional insights into the reasoning process
    (act to reason). This approach facilitates a more comprehensive and effective
    way of using language models to solve complex problems, enabling them to perform
    both reasoning and acting in an integrated manner.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Those are just some of the next few newly developed techniques: since it is
    a new and emerging domain of research, we will probably see an explosion of experimentation
    and papers about prompt design in the coming months.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is important to keep some ethical considerations about ChatGPT responses
    in mind. We will cover these in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding the risk of hidden bias and taking into account ethical considerations
    in ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ChatGPT has been provided with the Moderator API so that it cannot engage in
    conversations that might be unsafe. The Moderator API is a classification model
    performed by a GPT model based on the following classes: violence, self-harm,
    hate, harassment, and sex. For this, OpenAI uses anonymized data and synthetic
    data (in zero-shot form) to create synthetic data.'
  prefs: []
  type: TYPE_NORMAL
- en: The Moderation API is based on a more sophisticated version of the content filter
    model available among OpenAI APIs. We discussed this model in [*Chapter 1*](B19904_01.xhtml#_idTextAnchor015),
    where we saw how it is very conservative toward false positives rather than false
    negatives.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is something we can refer to as **hidden bias**, which derives
    directly from the knowledge base the model has been trained on. For example, concerning
    the main chunk of training data of GPT-3, known as the **Common Crawl**, experts
    believe that it was written mainly by white males from Western countries. If this
    is the case, we are already facing a hidden bias of the model, which will inevitably
    mimic a limited and unrepresentative category of human beings.
  prefs: []
  type: TYPE_NORMAL
- en: In their paper, *Languages Models are Few-Shots Learners*, OpenAI’s researchers
    Tom Brown et al. (https://arxiv.org/pdf/2005.1416) created an experimental setup
    to investigate racial bias in GPT-3\. The model was prompted with phrases containing
    racial categories and 800 samples were generated for each category. The sentiment
    of the generated text was measured using Senti WordNet based on word co-occurrences
    on a scale ranging from -100 to 100 (with positive scores indicating positive
    words, and vice versa).
  prefs: []
  type: TYPE_NORMAL
- en: 'The results showed that the sentiment associated with each racial category
    varied across different models, with *Asian* consistently having a high sentiment
    and *Black* consistently having a low sentiment. The authors caution that the
    results reflect the experimental setup and that socio-historical factors may influence
    the sentiment associated with different demographics. The study highlights the
    need for a more sophisticated analysis of the relationship between sentiment,
    entities, and input data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.14 – Racial sentiment across models](img/Figure_4.14_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.14 – Racial sentiment across models
  prefs: []
  type: TYPE_NORMAL
- en: This hidden bias could generate harmful responses not in line with responsible
    AI principles.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is worth noticing how ChatGPT, as well as all OpenAI models, are
    subject to continuous improvements. This is also consistent with OpenAI’s AI **alignment**
    (https://openai.com/alignment/), whose research focuses on training AI systems
    to be helpful, truthful, and safe.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we ask ChatGPT to formulate guesses based on people’s gender
    and race, it will not accommodate the request:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.15 – Example of ChatGPT improving over time since it gives an unbiased
    response](img/Figure_4.15_B19904.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.15 – Example of ChatGPT improving over time since it gives an unbiased
    response
  prefs: []
  type: TYPE_NORMAL
- en: Overall, despite the continuous improvement in the domain of ethical principles,
    while using ChatGPT, we should always make sure that the output is in line with
    those principles and not biased.
  prefs: []
  type: TYPE_NORMAL
- en: The concepts of bias and ethics within ChatGPT and OpenAI models have a wider
    collocation within the whole topic of responsible AI, which we are going to focus
    on in the last chapter of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have dived deeper into the concept of prompt design and
    engineering since it’s the most powerful way to control the output of ChatGPT
    and OpenAI models. We learned how to leverage different levels of shot learning
    to make ChatGPT more tailored toward our objectives: if we want the AI response
    to have a particular style and format, we can provide examples so that it can
    learn from them, as we saw when analyzing tweet sentiments. We also learned how
    to write an effective prompt with some nice examples – especially with the *Act
    as...* trick – and what to avoid, such as open-ended questions or information
    overload.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next few chapters, we will cover concrete examples of how ChatGPT can
    boost general users’ daily productivity, with easy prompts and tips you can replicate
    on your own.
  prefs: []
  type: TYPE_NORMAL
- en: Starting from the next chapter, we will dive deeper into different domains where
    ChatGPT can boost productivity and have a disruptive impact on the way we work
    today.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://dl.acm.org/doi/10.1145/3442188.3445922](https://dl.acm.org/doi/10.1145/3442188.3445922)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://openai.com/alignment/](https://openai.com/alignment/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://twitter.com/spiantado/status/1599462375887114240?ref _src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1599462375     887114240%7Ctwgr%5E1dc908b53fd4be487829472a6bc8590a9dc4aa2d%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fthestoryexchange.org%2F     chatgpt-and-the-hidden-bias-of-language-models%2F](https://twitter.com/spiantado/status/1599462375887114240?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1599462375887114240%7Ctwgr%5E1dc908b53fd4be487829472a6bc8590a9dc4aa2d%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fthestoryexchange.org%2Fchatgpt-and-the-hidden-bias-of-language-models%2F)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
