- en: '[CHAPTER 7](toc.xhtml#c07)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章
- en: '[ChatGPT Technical Overview: Introduction](toc.xhtml#c07)'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT技术概述：介绍
- en: '[Introduction](toc.xhtml#s63a)'
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Artificial Intelligence or Machine learning, provides automated both supervised
    and unsupervised learning across many modalities, be it textual, or imagery, or
    vocal, maybe across different types such as numerical data, contextual data, feature-based
    data, pattern-based data. **Natural language processing** (**NLP**) has been one
    of the subdomains in the arena of Artificial Intelligence which only captures
    almost 1/5th market share and number of solutions, focusing on the interaction
    between computers and human language.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能或机器学习提供了跨多种形式的自动化监督和无监督学习，无论是文本、图像还是语音，可能是跨不同类型，如数值数据、上下文数据、基于特征的数据、基于模式的数据。自然语言处理（NLP）一直是人工智能领域的一个子领域，它仅占据了几乎五分之一的市场份额和解决方案数量，专注于计算机与人类语言之间的互动。
- en: '[Introduction to Natural Language Processing](toc.xhtml#s64a)'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言处理简介
- en: NLP uses computational techniques to enable computers to understand, interpret,
    and generate human language. It is one of crucial segments of AI which deals with
    the linguistic tasks and automates the process of analyzing and getting meaningful
    context out of any phrase. The tasks involve sentiment analysis, context-mapping,
    chatbots, content predictions, captioning, answer generation, machine translation,
    content classification etc and are used across different industries like banking,
    finance, customer service, health and medical, educational and almost in every
    other entity. NLP has made significant advancements in recent years, thanks to
    the availability of large datasets, powerful computing resources, and advanced
    machine learning algorithms. With its ability to process and understand human
    language, NLP is helping to bridge the gap between humans and machines and making
    our interactions with technology more intuitive and natural.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: NLP使用计算技术使计算机能够理解、解释和生成人类语言。它是人工智能的重要组成部分之一，涉及语言任务并自动化分析和从任何短语中获取有意义的上下文的过程。这些任务包括情感分析、上下文映射、聊天机器人、内容预测、字幕、答案生成、机器翻译、内容分类等，并且在银行业、金融业、客户服务、健康和医疗、教育以及几乎所有其他实体中使用。近年来，NLP取得了重大进展，这要归功于大型数据集、强大的计算资源和先进的机器学习算法。凭借其处理和理解人类语言的能力，NLP正在帮助弥合人类和机器之间的差距，并使我们与技术的互动更直观和自然。
- en: '[Evolution of NLP](toc.xhtml#s65a)'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NLP的发展
- en: According to Stanford university, the first need towards NLP began during World
    war II where urgency translation was reflected. Back to the 1950s when researchers
    began to explore the possibility of using computers to understand and generate
    human language. In 1950, Alan Turing proposed the “Turing Test,” a benchmark for
    machine intelligence that involved a computer’s ability to carry on a conversation
    that was indistinguishable from a human. This led to the development of early
    NLP systems, such as the “ELIZA” program developed in the 1960s, which simulated
    a conversation between a computer and a human therapist.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 根据斯坦福大学的说法，对NLP的第一个需求始于二战期间的紧急翻译。回到20世纪50年代，研究人员开始探索使用计算机理解和生成人类语言的可能性。1950年，艾伦·图灵提出了“图灵测试”，这是机器智能的一个基准，涉及计算机进行与人类无法区分的对话的能力。这导致了早期NLP系统的开发，例如20世纪60年代开发的“ELIZA”程序，模拟了计算机和人类治疗师之间的对话。
- en: In the *1970s*, researchers began to develop more advanced NLP algorithms, such
    as the “SHRDLU” program, which could understand natural language commands and
    manipulate virtual objects in a simulated environment. In the 1980s and 1990s,
    researchers focused on developing statistical models for language processing,
    which allowed computers to learn from large datasets of human language.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪70年代，研究人员开始开发更先进的NLP算法，如“SHRDLU”程序，它可以理解自然语言命令并在模拟环境中操作虚拟对象。在20世纪80年代和90年代，研究人员专注于开发用于语言处理的统计模型，这使计算机能够从大量的人类语言数据集中学习。
- en: In the *2000s and 2010s*, NLP made significant advancements with the development
    of deep learning algorithms and the availability of large datasets, such as Wikipedia
    and social media data. These advancements have led to the development of more
    sophisticated NLP applications, such as voice assistants, chatbots, and machine
    translation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪2000年代和2010年代，NLP在深度学习算法的发展和维基百科、社交媒体数据等大型数据集的可用性方面取得了重大进展。这些进展导致了更复杂的NLP应用程序的开发，如语音助手、聊天机器人和机器翻译。
- en: In the latter part of the last decade, Natural Language Processing (NLP) has
    continued to advance, with researchers making significant progress in areas such
    as deep learning, transfer learning, and pre-training.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在上个十年的后半段，自然语言处理（NLP）继续取得进展，研究人员在深度学习、迁移学习和预训练等领域取得了重大进展。
- en: One of the most significant developments in NLP has been the emergence of large
    pre-trained language models such as **BERT** (**Bidirectional Encoder Representations
    from Transformers**), GPT-2 (Generative Pre-trained Transformer 2), and GPT-3\.
    These models are trained on massive amounts of text data and can perform a wide
    range of NLP tasks, including text classification, question answering, and language
    generation. They have enabled researchers to achieve state-of-the-art results
    on a variety of NLP benchmarks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: NLP中最重要的发展之一是大型预训练语言模型的出现，如BERT（双向编码器表示来自变压器）、GPT-2（生成式预训练变压器2）和GPT-3。这些模型经过大量文本数据的训练，可以执行各种NLP任务，包括文本分类、问答和语言生成。它们使研究人员能够在各种NLP基准测试中取得最先进的结果。
- en: Another important development in NLP has been the use of transfer learning,
    where models are first pre-trained on a large dataset and then fine-tuned for
    a specific task. This approach has been used to achieve high performance on a
    variety of NLP tasks, including sentiment analysis, named entity recognition,
    and text classification.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: NLP方面的另一个重要发展是迁移学习的使用，其中模型首先在大型数据集上进行预训练，然后针对特定任务进行微调。这种方法已被用于在各种NLP任务上实现高性能，包括情感分析、命名实体识别和文本分类。
- en: In addition to these advancements, researchers have also focused on improving
    the robustness and fairness of NLP models. This includes developing methods to
    detect and mitigate bias in language data and models and to ensure that NLP applications
    are accessible to people from diverse linguistic and cultural backgrounds.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些进展，研究人员还专注于改进NLP模型的鲁棒性和公平性。这包括开发方法来检测和减轻语言数据和模型中的偏见，并确保NLP应用对来自不同语言和文化背景的人们是可访问的。
- en: Overall, these advancements in NLP have opened up new possibilities for developing
    more sophisticated and accurate language-based applications, from chatbots to
    virtual assistants, and are likely to have far-reaching implications for many
    industries in the years to come. From then, LUNAR- scientific qualitative data,
    ELIZA - the first chatbot, from the complex models and use cases of today’s date
    such as smart Alexa, conversational bots is Siri with high-level complex neural
    networks at backend. In the context of ChatGPT, it’s one of the modern advanced
    NLP architectures developed, which is able to perform very high level tasks with
    more quantitative and qualitative accuracy and precision, closer to human perceptions
    and interpretations. In between, there has been a gradual yet constant development
    of the process of improvement from Word2Vec model to today’s ChatGPT through neural
    networks, LSTM models, encoder-decoder, Attention models, Transformer model, Google’
    BERT, imageBERT.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，NLP方面的这些进展为开发更复杂和准确的基于语言的应用程序打开了新的可能性，从聊天机器人到虚拟助手，可能会对许多行业产生深远的影响。从那时起，LUNAR-科学定性数据，ELIZA-第一个聊天机器人，从今天的复杂模型和用例，如智能Alexa，对话机器人是Siri，具有高级复杂的神经网络后端。在ChatGPT的背景下，这是一个现代先进的NLP架构，能够以更接近人类感知和解释的定量和定性准确性和精度执行非常高级的任务。在此期间，从Word2Vec模型到今天的ChatGPT，通过神经网络、LSTM模型、编码器-解码器、注意力模型、Transformer模型、Google的BERT、imageBERT等，这个过程的改进逐渐而持续地发展。
- en: '[GPT and ChatGPT](toc.xhtml#s66a)'
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[GPT和ChatGPT](toc.xhtml#s66a)'
- en: Talking about the **Generative Pre-trained Transformer** (GPT), it is a sophisticated
    neural network architecture that underpins ChatGPT with their version 3.5 of the
    GPT series( known as InstructGPT), being their most recent development. The Transformers
    model, created by Google in 2017, is the foundation and the preliminary element
    for this GPT model. It is based on the intuition of the attention-based model
    that was first presented in the paper “**Attention is all you need**.”
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到**生成式预训练变压器**（GPT），它是一个复杂的神经网络架构，支撑着ChatGPT的第3.5版GPT系列（称为InstructGPT），是他们最新的开发。由Google于2017年创建的Transformers模型是这个GPT模型的基础和初步元素。它基于首次在论文“**注意力就是你所需要的**”中提出的基于注意力的模型的直觉。
- en: '[GPT series by OpenAI](toc.xhtml#s67a)'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[GPT系列由OpenAI提供](toc.xhtml#s67a)'
- en: 'Between 2019 and 2022, the whole GPT series had numerous technical model and
    hyper-parameter adjustments by openAI and they have been improvising on many micro-level
    changes. The entire GPT-3 consists of approximately 175B parameters in its entire
    model which is around 50x higher than the language model that Google introduced
    in 2018, BERT; though there are some heavily loaded language models available
    in the research of NLP - like Megatron-NLG, by NVIDIA, with 530B parameters which
    is composed of 560 DGX A100 servers, each containing eight A100 80GB GPUs, capable
    of auto-completing phrases and statements. Google’s PaLM scaled to 540B parameters
    is another example of such a highly multi-tasking NLP model, trained on the largest
    TPU of the world with 6144 chips. Google also introduced LaMDA; in contrast to
    the task-based replies that conventional models frequently provide, the model
    may produce conversational chat in a free-form manner, which also has around 137B
    parameters. The following bubble chart by *Dr Alan D. Thompson* blog series explains
    about the estimation on recent developments of heavy load models with large parameters
    in language model:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在2019年至2022年期间，整个GPT系列通过OpenAI进行了许多技术模型和超参数的调整，并且他们一直在改进许多微观层面的变化。整个GPT-3模型包括大约1750亿个参数，这是谷歌在2018年推出的语言模型BERT的50倍，尽管在NLP研究中有一些装载较重的语言模型，如NVIDIA的Megatron-NLG，具有5300亿个参数，由560个DGX
    A100服务器组成，每个服务器包含八个A100 80GB GPU，能够自动完成短语和陈述。谷歌的PaLM扩展到了5400亿个参数，是另一个例子，这是一个高度多任务的NLP模型，训练在世界上最大的TPU上，拥有6144个芯片。谷歌还推出了LaMDA；与传统模型经常提供的基于任务的回复相反，该模型可以以自由形式产生对话聊天，也有大约1370亿个参数。
    *Dr Alan D. Thompson*博客系列的以下气泡图解释了语言模型中大参数最近发展的估计：
- en: '![](images/Figure-7.1.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](images/Figure-7.1.jpg)'
- en: '**Figure 7.1:** *Leading NLP models with large parameters [Source: Lifearchitect.ai]*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**图7.1：** *具有大参数的领先NLP模型[来源：Lifearchitect.ai]*'
- en: '[Points to remember](toc.xhtml#s68a)'
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[需要记住的要点](toc.xhtml#s68a)'
- en: Natural language processing (NLP) has been one of the subdomains in the arena
    of Artificial Intelligence which only captures almost 1/5th market share and number
    of solutions, focusing on the interaction between computers and human language.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）一直是人工智能领域的一个子领域，它只占据了几乎五分之一的市场份额和解决方案数量，专注于计算机与人类语言之间的交互。
- en: NLP uses computational techniques to enable computers to understand, interpret,
    and generate human language.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NLP使用计算技术使计算机能够理解、解释和生成人类语言。
- en: NLP has made significant advancements in recent years, thanks to the availability
    of large datasets, powerful computing resources, and advanced machine learning
    algorithms.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近年来，由于大型数据集、强大的计算资源和先进的机器学习算法的可用性，自然语言处理取得了重大进展。
- en: With its ability to process and understand human language, NLP is helping to
    bridge the gap between humans and machines and making our interactions with technology
    more intuitive and natural.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 凭借其处理和理解人类语言的能力，自然语言处理正在帮助弥合人类和机器之间的差距，并使我们与技术的互动更直观和自然。
- en: In the 2000s and 2010s, NLP made significant advancements with the development
    of deep learning algorithms and the availability of large datasets, such as Wikipedia
    and social media data.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在2000年代和2010年代，随着深度学习算法的发展和维基百科、社交媒体数据等大型数据集的可用性，自然语言处理取得了重大进展。
- en: In the latter part of the last decade, Natural Language Processing (NLP) has
    continued to advance, with researchers making significant progress in areas such
    as deep learning, transfer learning, and pre-training.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在上个十年的后半段，自然语言处理（NLP）继续取得进展，研究人员在深度学习、迁移学习和预训练等领域取得了重大进展。
- en: These models are trained on massive amounts of text data and can perform a wide
    range of NLP tasks, including text classification, question answering, and language
    generation.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些模型是在大量文本数据上训练的，可以执行各种自然语言处理任务，包括文本分类、问答和语言生成。
- en: In addition to these advancements, researchers have also focused on improving
    the robustness and fairness of NLP models.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了这些进展之外，研究人员还专注于改进自然语言处理模型的健壮性和公平性。
- en: This includes developing methods to detect and mitigate bias in language data
    and models and to ensure that NLP applications are accessible to people from diverse
    linguistic and cultural backgrounds.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这包括开发方法来检测和减轻语言数据和模型中的偏见，并确保自然语言处理应用对来自不同语言和文化背景的人们是可访问的。
- en: Overall, these advancements in NLP have opened up new possibilities for developing
    more sophisticated and accurate language-based applications, from chatbots to
    virtual assistants, and are likely to have far-reaching implications for many
    industries in the years to come.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总的来说，自然语言处理的这些进展为开发更复杂和准确的基于语言的应用打开了新的可能性，从聊天机器人到虚拟助手，可能会对许多行业产生深远的影响。
- en: Join our book's Discord space
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的Discord空间
- en: 'Join the book''s Discord Workspace for Latest updates, Offers, Tech happenings
    around the world, New Release and Sessions with the Authors:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 加入书籍的Discord Workspace，获取最新更新、优惠、全球科技动态、新发布和作者交流的信息：
- en: '[**https://discord.bpbonline.com**](https://discord.bpbonline.com)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[**https://discord.bpbonline.com**](https://discord.bpbonline.com)'
- en: '![](images/dis.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](images/dis.jpg)'
